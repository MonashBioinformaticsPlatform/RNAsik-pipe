{
    "docs": [
        {
            "location": "/", 
            "text": "RNAsik for RNAseq\n\n\n\n\nN.B\n This workflow assumes model organism has a reference genome. If the reference genome isn't applicable, different workflow is required.\n\n\n\n\nAbout\n\n\nRNAsik\n pipeline was build in house for processing \nRNA-seq(uencing)\n data.\nIt is written in \nBigDataScript (bds)\n, which is \ndomain specific language (DSL)\n, that makes writing pipelines easy as well as making them robust. To get a bit more technical, bds runs on \njava virtual machine (JVM)\n and therefore requires \nJava\n.\n\n\nIn simple terms any pipeline is a wrapper of several tools that makes it easier and arguably faster to get to the end goal. The three core parts to any \nRNA-seq analysis\n are: \n\n\n\n\nmapping to the reference genome\n\n\ncounting reads mapped into features e.g genes\n\n\ndoing differential expression (DE) statistics\n\n\n\n\nThe pipeline does the first two parts and \nDegust\n does the third part. Degust itself, in simple terms, a wrapper around \nlimma\n and \nedgeR\n R packages. In theory and practice one can take output from \nRNAsik\n pipeline, which is a table of counts where every gene is a row and every column is a sample and use those with any other R packages that do DE analysis.\n\n\nIn actual terms both \nRNAsik\n and \nDegust\n provide complete experience, not only you'll get your list of DE genes and QC metrics, but will be able to get full inside into your experimental design and the outcome of that. \nRNAsik\n does read alignment and read counting and cleaning and improvements of your table of counts, which makes \nDegust\n analysis one upload away. \nRNAsik\n wraps \nthese tools\n making your RNAseq analysis more streamline. It also has \"sanity checks\" inbuilt, checking command line options, checking if options are valid files/directories and it will talk to you so don't sweat :) but do read the error messages. \nDegust\n is exceptionally good for exploratory data visualisation and analysis. Both tools can also server as a nice proxy for learning bioinformatics as they provide command line and R code for doing the analysis. Last but not least thanks to \nMultiQC\n \nRNAsik\n provides an aggregate of different metrics in one place - multiqc report. This is a good place to start understanding your data.\n\n\nThe central bits of information are:\n\n\n\n\nAre there differences in library sizes?\n\n\nIs there any issues with mapping rates?\n\n\nIs there any issues with reads assignment rates?\n\n\n\n\nHowever there is so many other questions you can ask including:\n\n\n\n\nWhat is duplication rate?\n\n\nWhat is multi-mapping rate?\n\n\nWhat is intragenic and interagenic rates?\n\n\n\n\nAs mentioned above \nmultiqc\n report is a great first step in the attempt to answer those questions. A lot of the time everything looks fairly good and consistent allowing downstream analysis. Sometimes user can tweak certain individual parameters which can improve results, other times it comes down to experimental design and/or library preparation and sequencing issues. Either way one need to make this \"first iteration\" in order to see room for improvement. \n\n\nHow to cite\n\n\nAt the moment the only way to cite is point to github repository. I'm in the process of obtaining \ndoi\n reference.\n\n\n\n\n\n\nTsyganov, K. Perry, A. Archer, S. Powell, D. (2018, January 25). \nRNAsik pipeline for RNA sequencing analysis\n. https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe\n\n\n\n\n\n\nIt can be hard to give full acknowlegment to all contributors. The nature of the open source projects such that contributors can come and go, however they leave behind valuable contributions and need to get full credit for that. Please look at \nRNAsik GitHub\n repository to get a full sense of who is contributing. In particular one can look at \nnumber of commits\n, \nissues triaging and handling\n and \npull requests (PRs)\n. Please also remember that every contribution matters, nothing is too small!\n\n\nMBP team photo\n\n\n\n\nTweet to @kizza_a\n \n\n\n\n\n\n\nShare", 
            "title": "About"
        }, 
        {
            "location": "/#rnasik-for-rnaseq", 
            "text": "N.B  This workflow assumes model organism has a reference genome. If the reference genome isn't applicable, different workflow is required.", 
            "title": "RNAsik for RNAseq"
        }, 
        {
            "location": "/#about", 
            "text": "RNAsik  pipeline was build in house for processing  RNA-seq(uencing)  data.\nIt is written in  BigDataScript (bds) , which is  domain specific language (DSL) , that makes writing pipelines easy as well as making them robust. To get a bit more technical, bds runs on  java virtual machine (JVM)  and therefore requires  Java .  In simple terms any pipeline is a wrapper of several tools that makes it easier and arguably faster to get to the end goal. The three core parts to any  RNA-seq analysis  are:    mapping to the reference genome  counting reads mapped into features e.g genes  doing differential expression (DE) statistics   The pipeline does the first two parts and  Degust  does the third part. Degust itself, in simple terms, a wrapper around  limma  and  edgeR  R packages. In theory and practice one can take output from  RNAsik  pipeline, which is a table of counts where every gene is a row and every column is a sample and use those with any other R packages that do DE analysis.  In actual terms both  RNAsik  and  Degust  provide complete experience, not only you'll get your list of DE genes and QC metrics, but will be able to get full inside into your experimental design and the outcome of that.  RNAsik  does read alignment and read counting and cleaning and improvements of your table of counts, which makes  Degust  analysis one upload away.  RNAsik  wraps  these tools  making your RNAseq analysis more streamline. It also has \"sanity checks\" inbuilt, checking command line options, checking if options are valid files/directories and it will talk to you so don't sweat :) but do read the error messages.  Degust  is exceptionally good for exploratory data visualisation and analysis. Both tools can also server as a nice proxy for learning bioinformatics as they provide command line and R code for doing the analysis. Last but not least thanks to  MultiQC   RNAsik  provides an aggregate of different metrics in one place - multiqc report. This is a good place to start understanding your data.  The central bits of information are:   Are there differences in library sizes?  Is there any issues with mapping rates?  Is there any issues with reads assignment rates?   However there is so many other questions you can ask including:   What is duplication rate?  What is multi-mapping rate?  What is intragenic and interagenic rates?   As mentioned above  multiqc  report is a great first step in the attempt to answer those questions. A lot of the time everything looks fairly good and consistent allowing downstream analysis. Sometimes user can tweak certain individual parameters which can improve results, other times it comes down to experimental design and/or library preparation and sequencing issues. Either way one need to make this \"first iteration\" in order to see room for improvement.", 
            "title": "About"
        }, 
        {
            "location": "/#how-to-cite", 
            "text": "At the moment the only way to cite is point to github repository. I'm in the process of obtaining  doi  reference.    Tsyganov, K. Perry, A. Archer, S. Powell, D. (2018, January 25).  RNAsik pipeline for RNA sequencing analysis . https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe    It can be hard to give full acknowlegment to all contributors. The nature of the open source projects such that contributors can come and go, however they leave behind valuable contributions and need to get full credit for that. Please look at  RNAsik GitHub  repository to get a full sense of who is contributing. In particular one can look at  number of commits ,  issues triaging and handling  and  pull requests (PRs) . Please also remember that every contribution matters, nothing is too small!", 
            "title": "How to cite"
        }, 
        {
            "location": "/#mbp-team-photo", 
            "text": "Tweet to @kizza_a     \nShare", 
            "title": "MBP team photo"
        }, 
        {
            "location": "/docs/", 
            "text": "Documentation\n\n\nQuick start\n\n\nAlign raw reads\n\n\nRNAsik -align star \\\n       -fastaRef /path/to/reference.fasta \\\n       -fqDir /path/to/raw-data/directory\n\n\n\n\nCount gene features\n\n\nRNAsik -counts \\\n       -gtfFile path/to/annotation.gtf\n\n\n\n\nThe lot\n\n\nRNAsik -fqDir /path/to/raw-data/directory \\\n       -align star \\\n       -refFiles /path/to/refDir \\\n       -counts \\\n       -metrics \\\n       -threads 10\n\n\n\n\nData set for testing\n\n\n\n\nN.B \nRNAsik\n pipeline is some what resource hungry. This isn't \nRNAsik\n fault per say, because it \"simply\" wraps other tools. STAR aligner required fair amount of RAM and cpus. For a large genome like mouse it required around 30 Gb of RAM and the more cpus you have the quicker you'll map. I would advise not run the pipeline with less than 4 cores, which is default. This testing data set is of yeast and requires about 14 Gb of RAM.\n\n\n\n\nI figured that for testing you need smallish data set as well as species with a smalling genome, as indexing of genome takes a while for larger genome e.g mouse\nI found this study \nGSE103004\n which looks like an open access. If you follow \nthat link\n you should hit front GEO page for that study. You can find your way to actual data (SRA files) files, but I always find it's a bit convoluted, so hit \nhere is a link to data files\n. \n\n\nI've already prepared raw-data (fastq) files for you. I also reduced number of samples and sub-sampled reads to speed up your test run. Firstly though let me explain to you how to get full data set.\n\n\n\n\n\n\ndownload sratoolkit\n which is set of tools from \nNCBI\n that you'll need to download \nsra files\n and then extract/convert those to fastq files.\n\n\n\n\n\n\nfastq-dump --gzip --split-files SRR3407195\n this is a command that you'll want to run to get one particular sra file, not \n--split-files\n options, you need to use that if you data is paired end. If you don't use that flag, then you are going to end up with a single fastq file that has reads interleaved or truncated/merged in a funny way (had some issues like that in the past)\n\n\n\n\n\n\nHowever you don't want run that command several times, so use a loop\n\n\nwhile read s; do fastq-dump --gzip --split-files $s \n $s.log 2\n1 \ndone \n SRR_Acc_List.txt\n\n\n\n\nYou can download \nSRR_Acc_List.txt file at this page\n (mentioned that page before). That list has 9 sra files corresponding to 9 samples, where each samples was paired end and therefore total number of files is double - 18. \n\n\nAlso note that default marking when extracting from sra for R1 and R2 is \n_1\n and \n_2\n respectively and so if you are running \nRNAsik\n on that full data set you'll need to pass \n-pairIds \"_1,_2\"\n flag, default is \n-pairIds \"_R1,_R2\"\n \n\n\nIf you want nicely labeled bam and then counts you can pass \n-samplesSheet samplesSheet.txt\n. I haven't implemented url based samples sheets, so you'll need to download one before hand from \nhere\n. I'll include handling of url based samples sheets into roadmap, so watch that space !\n\n\nTry it out\n\n\nRNAsik -align star \\\n       -fastaRef ftp://ftp.ensembl.org/pub/release-91/fasta/saccharomyces_cerevisiae/dna/Saccharomyces_cerevisiae.R64-1-1.dna_sm.toplevel.fa.gz \\\n       -fqDir http://bioinformatics.erc.monash.edu/home/kirill/sikTestData/rawData/IndustrialAntifoamAgentsYeastRNAseqData.tar \\\n       -counts \\\n       -gtfFile ftp://ftp.ensembl.org/pub/release-91/gtf/saccharomyces_cerevisiae/Saccharomyces_cerevisiae.R64-1-1.91.gtf.gz \\\n       -metrics \\\n       -threads 10\n\n\n\n\nIntroduction\n\n\nAs mentioned previously in \nabout section\n very first step in \nRNA-seq analysis\n is to map your raw reads (\nFASTQ\n) to the reference genome following by counting of reads that map onto a feature. But there is always more you could do with your data, in fact almost always only by doing more you can get deeper inside into your biological experiment and the system you are studying. And so \nRNAsik\n uses these tools to get as much out of your data as possible in an streamline run:\n\n\n\n\nSTAR aligner for mapping\n\n\nfeatureCounts from subread package for read counting\n\n\nsamtools for coverage calculation and general bam files filtering\n\n\npicard tools also for general bam fiels filtering\n\n\nQualiMap for intragenic and interegenic rates\n\n\nFastQC for QC metrics on yor fastq files\n\n\nMultiQC for wraping everying into nice, single page report\n \n\n\n\n\nAs one can imagine every one of those tools has several number of options and by running \nRNAsik-pipeline\n you get predefined - subjective run. Obviously it all comes from years of experience and continues development and improvement. Use can always pass his/her own options through \n-extraOptions\n flag for more fine turning. \nAlternatively as, hinted above, user can leverage of \nRNAsik\n to run everything separately with fine control over the individual run. \nRNAsik\n produces \n.html report\n with all commands options specified.\n\n\nPrerequisites\n\n\n\n\nBigDataScript\n\n\nSTAR aligner\n\n\nsubread\n\n\nsamtools\n\n\nbedtools2\n\n\nPicard tools\n\n\nQualiMap\n\n\nMultiQC\n \n\n\nFastQC\n\n\n\n\nInstallation\n\n\nPreferred method\n\n\nFollow \nansible installation guid\n to get ansible then:\n\n\ngit clone https://github.com/MonashBioinformaticsPlatform/bio-ansible\ncd bio-ansible/\nansible-playbook -i host bio.yml --tags bds,rnasik,star,subread,samtools,htslib,bedtools,picard,qualimap,fastqc,multiqc\n\n\n\n\nNeed more help?\n\n\nAlternative method\n\n\nIf you have all of the tools installed and you just need \nRNAsik\n you can simply \ngit clone\n it. It doesn't require any\nother installations/compilations. BUT you do need to have \nBigDataScript\n installed\nand have it in your \nPATH\n for \nRNAsik\n to run\n\n\ngit clone https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe\npath/to/RNAsik-pipe/bin/RNAsik\n\n\n\n\nUser input\n\n\nReference files\n\n\n\n\nInput File\nDescription\n\n\nFASTA file\nMost often this is your genomic reference sequence. It is a FASTA file holding raw DNA sequences where different features e.g chromosomes are labeled uniquely with a header line starting with '>'. [FASTA Format Description](https://en.wikipedia.org/wiki/FASTA_format) \n\n\nGTF/GFF/SAF file\n This is your gene annotation file (i.e coordinates of your genes, exons and other genomic features). This should be linked and associated with your genomic reference file. SAF (simple annotation format) is something that featureCounts use and it supported by the pipeline\n\n\n\n\n\nRaw data\n\n\n\n\nInput File\nDescription\n\n\nFASTQ file\nThese are your raw files that are provided by the sequencing facility to you, they can be gzipped (.fq, .fastq, .fq.gz, .fastq.gz) \n\n\n\n\n\nUser input explained\n\n\nAnnotation files\n\n\nAnnotation file would central for differential expression (DE) analysis without one you won't be able to do one. You could have very well assembled genome with very good mapping rate, but unless you know where your genes are on that genome i.e start and end coordinates for your features e.g genes you won't be able to deduce any information about those features and therefore compare between conditions. Below is an example of bear minimum information you need for feature counting. \n\n\nGeneID  Chr Start   End Strand\n497097  chr1    3204563 3207049 -\n497097  chr1    3411783 3411982 -\n497097  chr1    3660633 3661579 -\n\n\n\n\nThere few entities that provide genome annotation, some cover more species than other. There will be of course individuals that simply provide annotation for one particular species, perhaps for more rare model organisms.\n\n\nThere are also different annotation file formats out there, which makes a little hard to provide \nRNAsik\n support for all of them. Currently \nRNAsik\n can only work with \nGFF\n, \nGTF\n or \nSAF\n file formats. There are many compatibilities issues between formats, but more importantly certain bits of information are only found in some of the files. The example above show \nSAF\n file format and as you can see that includes not human redable gene names nor biotype. \nGFF\n also often doesn't have biotype information, but on the other hand has product tag, which has short description, for protein coding at least, of resulting protein product, \nGTF\n lacks that information. Because of all these little nuances it can be hard to capture all of the desirable information.\n\n\nMost tools in the pipeline prefer \nGTF\n, some can only work with \nGTF\n. I guess main reason for this is that every line is self contained and the format has been fairly predictable/stable.\n\n\nIf for whatever reason you can't get hold of \nGFF/GTF\n files and your annotation comes in \nGenBank\n (very common for bacterial genomes) or \nBed\n files, don't panic and try to parse those files into \nSAF\n format. There are plans to include \ngb_parse.py\n script that should help most people with \nGenBank\n files.\n\n\nIrrespective of which reference file distributor and which annotation file you are going to use, it is highly recommended that both of those files come from the same distributor. Most common distributors are \nEnsembl\n, \nUCSC\n and \nNCBI\n.\n\n\nRaw data files\n\n\nRaw data is something that you should take good care of. You can regenerate all other data files, but you can't really regenerate you raw data, not unless you have lots of money and time. So be sure to back your \nfastq\n files up and never mess/do (i.e modify) your original fastq files. If you want to try something out, make a copy and do whatever you are doing on a copy. Also there will never be a need to unzip your fastq file. All of you fastq file should be gziped and have file extension \n.fastq.gz\n or \nfq.gz\n or something similar. \n\n\nRNAsik\n will search recursively your \n-fqDir\n and find all fastq files. \nRNAsik\n can handle nested directories as long as your data is homogeneous i.e all data belongs to the same library type single-end or paired-end. If data is paired end, \nRNAsik\n uses \n-pairIds\n value to figure out read pairs. You can check that all of your fastq files had been found by looking into \nsikRun/logs/samples/fqFiles\n. \n\n\nAfter obtaining a list of all fastq files \nRNAsik\n tries to be smart and attempts to group fastq files into samples, that is R1 and R2 reads are grouped, but also any fastq files that had been split across lanes should also be grouped. You should end up, after the run, with the same number of bam files as you have samples. Again you can check grouping in \nsikRun/logs/samples/fqMap\n\n\nRNAsik\n fastq grouping works in two modes:\n\n\n\n\nsmart guessing it is a little involved but essentially it uses regular expression to check if fastq files have common suffix and therefore belong to the same sample. It heavily relies on clear labeling of R1 and R2 reads for paired-end data. \n\n\na more straight forward mode is simply to use samples sheet file, which is any text file with two columns separated by a tab character, \nold_prefix\\tnew_prefix\n. Prefix in this case is your sample name, unique bit of the file. \n\n\n\n\nSamples sheet in a bit more details; If you have four samples, two wild-type and two controls, you should have four bam files after the analysis. However you number of fastq files is rather variable, depending on your sequencing. For paired-end sequencing you are going to end up with 2 fastq files per sample and 8 fastq files all up. If your sequencing was also split across lanes, say two lanes, then you are going to have 4 fastq file per each samples and 16 fastq files in total. \nRNAsik\n tries to simplify this for you.\n\n\nRNAsik output\n\n\nDirectories breakdown\n\n\n\n\nDirectories\nDescription\n\n\nrefFiles/\n Contains the reference files (FASTA and GTF) and indices (aligner index) used in the analysis run \n\n\nbamFiles/\n Contains \"raw\" BAM files, outputed from an aligner. Also may hold additional files from alignment run e.g aligner specific log files \n\n\ncountFiles/\n Contains read count files, \"raw\" - from `featureCounts`, degust ready counts and filtered for protein_coding features only\n\n\ncoverageFiles/\n Contains bigWig files for every bam (sample) file - from `bedtools genomecov` and `bedGrapToBigWig` USCS binary. Can load those into IGV\n\n\nmarkedBams/\n Contains pre-processed BAM files, these BAMs are sorted, reordered and duplicates marked as well as indexed, all using picard tools. These BAMs can be used in [IGV](http://software.broadinstitute.org/software/igv/) to view read alignments \n\n\nfastqReport/\n Contains FastQC HTML reports for individual FASTQ files\n\n\nqualiMapResults/\n Contains int(ra|er)genic rates from each BAM file. Each BAM has its own directory with metric files. These results generated using `QualiMap rnaseq` command\n\n\nfastqDir/\n If you are going to pull your FASTQ file over http in tarball, then tarball will be unarchived here\n\n\nmultiqc_data/\nDirectory created by MultiQC holding a parsed text file, it doesn't serve any purpose for html file\n\n\nlogs/\nDirectory that holds subdirectories, self explanatory, with logs files\n\n\n\n\n\nFiles breakdown\n\n\n\n\nFiles\nDescription\n\n\ngeneIds.txt\n Hold four additional columns that get added into read counts file, that has postfix \"-withNames. Gene.id, Chrom, Gene.Name, Biotype.\n\n\nstrandInfo.txt\n Contains guesses, based on `featureCounts` `.summary` files, strand informataion\n\n\nmultiqc_report.html\nThis is the report file produced by MultiQC tool. A stand alone html file and can be viewed in any browser\n\n\n\n\n\nRNAsik output explained\n\n\n\n\nI hope that the directories and files naming is some what self explanatory, but here is a bit more detailed explanation of those.\n\n\n\n\nBam files\n\n\nFirst thing you most certainly going to get out of the pipeline is your bam files, those will be placed into \nbamFiles/\n directory. I don't really understand why, but \nfeatureCounts\n works best (fastest) with name sorted BAM files a.k.a unsorted. There is really two types of sorting, sorted by coordinates, often preferred as you can index those bam files and then have quick access to random parts of the file, second type is sorted by name, which insures that in paired-end experiment R1 and R2 pairs are interleaved, one after another, but you can't index those). \nSTAR\n aligner can output either of those files. I'm however outputting \"unsorted\" bam file and then in the second step sorting it with \npicard SamSort\n tool. There are a couple of reasons for that:\n\n\n\n\nother aligners don't sort e.g bwa and therefore assuming sorted bam file won't work well\n\n\neven though \nSTAR\n is pretty amazing (honestly), but I still rather prefer one tool for one job,\nhence why I also don't count reads with \nSTAR\n\n\n\n\nThe bam files from \nbamFiles/\n are only used with \nfeatureCounts\n and then \npicard\n suite converts them into sorted and marked duplicate bam files, which are now placed into \nmdupsFiles/\n directory. The rest of the analysis based on these bam files. I'm still deciding what to do with \"raw\" bam files in \nbamFiles/\n directory. They should be removed after run have finished, but if you have to re-run the pipeline to get additional things (which you can, it will resolve all dependencies and only run new tasks) those bams are now gone and will get regenerated, which will trigger the rest of pipeline to re-run, which is unwanted result. This is why I'm not auto-removing those bam files, rather doing manually after I'm sure.  \n\n\nCount files\n\n\nProbably the second most important thing in the pipeline is getting read counts. That is given some genome annotation count how many of mapped reads actually ended up mapping into know annotation. For classical differential expression analysis we are interested in protein coding genes only, which pipeline attempts to filter for, but there are other biotypes that we can differentially compare.\n\n\nThe pipeline attempts to guess the strand (directionality) of your library. In theory sequencing provider that had made your libraries should be able to tell you that, but sometimes they get it wrong or simply that information never reaches us (bioinformaticians) hence the guessing.\n\n\nPipelines runs \nfeatureCounts\n three times forcing reads to forward strand only, forcing to reverse strand only and allowing counting on both strand (non stranded library). \nfeatureCounts\n is very nice and it provides summary table that has number of assigned to feature reads. One can simply compare forward and reverse stranded counts and deduce the strand of the library. In essence this formula is used \nforward-reverse/forward+reverse\n to obtain the ration, if ration is about 0.9 then library is stranded and sign indicates the strand type, if however ration is about 0.1 then library is non stranded, anything else will indication undetermined and \nstrandInfo.txt\n file with default to \nNonStranded,1\n note the number one after the comment indicating status code, meaning exit with error. If you see that in your \nstrandInfo.txt\n file you'll need to manually inspect your \n*.summary\n files from \nfeatureCounts\n and make decision about which library type to go with. Actual implementation of strand guessing can be found in this script \nscripts/strand_guessing.py\n.\n\n\nfeatureCounts\n by default for any given run outputs two files, counts (e.g \nNonStrandedCounts.txt\n) and summary (e.g \nNonStrandedCounts.txt.summary\n). \nRNAsik\n attempts to \"clean up\" counts file, which includes removing and addition of certain columns to make counts files more informative. The columns that are added can be found in \ngeneIds.txt\n. If for what ever reason your \ngeneIds.txt\n is empty then all the other files with postfix \n-withNames\n going to be empty too. You could try to regenerate \ngeneIds.txt\n file using \nscripts/get_gene_ids.py\n script and then \nscripts/mk_counts_file.py\n to obtain \"clean\" table of counts. Doing so isn't strictly needed however additional information such as human understandable gene name and biotypy often come very handy in understanding differential expression. Having a biotype in counts file also allows you to filter for specific biotype e.g \nprotein_coding\n or \nsnRNA\n provided your annotation file has that information.\n\n\nCommand line options\n\n\nRead alignment\n\n\n\n\nOptions\nUsage\n\n\n-align\nspecify your aligner of choice [star|starWithAnn|hisat|bwa]\n\n\n-fqDir\nspecify path to your raw data directory. `RNAsik` will search that path recursively, so don't worry about nested directores\n\n\n-fastaRef\nspecify path to your reference FASTA file, i.e file that holds your refrence genome\n\n\n-paired\nspecify if data is paired end (RNASik looks for R1 and R2 in the FASTQ filename representing Read 1 and Read 2 \n\n\n\n\n\nRead counting\n\n\n\n\nOptions\n Usage \n\n\n-counts\n \n flag if you'd like to get read counts\n\n\n-gtfFile\n \n specify path to your reference annotation file [GTF|GFF|SAF]\n\n\n\n\n\nReads metrics\n\n\n\n\nOptions\n Usage \n\n\n-metrics\n \n This is an aggregate flag that is a short hand of writing out -prePro, -fastqc, -exonicRate and -multiqc\n\n\n-fastqc\n \n flag if you'd like to get FastQC reports for your fastq files\n\n\n-exonicRate\n \n flag if you'd like to get Int(ra|er)genic rates for your reads, using QualiMap tool\n\n\n-multiqc\n \n flag if you'd like to get general report that summarises different log files including `STAR`, `featureCounts`, `FastQC` and `QualiMap`\n\n\n\n\n\nExtra options\n\n\n\n\nOptions\n Usage \n\n\n-prePro\n \n flag to get your BAM files pre-processed i.e get them sorted, duplicates marked and index\n\n\n-samplesSheet\n \n specify name of a tab separated text file, two columns,the first with old prefixes to be removed by new prefixes in the second column\n\n\n-genomeIdx\n \n specify path to pre-existing alignment index \n\n\n-outDir\ngive a name to your analysis output directory [sikRun] \n\n\n-extn\n \n provide your fastq files extntion. [\".fastq.gz\"]  \n\n\n-pairIds\n \n provide type identification, default is [`_R1,_R2`]\n\n\n-threads\n \n provide number of threads to use. [4]  \n\n\n-memory\n \n provide amount of memory to use. [40000000000]  \n\n\n-extraOpts\n \n provide key=value pairs, one per line, with key being tool name and value is a string of options e.g `star=\"--outWigType bedGraph\"` \n\n\n-configFile\nspecify your own config file with key=value pairs, one per line, for all tools\n\n\n\n\n\nUnusual user case\n\n\n\n\n-bamsDir\n \n specify path to BAMs directory. Use if bams were generated outside of the pipeline \n\n\n\n\n\nTweet to @kizza_a\n \n\n\n\n\n\n\nShare", 
            "title": "Docs"
        }, 
        {
            "location": "/docs/#documentation", 
            "text": "", 
            "title": "Documentation"
        }, 
        {
            "location": "/docs/#quick-start", 
            "text": "", 
            "title": "Quick start"
        }, 
        {
            "location": "/docs/#align-raw-reads", 
            "text": "RNAsik -align star \\\n       -fastaRef /path/to/reference.fasta \\\n       -fqDir /path/to/raw-data/directory", 
            "title": "Align raw reads"
        }, 
        {
            "location": "/docs/#count-gene-features", 
            "text": "RNAsik -counts \\\n       -gtfFile path/to/annotation.gtf", 
            "title": "Count gene features"
        }, 
        {
            "location": "/docs/#the-lot", 
            "text": "RNAsik -fqDir /path/to/raw-data/directory \\\n       -align star \\\n       -refFiles /path/to/refDir \\\n       -counts \\\n       -metrics \\\n       -threads 10", 
            "title": "The lot"
        }, 
        {
            "location": "/docs/#data-set-for-testing", 
            "text": "N.B  RNAsik  pipeline is some what resource hungry. This isn't  RNAsik  fault per say, because it \"simply\" wraps other tools. STAR aligner required fair amount of RAM and cpus. For a large genome like mouse it required around 30 Gb of RAM and the more cpus you have the quicker you'll map. I would advise not run the pipeline with less than 4 cores, which is default. This testing data set is of yeast and requires about 14 Gb of RAM.   I figured that for testing you need smallish data set as well as species with a smalling genome, as indexing of genome takes a while for larger genome e.g mouse\nI found this study  GSE103004  which looks like an open access. If you follow  that link  you should hit front GEO page for that study. You can find your way to actual data (SRA files) files, but I always find it's a bit convoluted, so hit  here is a link to data files .   I've already prepared raw-data (fastq) files for you. I also reduced number of samples and sub-sampled reads to speed up your test run. Firstly though let me explain to you how to get full data set.    download sratoolkit  which is set of tools from  NCBI  that you'll need to download  sra files  and then extract/convert those to fastq files.    fastq-dump --gzip --split-files SRR3407195  this is a command that you'll want to run to get one particular sra file, not  --split-files  options, you need to use that if you data is paired end. If you don't use that flag, then you are going to end up with a single fastq file that has reads interleaved or truncated/merged in a funny way (had some issues like that in the past)    However you don't want run that command several times, so use a loop  while read s; do fastq-dump --gzip --split-files $s   $s.log 2 1  done   SRR_Acc_List.txt  You can download  SRR_Acc_List.txt file at this page  (mentioned that page before). That list has 9 sra files corresponding to 9 samples, where each samples was paired end and therefore total number of files is double - 18.   Also note that default marking when extracting from sra for R1 and R2 is  _1  and  _2  respectively and so if you are running  RNAsik  on that full data set you'll need to pass  -pairIds \"_1,_2\"  flag, default is  -pairIds \"_R1,_R2\"    If you want nicely labeled bam and then counts you can pass  -samplesSheet samplesSheet.txt . I haven't implemented url based samples sheets, so you'll need to download one before hand from  here . I'll include handling of url based samples sheets into roadmap, so watch that space !", 
            "title": "Data set for testing"
        }, 
        {
            "location": "/docs/#try-it-out", 
            "text": "RNAsik -align star \\\n       -fastaRef ftp://ftp.ensembl.org/pub/release-91/fasta/saccharomyces_cerevisiae/dna/Saccharomyces_cerevisiae.R64-1-1.dna_sm.toplevel.fa.gz \\\n       -fqDir http://bioinformatics.erc.monash.edu/home/kirill/sikTestData/rawData/IndustrialAntifoamAgentsYeastRNAseqData.tar \\\n       -counts \\\n       -gtfFile ftp://ftp.ensembl.org/pub/release-91/gtf/saccharomyces_cerevisiae/Saccharomyces_cerevisiae.R64-1-1.91.gtf.gz \\\n       -metrics \\\n       -threads 10", 
            "title": "Try it out"
        }, 
        {
            "location": "/docs/#introduction", 
            "text": "As mentioned previously in  about section  very first step in  RNA-seq analysis  is to map your raw reads ( FASTQ ) to the reference genome following by counting of reads that map onto a feature. But there is always more you could do with your data, in fact almost always only by doing more you can get deeper inside into your biological experiment and the system you are studying. And so  RNAsik  uses these tools to get as much out of your data as possible in an streamline run:   STAR aligner for mapping  featureCounts from subread package for read counting  samtools for coverage calculation and general bam files filtering  picard tools also for general bam fiels filtering  QualiMap for intragenic and interegenic rates  FastQC for QC metrics on yor fastq files  MultiQC for wraping everying into nice, single page report     As one can imagine every one of those tools has several number of options and by running  RNAsik-pipeline  you get predefined - subjective run. Obviously it all comes from years of experience and continues development and improvement. Use can always pass his/her own options through  -extraOptions  flag for more fine turning. \nAlternatively as, hinted above, user can leverage of  RNAsik  to run everything separately with fine control over the individual run.  RNAsik  produces  .html report  with all commands options specified.", 
            "title": "Introduction"
        }, 
        {
            "location": "/docs/#prerequisites", 
            "text": "BigDataScript  STAR aligner  subread  samtools  bedtools2  Picard tools  QualiMap  MultiQC    FastQC", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/docs/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/docs/#preferred-method", 
            "text": "Follow  ansible installation guid  to get ansible then:  git clone https://github.com/MonashBioinformaticsPlatform/bio-ansible\ncd bio-ansible/\nansible-playbook -i host bio.yml --tags bds,rnasik,star,subread,samtools,htslib,bedtools,picard,qualimap,fastqc,multiqc  Need more help?", 
            "title": "Preferred method"
        }, 
        {
            "location": "/docs/#alternative-method", 
            "text": "If you have all of the tools installed and you just need  RNAsik  you can simply  git clone  it. It doesn't require any\nother installations/compilations. BUT you do need to have  BigDataScript  installed\nand have it in your  PATH  for  RNAsik  to run  git clone https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe\npath/to/RNAsik-pipe/bin/RNAsik", 
            "title": "Alternative method"
        }, 
        {
            "location": "/docs/#user-input", 
            "text": "", 
            "title": "User input"
        }, 
        {
            "location": "/docs/#reference-files", 
            "text": "Input File Description  FASTA file Most often this is your genomic reference sequence. It is a FASTA file holding raw DNA sequences where different features e.g chromosomes are labeled uniquely with a header line starting with '>'. [FASTA Format Description](https://en.wikipedia.org/wiki/FASTA_format)   GTF/GFF/SAF file  This is your gene annotation file (i.e coordinates of your genes, exons and other genomic features). This should be linked and associated with your genomic reference file. SAF (simple annotation format) is something that featureCounts use and it supported by the pipeline", 
            "title": "Reference files"
        }, 
        {
            "location": "/docs/#raw-data", 
            "text": "Input File Description  FASTQ file These are your raw files that are provided by the sequencing facility to you, they can be gzipped (.fq, .fastq, .fq.gz, .fastq.gz)", 
            "title": "Raw data"
        }, 
        {
            "location": "/docs/#user-input-explained", 
            "text": "", 
            "title": "User input explained"
        }, 
        {
            "location": "/docs/#annotation-files", 
            "text": "Annotation file would central for differential expression (DE) analysis without one you won't be able to do one. You could have very well assembled genome with very good mapping rate, but unless you know where your genes are on that genome i.e start and end coordinates for your features e.g genes you won't be able to deduce any information about those features and therefore compare between conditions. Below is an example of bear minimum information you need for feature counting.   GeneID  Chr Start   End Strand\n497097  chr1    3204563 3207049 -\n497097  chr1    3411783 3411982 -\n497097  chr1    3660633 3661579 -  There few entities that provide genome annotation, some cover more species than other. There will be of course individuals that simply provide annotation for one particular species, perhaps for more rare model organisms.  There are also different annotation file formats out there, which makes a little hard to provide  RNAsik  support for all of them. Currently  RNAsik  can only work with  GFF ,  GTF  or  SAF  file formats. There are many compatibilities issues between formats, but more importantly certain bits of information are only found in some of the files. The example above show  SAF  file format and as you can see that includes not human redable gene names nor biotype.  GFF  also often doesn't have biotype information, but on the other hand has product tag, which has short description, for protein coding at least, of resulting protein product,  GTF  lacks that information. Because of all these little nuances it can be hard to capture all of the desirable information.  Most tools in the pipeline prefer  GTF , some can only work with  GTF . I guess main reason for this is that every line is self contained and the format has been fairly predictable/stable.  If for whatever reason you can't get hold of  GFF/GTF  files and your annotation comes in  GenBank  (very common for bacterial genomes) or  Bed  files, don't panic and try to parse those files into  SAF  format. There are plans to include  gb_parse.py  script that should help most people with  GenBank  files.  Irrespective of which reference file distributor and which annotation file you are going to use, it is highly recommended that both of those files come from the same distributor. Most common distributors are  Ensembl ,  UCSC  and  NCBI .", 
            "title": "Annotation files"
        }, 
        {
            "location": "/docs/#raw-data-files", 
            "text": "Raw data is something that you should take good care of. You can regenerate all other data files, but you can't really regenerate you raw data, not unless you have lots of money and time. So be sure to back your  fastq  files up and never mess/do (i.e modify) your original fastq files. If you want to try something out, make a copy and do whatever you are doing on a copy. Also there will never be a need to unzip your fastq file. All of you fastq file should be gziped and have file extension  .fastq.gz  or  fq.gz  or something similar.   RNAsik  will search recursively your  -fqDir  and find all fastq files.  RNAsik  can handle nested directories as long as your data is homogeneous i.e all data belongs to the same library type single-end or paired-end. If data is paired end,  RNAsik  uses  -pairIds  value to figure out read pairs. You can check that all of your fastq files had been found by looking into  sikRun/logs/samples/fqFiles .   After obtaining a list of all fastq files  RNAsik  tries to be smart and attempts to group fastq files into samples, that is R1 and R2 reads are grouped, but also any fastq files that had been split across lanes should also be grouped. You should end up, after the run, with the same number of bam files as you have samples. Again you can check grouping in  sikRun/logs/samples/fqMap  RNAsik  fastq grouping works in two modes:   smart guessing it is a little involved but essentially it uses regular expression to check if fastq files have common suffix and therefore belong to the same sample. It heavily relies on clear labeling of R1 and R2 reads for paired-end data.   a more straight forward mode is simply to use samples sheet file, which is any text file with two columns separated by a tab character,  old_prefix\\tnew_prefix . Prefix in this case is your sample name, unique bit of the file.    Samples sheet in a bit more details; If you have four samples, two wild-type and two controls, you should have four bam files after the analysis. However you number of fastq files is rather variable, depending on your sequencing. For paired-end sequencing you are going to end up with 2 fastq files per sample and 8 fastq files all up. If your sequencing was also split across lanes, say two lanes, then you are going to have 4 fastq file per each samples and 16 fastq files in total.  RNAsik  tries to simplify this for you.", 
            "title": "Raw data files"
        }, 
        {
            "location": "/docs/#rnasik-output", 
            "text": "", 
            "title": "RNAsik output"
        }, 
        {
            "location": "/docs/#directories-breakdown", 
            "text": "Directories Description  refFiles/  Contains the reference files (FASTA and GTF) and indices (aligner index) used in the analysis run   bamFiles/  Contains \"raw\" BAM files, outputed from an aligner. Also may hold additional files from alignment run e.g aligner specific log files   countFiles/  Contains read count files, \"raw\" - from `featureCounts`, degust ready counts and filtered for protein_coding features only  coverageFiles/  Contains bigWig files for every bam (sample) file - from `bedtools genomecov` and `bedGrapToBigWig` USCS binary. Can load those into IGV  markedBams/  Contains pre-processed BAM files, these BAMs are sorted, reordered and duplicates marked as well as indexed, all using picard tools. These BAMs can be used in [IGV](http://software.broadinstitute.org/software/igv/) to view read alignments   fastqReport/  Contains FastQC HTML reports for individual FASTQ files  qualiMapResults/  Contains int(ra|er)genic rates from each BAM file. Each BAM has its own directory with metric files. These results generated using `QualiMap rnaseq` command  fastqDir/  If you are going to pull your FASTQ file over http in tarball, then tarball will be unarchived here  multiqc_data/ Directory created by MultiQC holding a parsed text file, it doesn't serve any purpose for html file  logs/ Directory that holds subdirectories, self explanatory, with logs files", 
            "title": "Directories breakdown"
        }, 
        {
            "location": "/docs/#files-breakdown", 
            "text": "Files Description  geneIds.txt  Hold four additional columns that get added into read counts file, that has postfix \"-withNames. Gene.id, Chrom, Gene.Name, Biotype.  strandInfo.txt  Contains guesses, based on `featureCounts` `.summary` files, strand informataion  multiqc_report.html This is the report file produced by MultiQC tool. A stand alone html file and can be viewed in any browser", 
            "title": "Files breakdown"
        }, 
        {
            "location": "/docs/#rnasik-output-explained", 
            "text": "I hope that the directories and files naming is some what self explanatory, but here is a bit more detailed explanation of those.", 
            "title": "RNAsik output explained"
        }, 
        {
            "location": "/docs/#bam-files", 
            "text": "First thing you most certainly going to get out of the pipeline is your bam files, those will be placed into  bamFiles/  directory. I don't really understand why, but  featureCounts  works best (fastest) with name sorted BAM files a.k.a unsorted. There is really two types of sorting, sorted by coordinates, often preferred as you can index those bam files and then have quick access to random parts of the file, second type is sorted by name, which insures that in paired-end experiment R1 and R2 pairs are interleaved, one after another, but you can't index those).  STAR  aligner can output either of those files. I'm however outputting \"unsorted\" bam file and then in the second step sorting it with  picard SamSort  tool. There are a couple of reasons for that:   other aligners don't sort e.g bwa and therefore assuming sorted bam file won't work well  even though  STAR  is pretty amazing (honestly), but I still rather prefer one tool for one job,\nhence why I also don't count reads with  STAR   The bam files from  bamFiles/  are only used with  featureCounts  and then  picard  suite converts them into sorted and marked duplicate bam files, which are now placed into  mdupsFiles/  directory. The rest of the analysis based on these bam files. I'm still deciding what to do with \"raw\" bam files in  bamFiles/  directory. They should be removed after run have finished, but if you have to re-run the pipeline to get additional things (which you can, it will resolve all dependencies and only run new tasks) those bams are now gone and will get regenerated, which will trigger the rest of pipeline to re-run, which is unwanted result. This is why I'm not auto-removing those bam files, rather doing manually after I'm sure.", 
            "title": "Bam files"
        }, 
        {
            "location": "/docs/#count-files", 
            "text": "Probably the second most important thing in the pipeline is getting read counts. That is given some genome annotation count how many of mapped reads actually ended up mapping into know annotation. For classical differential expression analysis we are interested in protein coding genes only, which pipeline attempts to filter for, but there are other biotypes that we can differentially compare.  The pipeline attempts to guess the strand (directionality) of your library. In theory sequencing provider that had made your libraries should be able to tell you that, but sometimes they get it wrong or simply that information never reaches us (bioinformaticians) hence the guessing.  Pipelines runs  featureCounts  three times forcing reads to forward strand only, forcing to reverse strand only and allowing counting on both strand (non stranded library).  featureCounts  is very nice and it provides summary table that has number of assigned to feature reads. One can simply compare forward and reverse stranded counts and deduce the strand of the library. In essence this formula is used  forward-reverse/forward+reverse  to obtain the ration, if ration is about 0.9 then library is stranded and sign indicates the strand type, if however ration is about 0.1 then library is non stranded, anything else will indication undetermined and  strandInfo.txt  file with default to  NonStranded,1  note the number one after the comment indicating status code, meaning exit with error. If you see that in your  strandInfo.txt  file you'll need to manually inspect your  *.summary  files from  featureCounts  and make decision about which library type to go with. Actual implementation of strand guessing can be found in this script  scripts/strand_guessing.py .  featureCounts  by default for any given run outputs two files, counts (e.g  NonStrandedCounts.txt ) and summary (e.g  NonStrandedCounts.txt.summary ).  RNAsik  attempts to \"clean up\" counts file, which includes removing and addition of certain columns to make counts files more informative. The columns that are added can be found in  geneIds.txt . If for what ever reason your  geneIds.txt  is empty then all the other files with postfix  -withNames  going to be empty too. You could try to regenerate  geneIds.txt  file using  scripts/get_gene_ids.py  script and then  scripts/mk_counts_file.py  to obtain \"clean\" table of counts. Doing so isn't strictly needed however additional information such as human understandable gene name and biotypy often come very handy in understanding differential expression. Having a biotype in counts file also allows you to filter for specific biotype e.g  protein_coding  or  snRNA  provided your annotation file has that information.", 
            "title": "Count files"
        }, 
        {
            "location": "/docs/#command-line-options", 
            "text": "", 
            "title": "Command line options"
        }, 
        {
            "location": "/docs/#read-alignment", 
            "text": "Options Usage  -align specify your aligner of choice [star|starWithAnn|hisat|bwa]  -fqDir specify path to your raw data directory. `RNAsik` will search that path recursively, so don't worry about nested directores  -fastaRef specify path to your reference FASTA file, i.e file that holds your refrence genome  -paired specify if data is paired end (RNASik looks for R1 and R2 in the FASTQ filename representing Read 1 and Read 2", 
            "title": "Read alignment"
        }, 
        {
            "location": "/docs/#read-counting", 
            "text": "Options  Usage   -counts    flag if you'd like to get read counts  -gtfFile    specify path to your reference annotation file [GTF|GFF|SAF]", 
            "title": "Read counting"
        }, 
        {
            "location": "/docs/#reads-metrics", 
            "text": "Options  Usage   -metrics    This is an aggregate flag that is a short hand of writing out -prePro, -fastqc, -exonicRate and -multiqc  -fastqc    flag if you'd like to get FastQC reports for your fastq files  -exonicRate    flag if you'd like to get Int(ra|er)genic rates for your reads, using QualiMap tool  -multiqc    flag if you'd like to get general report that summarises different log files including `STAR`, `featureCounts`, `FastQC` and `QualiMap`", 
            "title": "Reads metrics"
        }, 
        {
            "location": "/docs/#extra-options", 
            "text": "Options  Usage   -prePro    flag to get your BAM files pre-processed i.e get them sorted, duplicates marked and index  -samplesSheet    specify name of a tab separated text file, two columns,the first with old prefixes to be removed by new prefixes in the second column  -genomeIdx    specify path to pre-existing alignment index   -outDir give a name to your analysis output directory [sikRun]   -extn    provide your fastq files extntion. [\".fastq.gz\"]    -pairIds    provide type identification, default is [`_R1,_R2`]  -threads    provide number of threads to use. [4]    -memory    provide amount of memory to use. [40000000000]    -extraOpts    provide key=value pairs, one per line, with key being tool name and value is a string of options e.g `star=\"--outWigType bedGraph\"`   -configFile specify your own config file with key=value pairs, one per line, for all tools", 
            "title": "Extra options"
        }, 
        {
            "location": "/docs/#unusual-user-case", 
            "text": "-bamsDir    specify path to BAMs directory. Use if bams were generated outside of the pipeline    Tweet to @kizza_a     \nShare", 
            "title": "Unusual user case"
        }, 
        {
            "location": "/help/", 
            "text": "RNAsik? yep!\n\n\nGetting help\n\n\nThere is an open \nRNAsik user's google group\n any can ask and answer\nquestions there. I will try my best to respond to any questions there, but bear in mind that I could get saturated with work\nand might not be able to respond straight away.\n\n\nAlso couple of house keeping things:\n\n\n\n\nbe polite (in general) and considerate of others.\n\n\nInclude as much information about your problem as you can.\nThe problem needs to be reproducible, otherwise I might not be able to help you.\n\n\n\n\np.s any feedback and suggestions are also welcomed there\n\n\nBug reports\n\n\nBest place to submit bugs is with \nGitHub issues\n\nTry to include as much information as you can and again problem needs to be reproducible. Sometimes problem could be \nBigDataScript specific so also try looking at \nBigDataScrip user's group", 
            "title": "Help"
        }, 
        {
            "location": "/help/#rnasik-yep", 
            "text": "", 
            "title": "RNAsik? yep!"
        }, 
        {
            "location": "/help/#getting-help", 
            "text": "There is an open  RNAsik user's google group  any can ask and answer\nquestions there. I will try my best to respond to any questions there, but bear in mind that I could get saturated with work\nand might not be able to respond straight away.  Also couple of house keeping things:   be polite (in general) and considerate of others.  Include as much information about your problem as you can.\nThe problem needs to be reproducible, otherwise I might not be able to help you.   p.s any feedback and suggestions are also welcomed there", 
            "title": "Getting help"
        }, 
        {
            "location": "/help/#bug-reports", 
            "text": "Best place to submit bugs is with  GitHub issues \nTry to include as much information as you can and again problem needs to be reproducible. Sometimes problem could be \nBigDataScript specific so also try looking at  BigDataScrip user's group", 
            "title": "Bug reports"
        }, 
        {
            "location": "/contrib/", 
            "text": "Contributing\n\n\nThere are many places for contribution the most obvious ones are help with documentations, help in the \nuser's group\n\nand of course with the source itself.\n\n\nDocumentations\n\n\nI'm using \nmkdocs\n to generate this site, which has been very easy to use.\nAll documentations are written in plain markdown and located in main repo \ndocs/\n directory\n. You can simply fork \nRNAsik\n repository, do appropriate changes to the docs and send me a pull request (PR). Any small changes are super welcomed, even one letter spell correction (there'll be more than one), but all changes need to come through PR, which will not only acknowledge you as contributor, but also enable me to review changes quickly and incorporate them in (pull them in) easily.\n\n\nQuick notes on \nmkdocs\n, it is pretty easy to install with \npip\n in \nvirtualenv\n if you prefer (you should).\n\n\ngit clone https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe\ncd RNAsik-pipe\nmkdocs serve\n\n\n\n\nThis will give you live updates to you copy of the docs, default URL should be \nlocalhost:8000\n, but it will tell you that once you've started the server. Then simply use your favourite text editor to edit markdown documents. Commit your changes, don't be afraid to be verbose, say what you've added/changed/removed in your commit message. And send me PR\n\n\nUser's group\n\n\nJust jump in and do it!\n\n\nDeveloping pipeline further\n\n\nI need to write a more comprehensive developer guide at sometime soon. Any contributions are again extremely welcomed and again as I've mentioned in the \ndocumentations\n section above, any contributions need to come through pull request (PR). \n\n\nTo summarise briefly layouts of the \nsrc/\n:\n\n\n\n\nRNAsik.bds\n is main \"executable\" file that sources and runs the pipeline. \n\n\nsikHeader.bds\n defines help menu and all user inputs options. I do have a couple of command line \narguments hidden from main help menu, but if you take a pick at this file you'll see them all\n\n\nAll other \n*.bds\n files contain functions to specific tasks those functions get called in \nRNAsik.bds\n\n\n\n\nTweet to @kizza_a\n \n\n\n\n\n\n\nShare", 
            "title": "Contributing"
        }, 
        {
            "location": "/contrib/#contributing", 
            "text": "There are many places for contribution the most obvious ones are help with documentations, help in the  user's group \nand of course with the source itself.", 
            "title": "Contributing"
        }, 
        {
            "location": "/contrib/#documentations", 
            "text": "I'm using  mkdocs  to generate this site, which has been very easy to use.\nAll documentations are written in plain markdown and located in main repo  docs/  directory . You can simply fork  RNAsik  repository, do appropriate changes to the docs and send me a pull request (PR). Any small changes are super welcomed, even one letter spell correction (there'll be more than one), but all changes need to come through PR, which will not only acknowledge you as contributor, but also enable me to review changes quickly and incorporate them in (pull them in) easily.  Quick notes on  mkdocs , it is pretty easy to install with  pip  in  virtualenv  if you prefer (you should).  git clone https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe\ncd RNAsik-pipe\nmkdocs serve  This will give you live updates to you copy of the docs, default URL should be  localhost:8000 , but it will tell you that once you've started the server. Then simply use your favourite text editor to edit markdown documents. Commit your changes, don't be afraid to be verbose, say what you've added/changed/removed in your commit message. And send me PR", 
            "title": "Documentations"
        }, 
        {
            "location": "/contrib/#users-group", 
            "text": "Just jump in and do it!", 
            "title": "User's group"
        }, 
        {
            "location": "/contrib/#developing-pipeline-further", 
            "text": "I need to write a more comprehensive developer guide at sometime soon. Any contributions are again extremely welcomed and again as I've mentioned in the  documentations  section above, any contributions need to come through pull request (PR).   To summarise briefly layouts of the  src/ :   RNAsik.bds  is main \"executable\" file that sources and runs the pipeline.   sikHeader.bds  defines help menu and all user inputs options. I do have a couple of command line \narguments hidden from main help menu, but if you take a pick at this file you'll see them all  All other  *.bds  files contain functions to specific tasks those functions get called in  RNAsik.bds   Tweet to @kizza_a     \nShare", 
            "title": "Developing pipeline further"
        }, 
        {
            "location": "/roadmap/", 
            "text": "Roadmap\n\n\nGoing forward\n\n\n1.4.9 Q1 (January) 2018\n\n\n\n\ngeneral bug fixes and maintenance\n\n\n\n\n1.4.x\n\n\n\n\nneed to have better way to check for index directory, want to know if starIdx includes or doesn't indexing with annotation. \n\n\nrecheck \nStuart's PR\n, polish off refFiles detection\n\n\nrecheck \nthis whole PR\n\n\n\n\n1.4.10 Q1 (February) 2018\n\n\n\n\nimprove \nRNAsik\n logging, particular want to make individual tools version logging independent of each other, so that if one wants to run\njust counts, \nRNAsik\n shouldn't complain about \nbwa\n not found in the PATH. Also double check the behaviour of the logger when pipelines re-runs.\nFrom memory it might not perform as it should. You really want a log of every event that had happened.\n\n\ninclude logging of split lanes and R1 and R2. Want to be able to see from the log whether two reads were classified as split lanes or paired end. This is\nto do with recent bug that got fixed in \nb924027\n \n\n\n\n\n1.4.11 Q1 (February/March) 2018\n\n\n\n\nadd \nsamtools flagstat\n qc run. Definitely need this for bacterial RNAseq i.e when running \nbwa aligner\n, but this metric\nwouldn't hurt in general. It does overlap overall with \nSTAR aligner\n qc output, but going forward other aligners will be\nadded/used but \nsamtools flagstat\n will remain\n\n\nimprove python scripts, make strand_guessing more pythonic, also consider making it python3 friendly as per \nAndrews PR\n,\nalso output ration value as a third value csv value. This is useful number, particular if exit code is 1.\n\n\nDocument python scripts existence, what they do, how to run them manually in the case of failure, and the output they give\n\n\n\n\n1.5.0 Q1 (March) 2018\n\n\nNew feature(s) described below:\n\n\n\n\nimplement new flag \n-fqFiles\n that can take either a file or a directory.\n\n\nif a directory is given, do what \n-fqDir\n does now and traverse down retuning list of fastq files. \n\n\nif a file is given, use those locations getting fastq files. Location can be local file path or URLs, assume one location per line\n\n\n\n\n\n\n\n\nWill keep \n-fqDir\n flag, as a backward compatibility with a warning that flag had been deprecated. Will also schedule to remove \n-fqDir\n completely in future releases\nBecause of changes in arg's options will do a minor version bump.\n\n\n\n\ninclude handling of url based samples sheets, i.e \n-samplesSheet\n flag should handle local based or remote files, just like \n-fastaRef\n option\n\n\n\n\n1.5.1 Q2 (April) 2018\n\n\n\n\ngeneral maintenance and bug fixes\n\n\nstart including unit testing in your master branch, once I'm happy with with \nunit_test\n branch\n\n\n\n\n1.6.0 Q3 (October/November) 2018\n\n\n\n\n\n\nPlans to add variants calling to \nRNAsik\n. It'll be opt in flag,  \n-varsCall\n. Suggestions are welcomed about different name for a flag.\nI already have a prototype in bds, just need to plug it in.\n\n\n\n\nNot sure which caller to use \nGATK\n or \nfreebayes\n will need to do more reading on that. \n\n\nAlso need to document common pitfalls for using RNAseq for variant calling e.g can only can variances in coding regions that are expressed. \n\n\nNot a good idea to use pulled samples as you won't be able to get allele frequency\n\n\nwill also need to find out where to get known SNP's (snpDB? for known germ line mutations) and a list of blacklisted regions\n\n\n\n\n\n\n\n\nan example of someone else variant calling pipeline\n\n\n\n\n\n\nIdeas for future releases\n\n\n\n\ninclude IGVlink into RNAsik-pipe output, can only do that if data outputted into something that is hostable i.e object store?\n\n\nNeed better support for exonic/intronic rates estimation. Is \nread_distribution.py\n from RSeQC good idea? Right now qualiMap is ok flag to opt in.\n\n\nadd alignment free support for RNAseq analysis e.g salmon/kalisto\n\n\nis there need for circular RNA support?\n\n\n\n\nChangelog\n\n\n1.4.9\n\n\n\n\nFixed BWA indexing problem. Problem around STAR and Hisat2 aligners pass index as directory whereas bwa as a file, had to fight to make all different options i.e \n-refFiles\n and \n-genomeIdx\n to work\n\n\nIncluded proper support for SAF file format handled through -gtfFile flag i.e user can pass GTF, GFF or SAF through that flag and will still get counts\n\n\nImporved handling of urls for refrence files \n-fastaRef\n, \n-gtfFile\n now works with all bds supported url types. Also fixed tarball url handling through \n-fqDir\n\n\nImproved code readability in several places and included \ncanFail\n flag for making degust reads counts files.\n\n\nFixed a bug in \nexonicRates\n function was passing \"wrong\" gtf file path\n\n\nUpdated docs, added more explanation on how RNAsik ticks. Included a roadmap to allow better time and features management\n\n\nfixed \n-pairIds\n bug, courtesy @stu2 (PR #6) and samples sheet file making\n\n\nImproved python script, including several small bug fixing\n\n\n\n\n1.4.8\n\n\n\n\nadded new feature: coverage plots generation\n\n\nadded new feature: ability to pass previously generated references directory, saves spaces and time\n\n\nfixed strand guessing script, should be better at guessing now\n\n\nmoved to \nmkdocs\n for documents compilation and deployment to gh_pages\n\n\nadded new python script to make degust file, this simplifies and strengthens the code\n\n\nimproved readability of the code\n\n\nimproved and fixed bugs in handling fastq files and assignment of fastq to sample names\n\n\n\n\n1.4.7\n\n\n\n\nfixed STAR memory allocation issue, now user can run with fewer cpus without a worry for STAR spawning multiple tasks causing out of memory issue.\n\n\nmade BASH wrapper (not ideal) for \nRNAsik\n this is capture \nbds\n logs including report.html which is rather valuable piece of information about the run\n\n\nintroduced another new aligner - \nbwa mem\n to do bacterial RNAseq.\n\n\nintroduced multiqc config file in \nconfigs\n directory now\n\n\ncompletely removed \n-fqRegex\n and added sanity check for paired end data. If R2 is found and -paired isn't set or vice verse then error message sent\n\n\nseveral general bug fixes\n\n\nsimplified help menu\n\n\n\n\n1.4.6\n\n\n\n\ngeneralised aligner's call, this will make it easier to add new aligners into RNAsik\n\n\nincluded support for \nhista2\naligner\n\n\nadded samplesSheep logging\n\n\nfixed few minor bugs and improved code quality\n\n\nadded \ncanFail\n option to several non crucial tasks, allowing pipeline to continue if some task failed of fastqc and qualimap to allow them to fail as those are non essential tasks.\n\n\n\n\nTweet to @kizza_a\n \n\n\n\n\n\n\nShare", 
            "title": "Roadmap"
        }, 
        {
            "location": "/roadmap/#roadmap", 
            "text": "", 
            "title": "Roadmap"
        }, 
        {
            "location": "/roadmap/#going-forward", 
            "text": "", 
            "title": "Going forward"
        }, 
        {
            "location": "/roadmap/#149-q1-january-2018", 
            "text": "general bug fixes and maintenance", 
            "title": "1.4.9 Q1 (January) 2018"
        }, 
        {
            "location": "/roadmap/#14x", 
            "text": "need to have better way to check for index directory, want to know if starIdx includes or doesn't indexing with annotation.   recheck  Stuart's PR , polish off refFiles detection  recheck  this whole PR", 
            "title": "1.4.x"
        }, 
        {
            "location": "/roadmap/#1410-q1-february-2018", 
            "text": "improve  RNAsik  logging, particular want to make individual tools version logging independent of each other, so that if one wants to run\njust counts,  RNAsik  shouldn't complain about  bwa  not found in the PATH. Also double check the behaviour of the logger when pipelines re-runs.\nFrom memory it might not perform as it should. You really want a log of every event that had happened.  include logging of split lanes and R1 and R2. Want to be able to see from the log whether two reads were classified as split lanes or paired end. This is\nto do with recent bug that got fixed in  b924027", 
            "title": "1.4.10 Q1 (February) 2018"
        }, 
        {
            "location": "/roadmap/#1411-q1-februarymarch-2018", 
            "text": "add  samtools flagstat  qc run. Definitely need this for bacterial RNAseq i.e when running  bwa aligner , but this metric\nwouldn't hurt in general. It does overlap overall with  STAR aligner  qc output, but going forward other aligners will be\nadded/used but  samtools flagstat  will remain  improve python scripts, make strand_guessing more pythonic, also consider making it python3 friendly as per  Andrews PR ,\nalso output ration value as a third value csv value. This is useful number, particular if exit code is 1.  Document python scripts existence, what they do, how to run them manually in the case of failure, and the output they give", 
            "title": "1.4.11 Q1 (February/March) 2018"
        }, 
        {
            "location": "/roadmap/#150-q1-march-2018", 
            "text": "New feature(s) described below:   implement new flag  -fqFiles  that can take either a file or a directory.  if a directory is given, do what  -fqDir  does now and traverse down retuning list of fastq files.   if a file is given, use those locations getting fastq files. Location can be local file path or URLs, assume one location per line     Will keep  -fqDir  flag, as a backward compatibility with a warning that flag had been deprecated. Will also schedule to remove  -fqDir  completely in future releases\nBecause of changes in arg's options will do a minor version bump.   include handling of url based samples sheets, i.e  -samplesSheet  flag should handle local based or remote files, just like  -fastaRef  option", 
            "title": "1.5.0 Q1 (March) 2018"
        }, 
        {
            "location": "/roadmap/#151-q2-april-2018", 
            "text": "general maintenance and bug fixes  start including unit testing in your master branch, once I'm happy with with  unit_test  branch", 
            "title": "1.5.1 Q2 (April) 2018"
        }, 
        {
            "location": "/roadmap/#160-q3-octobernovember-2018", 
            "text": "Plans to add variants calling to  RNAsik . It'll be opt in flag,   -varsCall . Suggestions are welcomed about different name for a flag.\nI already have a prototype in bds, just need to plug it in.   Not sure which caller to use  GATK  or  freebayes  will need to do more reading on that.   Also need to document common pitfalls for using RNAseq for variant calling e.g can only can variances in coding regions that are expressed.   Not a good idea to use pulled samples as you won't be able to get allele frequency  will also need to find out where to get known SNP's (snpDB? for known germ line mutations) and a list of blacklisted regions     an example of someone else variant calling pipeline", 
            "title": "1.6.0 Q3 (October/November) 2018"
        }, 
        {
            "location": "/roadmap/#ideas-for-future-releases", 
            "text": "include IGVlink into RNAsik-pipe output, can only do that if data outputted into something that is hostable i.e object store?  Need better support for exonic/intronic rates estimation. Is  read_distribution.py  from RSeQC good idea? Right now qualiMap is ok flag to opt in.  add alignment free support for RNAseq analysis e.g salmon/kalisto  is there need for circular RNA support?", 
            "title": "Ideas for future releases"
        }, 
        {
            "location": "/roadmap/#changelog", 
            "text": "", 
            "title": "Changelog"
        }, 
        {
            "location": "/roadmap/#149", 
            "text": "Fixed BWA indexing problem. Problem around STAR and Hisat2 aligners pass index as directory whereas bwa as a file, had to fight to make all different options i.e  -refFiles  and  -genomeIdx  to work  Included proper support for SAF file format handled through -gtfFile flag i.e user can pass GTF, GFF or SAF through that flag and will still get counts  Imporved handling of urls for refrence files  -fastaRef ,  -gtfFile  now works with all bds supported url types. Also fixed tarball url handling through  -fqDir  Improved code readability in several places and included  canFail  flag for making degust reads counts files.  Fixed a bug in  exonicRates  function was passing \"wrong\" gtf file path  Updated docs, added more explanation on how RNAsik ticks. Included a roadmap to allow better time and features management  fixed  -pairIds  bug, courtesy @stu2 (PR #6) and samples sheet file making  Improved python script, including several small bug fixing", 
            "title": "1.4.9"
        }, 
        {
            "location": "/roadmap/#148", 
            "text": "added new feature: coverage plots generation  added new feature: ability to pass previously generated references directory, saves spaces and time  fixed strand guessing script, should be better at guessing now  moved to  mkdocs  for documents compilation and deployment to gh_pages  added new python script to make degust file, this simplifies and strengthens the code  improved readability of the code  improved and fixed bugs in handling fastq files and assignment of fastq to sample names", 
            "title": "1.4.8"
        }, 
        {
            "location": "/roadmap/#147", 
            "text": "fixed STAR memory allocation issue, now user can run with fewer cpus without a worry for STAR spawning multiple tasks causing out of memory issue.  made BASH wrapper (not ideal) for  RNAsik  this is capture  bds  logs including report.html which is rather valuable piece of information about the run  introduced another new aligner -  bwa mem  to do bacterial RNAseq.  introduced multiqc config file in  configs  directory now  completely removed  -fqRegex  and added sanity check for paired end data. If R2 is found and -paired isn't set or vice verse then error message sent  several general bug fixes  simplified help menu", 
            "title": "1.4.7"
        }, 
        {
            "location": "/roadmap/#146", 
            "text": "generalised aligner's call, this will make it easier to add new aligners into RNAsik  included support for  hista2 aligner  added samplesSheep logging  fixed few minor bugs and improved code quality  added  canFail  option to several non crucial tasks, allowing pipeline to continue if some task failed of fastqc and qualimap to allow them to fail as those are non essential tasks.   Tweet to @kizza_a     \nShare", 
            "title": "1.4.6"
        }
    ]
}