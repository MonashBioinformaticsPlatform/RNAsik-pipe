{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RNAsik for RNAseq N.B This workflow assumes model organism has a reference genome. If the reference genome isn't applicable, different workflow might be required. About RNAsik pipeline was build in house for processing RNA-seq(uencing) data. It is written in BigDataScript (bds) , which is domain specific language (DSL) , that makes writing pipelines easy as well as making them robust. To get a bit more technical, bds runs on java virtual machine (JVM) and therefore requires Java . In simple terms any pipeline is a wrapper of several tools that makes it easier and arguably faster to get to the end goal. The three core parts to any RNA-seq analysis are: mapping to the reference genome counting reads mapped into features e.g genes doing differential expression (DE) statistics The pipeline does the first two parts and Degust does the third part. Degust itself, in simple terms, a wrapper around limma and edgeR R packages. In theory and practice one can take output from RNAsik pipeline, which is a table of counts where every gene is a row and every column is a sample and use those with any other R packages that do DE analysis. In actual terms both RNAsik and Degust provide complete experience, not only you'll get your list of DE genes and QC metrics, but will be able to get full inside into your experimental design and the outcome of that. RNAsik does read alignment and read counting and cleaning and improvements of your table of counts, which makes Degust analysis one upload away. RNAsik wraps these tools making your RNAseq analysis more streamline. It also has \"sanity checks\" inbuilt, checking command line options, checking if options are valid files/directories and it will talk to you so don't sweat :) but do read the error messages. Degust is exceptionally good for exploratory data visualisation and analysis. Both tools can also server as a nice proxy for learning bioinformatics as they provide command line and R code for doing the analysis. Last but not least thanks to MultiQC RNAsik provides an aggregate of different metrics in one place - multiqc report. This is a good place to start understanding your data. The central bits of information are: Are there differences in library sizes? Is there any issues with mapping rates? Is there any issues with reads assignment rates? However there is so many other questions you can ask including: What is duplication rate? What is multi-mapping rate? What is intragenic and interagenic rates? As mentioned above multiqc report is a great first step in the attempt to answer those questions. A lot of the time everything looks fairly good and consistent allowing downstream analysis. Sometimes user can tweak certain individual parameters which can improve results, other times it comes down to experimental design and/or library preparation and sequencing issues. Either way one need to make this \"first iteration\" in order to see room for improvement. How to cite Tsyganov, Kirill, Andrew James Perry, Stuart Kenneth Archer, and David Powell. 2018. \u201cRNAsik: A Pipeline for Complete and Reproducible RNA-Seq Analysis That Runs Anywhere with Speed and Ease.\u201d Journal of Open Source Software 3: 583. It is hard to give full acknowlegment to all contributors. The nature of the open source projects such that contributors can come and go, however they leave behind valuable contributions and need to get full credit for that. Please look at RNAsik GitHub repository to get a full sense of who is contributing. In particular one can look at number of commits , issues triaging and handling and pull requests (PRs) . Please also remember that every contribution matters, nothing is too small! Methods Raw fastq files have been analysed with RNAsik pipeline (Tsyganov et al. 2018) to produce raw genes count matrix and various quality control metrics. For this analysis RNAsik pipeline (Tsyganov et al. 2018) ran with STAR aligner option (Dobin et al. 2013) and reads were quantified with featureCounts (Liao, Smyth, and Shi 2014) . The reference GTF and FASTA files were downloaded from Ensembl database . Raw counts were then analysed with Degust (Powell 2015) web tool to do differential expression analysis to produce list of differentially expressed genes and several quality plots including classical multidimensional scaling (MDS) and MA plots. In this analysis limma voom (Law et al. 2014) was used for differential expression analysis. Degust (Powell 2015) largely follows limma voom workflow with typical conts per million (CPM) library size normalisation and trimmed mean of M values (TMM) normalisation (Robinson and Oshlack 2010) for RNA composition normalisation. References Dobin, Alexander, Carrie A Davis, Felix Schlesinger, Jorg Drenkow, Chris Zaleski, Sonali Jha, Philippe Batut, Mark Chaisson, and Thomas R Gingeras. 2013. \u201cSTAR: Ultrafast Universal RNA-seq Aligner.\u201d Bioinformatics 29 (1): 15\u201321. http://dx.doi.org/10.1093/bioinformatics/bts635 . Law, Charity W, Yunshun Chen, Wei Shi, and Gordon K Smyth. 2014. \u201cVoom: Precision Weights Unlock Linear Model Analysis Tools for RNA-seq Read Counts.\u201d Genome Biol. 15 (2): R29. http://dx.doi.org/10.1186/gb-2014-15-2-r29 . Liao, Yang, Gordon K Smyth, and Wei Shi. 2014. \u201cFeatureCounts: An Efficient General Purpose Program for Assigning Sequence Reads to Genomic Features.\u201d Bioinformatics 30 (7): 923\u201330. http://dx.doi.org/10.1093/bioinformatics/btt656 . Powell, David. 2015. \u201cDegust: Powerfull and User Friendly Front-End Data Analsysis, Visualisation and Exploratory Tool for Rna-Sequencing.\u201d github. http://degust.erc.monash.edu . Robinson, Mark D, and Alicia Oshlack. 2010. \u201cA Scaling Normalization Method for Differential Expression Analysis of RNA-seq Data.\u201d Genome Biol. 11 (3): R25. http://dx.doi.org/10.1186/gb-2010-11-3-r25 . Tsyganov, Kirill, Andrew James Perry, Stuart Kenneth Archer, and David Powell. 2018. \u201cRNAsik: A Pipeline for Complete and Reproducible RNA-seq Analysis That Runs Anywhere with Speed and Ease.\u201d Journal of Open Source Software 3: 583. https://www.theoj.org/joss-papers/joss.00583/10.21105.joss.00583.pdf . MBP team photo Tweet to @kizza_a Share","title":"About"},{"location":"#rnasik-for-rnaseq","text":"N.B This workflow assumes model organism has a reference genome. If the reference genome isn't applicable, different workflow might be required.","title":"RNAsik for RNAseq"},{"location":"#about","text":"RNAsik pipeline was build in house for processing RNA-seq(uencing) data. It is written in BigDataScript (bds) , which is domain specific language (DSL) , that makes writing pipelines easy as well as making them robust. To get a bit more technical, bds runs on java virtual machine (JVM) and therefore requires Java . In simple terms any pipeline is a wrapper of several tools that makes it easier and arguably faster to get to the end goal. The three core parts to any RNA-seq analysis are: mapping to the reference genome counting reads mapped into features e.g genes doing differential expression (DE) statistics The pipeline does the first two parts and Degust does the third part. Degust itself, in simple terms, a wrapper around limma and edgeR R packages. In theory and practice one can take output from RNAsik pipeline, which is a table of counts where every gene is a row and every column is a sample and use those with any other R packages that do DE analysis. In actual terms both RNAsik and Degust provide complete experience, not only you'll get your list of DE genes and QC metrics, but will be able to get full inside into your experimental design and the outcome of that. RNAsik does read alignment and read counting and cleaning and improvements of your table of counts, which makes Degust analysis one upload away. RNAsik wraps these tools making your RNAseq analysis more streamline. It also has \"sanity checks\" inbuilt, checking command line options, checking if options are valid files/directories and it will talk to you so don't sweat :) but do read the error messages. Degust is exceptionally good for exploratory data visualisation and analysis. Both tools can also server as a nice proxy for learning bioinformatics as they provide command line and R code for doing the analysis. Last but not least thanks to MultiQC RNAsik provides an aggregate of different metrics in one place - multiqc report. This is a good place to start understanding your data. The central bits of information are: Are there differences in library sizes? Is there any issues with mapping rates? Is there any issues with reads assignment rates? However there is so many other questions you can ask including: What is duplication rate? What is multi-mapping rate? What is intragenic and interagenic rates? As mentioned above multiqc report is a great first step in the attempt to answer those questions. A lot of the time everything looks fairly good and consistent allowing downstream analysis. Sometimes user can tweak certain individual parameters which can improve results, other times it comes down to experimental design and/or library preparation and sequencing issues. Either way one need to make this \"first iteration\" in order to see room for improvement.","title":"About"},{"location":"#how-to-cite","text":"Tsyganov, Kirill, Andrew James Perry, Stuart Kenneth Archer, and David Powell. 2018. \u201cRNAsik: A Pipeline for Complete and Reproducible RNA-Seq Analysis That Runs Anywhere with Speed and Ease.\u201d Journal of Open Source Software 3: 583. It is hard to give full acknowlegment to all contributors. The nature of the open source projects such that contributors can come and go, however they leave behind valuable contributions and need to get full credit for that. Please look at RNAsik GitHub repository to get a full sense of who is contributing. In particular one can look at number of commits , issues triaging and handling and pull requests (PRs) . Please also remember that every contribution matters, nothing is too small!","title":"How to cite"},{"location":"#methods","text":"Raw fastq files have been analysed with RNAsik pipeline (Tsyganov et al. 2018) to produce raw genes count matrix and various quality control metrics. For this analysis RNAsik pipeline (Tsyganov et al. 2018) ran with STAR aligner option (Dobin et al. 2013) and reads were quantified with featureCounts (Liao, Smyth, and Shi 2014) . The reference GTF and FASTA files were downloaded from Ensembl database . Raw counts were then analysed with Degust (Powell 2015) web tool to do differential expression analysis to produce list of differentially expressed genes and several quality plots including classical multidimensional scaling (MDS) and MA plots. In this analysis limma voom (Law et al. 2014) was used for differential expression analysis. Degust (Powell 2015) largely follows limma voom workflow with typical conts per million (CPM) library size normalisation and trimmed mean of M values (TMM) normalisation (Robinson and Oshlack 2010) for RNA composition normalisation.","title":"Methods"},{"location":"#mbp-team-photo","text":"Tweet to @kizza_a Share","title":"MBP team photo"},{"location":"TODO/","text":"ToDo turns out that picard that comes with conda install isn't good for clusters env. there might be a simple fix to this, but basically this to do to remind me to DO that. This is all to do with not having enough heap memory, I think the fix might be as simple as setting sik.config to have picardExe = pirad -Xmx6g From reading condas picard wrapper script it appears that I can just pass extra java args through like that, needs testing document RNASIK_BDS_CONFIG and do travi test add support for \"transcript_level_support\" into geneIds.txt file and propogate that through. idea being that some genes have greater support (confidence) then others, perhaps would be nice to see that but also filter on that i.e only \"transcript_support_level = 1\" best evidence (biological) It looks like \"transcript_support_level\" applicable to transcript and given gene can have several once so will need thing on best way to summarise that Java related issues I need to start gather better logs. This is useful command to grab java version and args java -version # Picked up JAVA_TOOL_OPTIONS: # Picked up _JAVA_OPTIONS: -Xmx512m -Xms64m # java version 1.7.0_40 OpenJDK Runtime Environment (IcedTea 2.4.1) (suse-3.41.1-x86_64) OpenJDK 64-Bit Server VM (build 24.0-b50, mixed mode) I think issue of passing in correct memory i.e memory passed to the task has to be the same as memmory passed to JVM, can be solved with _JAVA_OPTIONS parameter. Other couple of useful commands are jps jps -v This is to list running java process and they flags I don't know at this stage what would be better sys _JAVA_OPTIONS=blah $picardExe ... OR Parse memory out of the config and set it globaly Do I need this option? JAVA_OPTIONS=\"-Djava.io.tmpdir=$HOME/tmp\" Links https://stackoverflow.com/questions/28327620/difference-between-java-options-java-tool-options-and-java-opts Modules and extensibility If I want RNAsik to do additional things for me for example call variances or put it more generally execute me random bds scripts how can I do that? Let's say I wrote a plugin that can latch onto RNAsik Let's do that in a form of additional flag -pluginFile path/to/file In that file one will specify input/output, something rather simple e.g bamFiles meaning the input for the plugin will be bamFiles Then path to a plugin module i.e newPlugIn.bds Plugin module needs to inheret sikRun path and all other configFile paths, because we want to deposit plugin staff inside into sikRun directory The right thing would be to somehow include plugin module before very last - multiqc step such that multiqc has a chance to pickup on those extra log file that module could generate","title":"ToDo"},{"location":"TODO/#todo","text":"turns out that picard that comes with conda install isn't good for clusters env. there might be a simple fix to this, but basically this to do to remind me to DO that. This is all to do with not having enough heap memory, I think the fix might be as simple as setting sik.config to have picardExe = pirad -Xmx6g From reading condas picard wrapper script it appears that I can just pass extra java args through like that, needs testing document RNASIK_BDS_CONFIG and do travi test add support for \"transcript_level_support\" into geneIds.txt file and propogate that through. idea being that some genes have greater support (confidence) then others, perhaps would be nice to see that but also filter on that i.e only \"transcript_support_level = 1\" best evidence (biological) It looks like \"transcript_support_level\" applicable to transcript and given gene can have several once so will need thing on best way to summarise that","title":"ToDo"},{"location":"TODO/#java-related-issues","text":"I need to start gather better logs. This is useful command to grab java version and args java -version # Picked up JAVA_TOOL_OPTIONS: # Picked up _JAVA_OPTIONS: -Xmx512m -Xms64m # java version 1.7.0_40 OpenJDK Runtime Environment (IcedTea 2.4.1) (suse-3.41.1-x86_64) OpenJDK 64-Bit Server VM (build 24.0-b50, mixed mode) I think issue of passing in correct memory i.e memory passed to the task has to be the same as memmory passed to JVM, can be solved with _JAVA_OPTIONS parameter. Other couple of useful commands are jps jps -v This is to list running java process and they flags I don't know at this stage what would be better sys _JAVA_OPTIONS=blah $picardExe ... OR Parse memory out of the config and set it globaly Do I need this option? JAVA_OPTIONS=\"-Djava.io.tmpdir=$HOME/tmp\"","title":"Java related issues"},{"location":"TODO/#links","text":"https://stackoverflow.com/questions/28327620/difference-between-java-options-java-tool-options-and-java-opts","title":"Links"},{"location":"TODO/#modules-and-extensibility","text":"If I want RNAsik to do additional things for me for example call variances or put it more generally execute me random bds scripts how can I do that? Let's say I wrote a plugin that can latch onto RNAsik Let's do that in a form of additional flag -pluginFile path/to/file In that file one will specify input/output, something rather simple e.g bamFiles meaning the input for the plugin will be bamFiles Then path to a plugin module i.e newPlugIn.bds Plugin module needs to inheret sikRun path and all other configFile paths, because we want to deposit plugin staff inside into sikRun directory The right thing would be to somehow include plugin module before very last - multiqc step such that multiqc has a chance to pickup on those extra log file that module could generate","title":"Modules and extensibility"},{"location":"checklist/","text":"Checklist I feel that the researchers some what commonly ask bioinformaticians - What do you need to know about the experiment? The short answer is everything ! but here is a break down of everything.. The best practice is to gather all of the information in the checklist before the analysis. Must If the below information isn't give I can't really do the analysis Have you got raw (FASTQ) files? What is your model organism? Which reference database to use? (e.g. ucsc, ensembl, refseq) Additional reference files e.g transgenes? will need relevant files (FASTA , GTF/GFF) Do you have a samples sheet for me? Should I'm saying should, but really the more information you provide the more accurate - more reflective analysis is going to be of your biological experiment Have I got enough explanation about experimental design including: Any batch effects. Paired-data (eg. individual before/after treatment) Comparisons of interest. Pairwise? Interaction? Additional factors for contrast matrix: sample pairing sex time points phenotype stimulus other.. Up to you This is your experiment and your money and time spend on it. I'm just saying that there are instrument to instrument variations and biases. As well as certain artifacts due to particular library preparation method. On top of that you'll need this information if you are going to publish your results in a paper. Which sequencing facility was doing the sequencing? Library preparation info: library type: single or paired end preparation method ribo-depletion or poly(A), other is library stranded name of preparation kit was used Sequencer used (e.g HiSeq1500, NovaSeq, NextSeq etc) Are you keeping a copy of your raw data somewhere safe","title":"Checklist"},{"location":"checklist/#checklist","text":"I feel that the researchers some what commonly ask bioinformaticians - What do you need to know about the experiment? The short answer is everything ! but here is a break down of everything.. The best practice is to gather all of the information in the checklist before the analysis.","title":"Checklist"},{"location":"checklist/#must","text":"If the below information isn't give I can't really do the analysis Have you got raw (FASTQ) files? What is your model organism? Which reference database to use? (e.g. ucsc, ensembl, refseq) Additional reference files e.g transgenes? will need relevant files (FASTA , GTF/GFF) Do you have a samples sheet for me?","title":"Must"},{"location":"checklist/#should","text":"I'm saying should, but really the more information you provide the more accurate - more reflective analysis is going to be of your biological experiment Have I got enough explanation about experimental design including: Any batch effects. Paired-data (eg. individual before/after treatment) Comparisons of interest. Pairwise? Interaction? Additional factors for contrast matrix: sample pairing sex time points phenotype stimulus other..","title":"Should"},{"location":"checklist/#up-to-you","text":"This is your experiment and your money and time spend on it. I'm just saying that there are instrument to instrument variations and biases. As well as certain artifacts due to particular library preparation method. On top of that you'll need this information if you are going to publish your results in a paper. Which sequencing facility was doing the sequencing? Library preparation info: library type: single or paired end preparation method ribo-depletion or poly(A), other is library stranded name of preparation kit was used Sequencer used (e.g HiSeq1500, NovaSeq, NextSeq etc) Are you keeping a copy of your raw data somewhere safe","title":"Up to you"},{"location":"contrib/","text":"Contributing There are many places for contribution the most obvious ones are help with documentations, help in the user's group and of course with the source itself. Documentations I'm using mkdocs to generate this site, which has been very easy to use. All documentations are written in plain markdown and located in main repo docs/ directory . You can simply fork RNAsik repository, do changes to the docs and send me a pull request (PR). Any changes are super welcomed, even one letter spell correction (there'll be more than one), but all changes need to come through PR, which will not only acknowledge you as contributor, but also enable me to review changes quickly and incorporate them in (pull them in) easily. Quick notes on mkdocs , it is pretty easy to install with pip in virtualenv if you prefer (you should). to install mkdocs (don't have to use virtualenv ) virtualenv mkdocs_env source mkdocs_env/bin/activate pip install mkdocs mkdocs in the nutshell mkdocs build mkdocs gh-deploy This will deploy your copy of RNAsik docs to your github-pages (gh-pages) You actually don't need to do that, you don't need deploy your own copy of the docs to your branch. Just use mkdocs server (read below) to prerview changes and send them through to me. git clone https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe cd RNAsik-pipe # do docs changes get localhost server (to preview your changes) mkdocs server This will give you live updates to you copy of the docs, default URL should be localhost:8000 , but it will tell you that once you've started the server. Then simply use your favourite text editor to edit markdown documents. Commit your changes, don't be afraid to be verbose, say what you've added/changed/removed in your commit message. And send me PR. User's group Just jump in and do it! Developing pipeline further I need to write a more comprehensive developer guide at sometime soon. Any contributions are again extremely welcomed and again as I've mentioned in the documentations section above, any contributions need to come through pull request (PR). To summarise briefly layouts of the src/ : RNAsik.bds is the main \"executable\" file that sources all required modules and runs the pipeline. sikHeader.bds defines help menu and all user inputs options. I do have a couple of command line arguments hidden from main help menu, but if you take a pick at this file you'll see them all All other *.bds files contain functions to specific tasks those functions get called in RNAsik.bds Building conda package First of all you need to set up your conda environment. If you don't have conda installed get it first. download miniconda .sh installer run it and follow the prompts bash Miniconda3-latest-Linux-x86_64.sh These are fairly routine steps, but if this is your first time you'll need to do them add a few conda \"channels\", this is so conda knows where to get things from conda config --add channels defaults conda config --add channels conda-forge conda config --add channels bioconda install a couple of required conda packages conda install conda-build conda install anaconda-client Note that you can use -y flag to say assume yes instead of manually entering yes/no you will need a copy of bioconda recipes. I haven't PR my fork to official bioconda channel so for now it is git clone https://github.com/serine/bioconda-recipes cd bioconda-recipes conda build recipes/rnasik To install RNAsik locally from just build package. You need these two commands. First command simply list the location of where the .tar.bz2 file is on the system. You also need that location if you want to publish to anaconda repository. The second command simply installs the package conda build recipes/rnasik --output conda install -y --use-local rnasik To upload newly build package to anacoda repository set up an account at Anacoda anaconda login anaconda upload path_to_file.tar.bz2 anaconda upload path_to_file.tar.bz2 --label dev Once you've logged in once, anaconda will store login token somewhere in your home directory here ? ~/.continuum/anaconda-client Travis CI and testing Continues integration is very useful to ensure your code is checked continiouslly. RNAsik code is checked (tested) with every commit. However that testing only as good as I, or hopefully we, will make it. BigDataScript provides very nice unit testing mechanism, the trick of course it gotta to be written. Currently only very small proportion of the code is actually covered by tests. A lot of work is needed in this space. Of course one might say that I should have been writing tests as I was writing my code. Perhaps, but I'm new to this and better later then never! Have a look at bds docs on how to write tests. Tweet to @kizza_a Share","title":"Contributing"},{"location":"contrib/#contributing","text":"There are many places for contribution the most obvious ones are help with documentations, help in the user's group and of course with the source itself.","title":"Contributing"},{"location":"contrib/#documentations","text":"I'm using mkdocs to generate this site, which has been very easy to use. All documentations are written in plain markdown and located in main repo docs/ directory . You can simply fork RNAsik repository, do changes to the docs and send me a pull request (PR). Any changes are super welcomed, even one letter spell correction (there'll be more than one), but all changes need to come through PR, which will not only acknowledge you as contributor, but also enable me to review changes quickly and incorporate them in (pull them in) easily. Quick notes on mkdocs , it is pretty easy to install with pip in virtualenv if you prefer (you should). to install mkdocs (don't have to use virtualenv ) virtualenv mkdocs_env source mkdocs_env/bin/activate pip install mkdocs mkdocs in the nutshell mkdocs build mkdocs gh-deploy This will deploy your copy of RNAsik docs to your github-pages (gh-pages) You actually don't need to do that, you don't need deploy your own copy of the docs to your branch. Just use mkdocs server (read below) to prerview changes and send them through to me. git clone https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe cd RNAsik-pipe # do docs changes get localhost server (to preview your changes) mkdocs server This will give you live updates to you copy of the docs, default URL should be localhost:8000 , but it will tell you that once you've started the server. Then simply use your favourite text editor to edit markdown documents. Commit your changes, don't be afraid to be verbose, say what you've added/changed/removed in your commit message. And send me PR.","title":"Documentations"},{"location":"contrib/#users-group","text":"Just jump in and do it!","title":"User's group"},{"location":"contrib/#developing-pipeline-further","text":"I need to write a more comprehensive developer guide at sometime soon. Any contributions are again extremely welcomed and again as I've mentioned in the documentations section above, any contributions need to come through pull request (PR). To summarise briefly layouts of the src/ : RNAsik.bds is the main \"executable\" file that sources all required modules and runs the pipeline. sikHeader.bds defines help menu and all user inputs options. I do have a couple of command line arguments hidden from main help menu, but if you take a pick at this file you'll see them all All other *.bds files contain functions to specific tasks those functions get called in RNAsik.bds","title":"Developing pipeline further"},{"location":"contrib/#building-conda-package","text":"First of all you need to set up your conda environment. If you don't have conda installed get it first. download miniconda .sh installer run it and follow the prompts bash Miniconda3-latest-Linux-x86_64.sh These are fairly routine steps, but if this is your first time you'll need to do them add a few conda \"channels\", this is so conda knows where to get things from conda config --add channels defaults conda config --add channels conda-forge conda config --add channels bioconda install a couple of required conda packages conda install conda-build conda install anaconda-client Note that you can use -y flag to say assume yes instead of manually entering yes/no you will need a copy of bioconda recipes. I haven't PR my fork to official bioconda channel so for now it is git clone https://github.com/serine/bioconda-recipes cd bioconda-recipes conda build recipes/rnasik To install RNAsik locally from just build package. You need these two commands. First command simply list the location of where the .tar.bz2 file is on the system. You also need that location if you want to publish to anaconda repository. The second command simply installs the package conda build recipes/rnasik --output conda install -y --use-local rnasik To upload newly build package to anacoda repository set up an account at Anacoda anaconda login anaconda upload path_to_file.tar.bz2 anaconda upload path_to_file.tar.bz2 --label dev Once you've logged in once, anaconda will store login token somewhere in your home directory here ? ~/.continuum/anaconda-client","title":"Building conda package"},{"location":"contrib/#travis-ci-and-testing","text":"Continues integration is very useful to ensure your code is checked continiouslly. RNAsik code is checked (tested) with every commit. However that testing only as good as I, or hopefully we, will make it. BigDataScript provides very nice unit testing mechanism, the trick of course it gotta to be written. Currently only very small proportion of the code is actually covered by tests. A lot of work is needed in this space. Of course one might say that I should have been writing tests as I was writing my code. Perhaps, but I'm new to this and better later then never! Have a look at bds docs on how to write tests. Tweet to @kizza_a Share","title":"Travis CI and testing"},{"location":"docs/","text":"Documentation Quick start Install Download and run quick_install.bash script export PATH=$(readlink -f miniconda)/bin:$PATH Align raw reads RNAsik -align star \\ -fastaRef /path/to/reference.fasta \\ -fqDir /path/to/raw-data/directory Count gene features RNAsik -counts \\ -gtfFile path/to/annotation.gtf The lot RNAsik -fqDir /path/to/raw-data/directory \\ -align star \\ -refFiles /path/to/refDir \\ -counts \\ -all Data set for testing N.B RNAsik pipeline is some what resource hungry. This isn't RNAsik fault per say, because it \"simply\" wraps other tools. STAR aligner required fair amount of RAM and cpus. For a large genome like mouse it required around 30 Gb of RAM and the more cpus you have the quicker you'll map. I would advise not run the pipeline with less than 4 cores, which is default. This testing data set is of yeast and requires about 14 Gb of RAM. Also read this comment , in summary you might have RNAsik failing on system that are under minimum system resources, this is work in progess and should be fixed in the future. I figured that for testing you need smallish data set as well as species with a small genome, as indexing of genome takes a while for larger genome e.g mouse I found this study GSE103004 which looks like an open access. If you follow that link you should hit front GEO page for that study. You can find your way to actual data (SRA files) files, but I always find it's a bit convoluted, so hit here is a link to data files . I've already prepared raw-data (fastq) files for you. I also reduced number of samples and sub-sampled reads to speed up your test run. Firstly though let me explain to you how to get full data set. download sratoolkit which is set of tools from NCBI that you'll need to download sra files and then extract/convert those to fastq files. fastq-dump --gzip --split-files SRR3407195 this is a command that you'll want to run to get one particular sra file, not --split-files options, you need to use that if you data is paired end. If you don't use that flag, then you are going to end up with a single fastq file that has reads interleaved or truncated/merged in a funny way (had some issues like that in the past) However you don't want run that command several times, so use a loop while read s; do fastq-dump --gzip --split-files $s $s.log 2 1 done SRR_Acc_List.txt You can download SRR_Acc_List.txt file at this page (mentioned that page before). That list has 9 sra files corresponding to 9 samples, where each samples was paired end and therefore total number of files is double - 18. Also note that default marking when extracting from sra for R1 and R2 is _1 and _2 respectively and so if you are running RNAsik on that full data set you'll need to pass -pairIds \"_1,_2\" flag, default is -pairIds \"_R1,_R2\" If you want nicely labeled bam and then counts you can pass -samplesSheet samplesSheet.txt . I haven't implemented url based samples sheets, so you'll need to download one before hand from here . I'll include handling of url based samples sheets into roadmap, so watch that space ! If you ran RNAsik on a full data set and then used Degust for DGE analysis you should get these results . Note that report was generated using pandoc with custome template and igv_links were created using mk_igv_links script located in scripts/ directory Try it out RNAsik -fqDir https://bioinformatics.erc.monash.edu/home/kirill/sikTestData/rawData/fqFiles.txt \\ -align star \\ -fastaRef ftp://ftp.ensembl.org/pub/release-91/fasta/saccharomyces_cerevisiae/dna/Saccharomyces_cerevisiae.R64-1-1.dna_sm.toplevel.fa.gz \\ -gtfFile ftp://ftp.ensembl.org/pub/release-91/gtf/saccharomyces_cerevisiae/Saccharomyces_cerevisiae.R64-1-1.91.gtf.gz \\ -counts \\ -paired \\ -all Introduction As mentioned previously in about section very first step in RNA-seq analysis is to map your raw reads ( FASTQ ) to the reference genome following by counting of reads that map onto a feature. But there is always more you could do with your data, in fact almost always only by doing more you can get deeper inside into your biological experiment and the system you are studying. And so RNAsik uses these tools to get as much out of your data as possible in an streamline run: STAR aligner for mapping featureCounts from subread package for read counting samtools for coverage calculation and general bam files filtering picard tools also for general bam fiels filtering QualiMap for intragenic and interegenic rates FastQC for QC metrics on yor fastq files MultiQC for wraping everying into nice, single page report As one can imagine every one of those tools has several number of options and by running RNAsik-pipeline you get predefined - subjective run. Obviously it all comes from years of experience and continues development and improvement. Use can always pass his/her own options through -extraOptions flag for more fine turning. Alternatively as, hinted above, user can leverage of RNAsik to run everything separately with fine control over the individual run. RNAsik produces .html report with all commands options specified. Installation Using conda download miniconda .sh installer run it and follow the prompts bash Miniconda3-latest-Linux-x86_64.sh add a few conda \"channels\", this is so conda knows where to get things from conda config --add channels defaults conda config --add channels conda-forge conda config --add channels bioconda install RNAsik pipeline conda install -c serine rnasik additionally install qualimap separately (it was a tricky to include qualimap into RNAsik because large number of dependencies that qualimap has) conda install -c bioconda qualimap Right now RNAsik hosted from my \"channel\" (conda terminology). There are plans to push it to official bioconda channel conda extras search \"main\" label (repository) conda search -c serine rnasik search \"dev\" label (repository) conda search -c serine/label/dev rnasik install specific version conda install -c serine/label/dev rnasik=1.5.1+3ecd215 install specific version and specific build number conda install -c serine/label/dev rnasik=1.5.1+3ecd215=4 simply install latest from that \"dev\" label (repository) conda install -c serine/label/dev rnasik NOTE: that these are just some extras commands mainly for testing purposes not for production use ! Alternative installation methods HERE User input Reference files Input File Description FASTA file Most often this is your genomic reference sequence. It is a FASTA file holding raw DNA sequences where different features e.g chromosomes are labeled uniquely with a header line starting with '>'. [FASTA Format Description](https://en.wikipedia.org/wiki/FASTA_format) GTF/GFF/SAF file This is your gene annotation file (i.e coordinates of your genes, exons and other genomic features). This should be linked and associated with your genomic reference file. SAF (simple annotation format) is something that featureCounts use and it supported by the pipeline Raw data Input File Description FASTQ file These are your raw files that are provided by the sequencing facility to you, they can be gzipped (.fq, .fastq, .fq.gz, .fastq.gz) User input explained Annotation files Annotation file would central for differential expression (DE) analysis without one you won't be able to do one. You could have very well assembled genome with very good mapping rate, but unless you know where your genes are on that genome i.e start and end coordinates for your features e.g genes you won't be able to deduce any information about those features and therefore compare between conditions. Below is an example of bear minimum information you need for feature counting. GeneID Chr Start End Strand 497097 chr1 3204563 3207049 - 497097 chr1 3411783 3411982 - 497097 chr1 3660633 3661579 - There few entities that provide genome annotation, some cover more species than other. There will be of course individuals that simply provide annotation for one particular species, perhaps for more rare model organisms. There are also different annotation file formats out there, which makes a little hard to provide RNAsik support for all of them. Currently RNAsik can only work with GFF , GTF or SAF file formats. There are many compatibilities issues between formats, but more importantly certain bits of information are only found in some of the files. The example above show SAF file format and as you can see that includes not human redable gene names nor biotype. GFF also often doesn't have biotype information, but on the other hand has product tag, which has short description, for protein coding at least, of resulting protein product, GTF lacks that information. Because of all these little nuances it can be hard to capture all of the desirable information. Most tools in the pipeline prefer GTF , some can only work with GTF . I guess main reason for this is that every line is self contained and the format has been fairly predictable/stable. If for whatever reason you can't get hold of GFF/GTF files and your annotation comes in GenBank (very common for bacterial genomes) or Bed files, don't panic and try to parse those files into SAF format. There are plans to include gb_parse.py script that should help most people with GenBank files. Irrespective of which reference file distributor and which annotation file you are going to use, it is highly recommended that both of those files come from the same distributor. Most common distributors are Ensembl , UCSC and NCBI . Raw data files Raw data is something that you should take good care of. You can regenerate all other data files, but you can't really regenerate you raw data, not unless you have lots of money and time. So be sure to back your fastq files up and never mess/do (i.e modify) your original fastq files. If you want to try something out, make a copy and do whatever you are doing on a copy. Also there will never be a need to unzip your fastq file. All of you fastq file should be gziped and have file extension .fastq.gz or fq.gz or something similar. RNAsik will search recursively your -fqDir and find all fastq files. RNAsik can handle nested directories as long as your data is homogeneous i.e all data belongs to the same library type single-end or paired-end. If data is paired end, RNAsik uses -pairIds value to figure out read pairs. You can check that all of your fastq files had been found by looking into sikRun/logs/samples/fqFiles . After obtaining a list of all fastq files RNAsik tries to be smart and attempts to group fastq files into samples, that is R1 and R2 reads are grouped, but also any fastq files that had been split across lanes should also be grouped. You should end up, after the run, with the same number of bam files as you have samples. Again you can check grouping in sikRun/logs/samples/fqMap RNAsik fastq grouping works in two modes: smart guessing it is a little involved but essentially it uses regular expression to check if fastq files have common suffix and therefore belong to the same sample. It heavily relies on clear labeling of R1 and R2 reads for paired-end data. a more straight forward mode is simply to use samples sheet file, which is any text file with two columns separated by a tab character, old_prefix\\tnew_prefix . Prefix in this case is your sample name, unique bit of the file. Samples sheet in a bit more details; If you have four samples, two wild-type and two controls, you should have four bam files after the analysis. However you number of fastq files is rather variable, depending on your sequencing. For paired-end sequencing you are going to end up with 2 fastq files per sample and 8 fastq files all up. If your sequencing was also split across lanes, say two lanes, then you are going to have 4 fastq file per each samples and 16 fastq files in total. RNAsik tries to simplify this for you. RNAsik output Directories breakdown Directories Description refFiles/ Contains the reference files (FASTA and GTF) and indices (aligner index) used in the analysis run alignerFiles/ Containts all other, additional files from alignment run, but the bam files. e.g aligner specific log files, splice junction files bamFiles/ Contains pre-processed BAM files, i.e sorted and duplicates marked as well as indexed, all using samtools and picard tools. These BAMs can be used in [IGV](http://software.broadinstitute.org/software/igv/) to view read alignments countFiles/ Contains read count files, \"raw\" - from `featureCounts`, degust ready counts and filtered for protein_coding features only coverageFiles/ Contains bigWig files for every bam (sample) file - from `bedtools genomecov` and `bedGrapToBigWig` USCS binary. Can load those into IGV fastqReport/ Contains FastQC HTML reports for individual FASTQ files qualiMapResults/ Contains int(ra|er)genic rates from each BAM file. Each BAM has its own directory with metric files. These results generated using `QualiMap rnaseq` command fastqDir/ If you are going to pull your FASTQ file over http in tarball, then tarball will be unarchived here multiqc_data/ Directory created by MultiQC holding a parsed text file, it doesn't serve any purpose for html file logs/ Directory that holds subdirectories, self explanatory, with logs files Files breakdown Files Description geneIds.txt Hold four additional columns that get added into read counts file, that has postfix \"-withNames. Gene.id, Chrom, Gene.Name, Biotype. strandInfo.txt Contains guesses, based on `featureCounts` `.summary` files, strand informataion multiqc_report.html This is the report file produced by MultiQC tool. A stand alone html file and can be viewed in any browser RNAsik output explained I hope that the directories and files naming is some what self explanatory, but here is a bit more detailed explanation of those. Bam files First thing you most certainly going to get out of the pipeline is your bam files, those will be placed into bamFiles/ directory. I don't really understand why, but featureCounts works best (fastest) with name sorted BAM files a.k.a unsorted. There is really two types of sorting, sorted by coordinates, often preferred as you can index those bam files and then have quick access to random parts of the file, second type is sorted by name, which insures that in paired-end experiment R1 and R2 pairs are interleaved, one after another, but you can't index those). STAR aligner can output either of those files. I'm however outputting \"unsorted\" bam file and then in the second step sorting it with picard SamSort tool. There are a couple of reasons for that: other aligners don't sort e.g bwa and therefore assuming sorted bam file won't work well even though STAR is pretty amazing (honestly), but I still rather prefer one tool for one job, hence why I also don't count reads with STAR The bam files from bamFiles/ are only used with featureCounts and then picard suite converts them into sorted and marked duplicate bam files, which are now placed into mdupsFiles/ directory. The rest of the analysis based on these bam files. I'm still deciding what to do with \"raw\" bam files in bamFiles/ directory. They should be removed after run have finished, but if you have to re-run the pipeline to get additional things (which you can, it will resolve all dependencies and only run new tasks) those bams are now gone and will get regenerated, which will trigger the rest of pipeline to re-run, which is unwanted result. This is why I'm not auto-removing those bam files, rather doing manually after I'm sure. Count files Probably the second most important thing in the pipeline is getting read counts. That is given some genome annotation count how many of mapped reads actually ended up mapping into know annotation. For classical differential expression analysis we are interested in protein coding genes only, which pipeline attempts to filter for, but there are other biotypes that we can differentially compare. The pipeline attempts to guess the strand (directionality) of your library. In theory sequencing provider that had made your libraries should be able to tell you that, but sometimes they get it wrong or simply that information never reaches us (bioinformaticians) hence the guessing. Pipelines runs featureCounts three times forcing reads to forward strand only, forcing to reverse strand only and allowing counting on both strand (non stranded library). featureCounts is very nice and it provides summary table that has number of assigned to feature reads. One can simply compare forward and reverse stranded counts and deduce the strand of the library. In essence this formula is used forward-reverse/forward+reverse to obtain the ration, if ration is about 0.9 then library is stranded and sign indicates the strand type, if however ration is about 0.1 then library is non stranded, anything else will indication undetermined and strandInfo.txt file with default to NonStranded,1 note the number one after the comment indicating status code, meaning exit with error. If you see that in your strandInfo.txt file you'll need to manually inspect your *.summary files from featureCounts and make decision about which library type to go with. Actual implementation of strand guessing can be found in this script scripts/strand_guessing.py . featureCounts by default for any given run outputs two files, counts (e.g NonStrandedCounts.txt ) and summary (e.g NonStrandedCounts.txt.summary ). RNAsik attempts to \"clean up\" counts file, which includes removing and addition of certain columns to make counts files more informative. The columns that are added can be found in geneIds.txt . If for what ever reason your geneIds.txt is empty then all the other files with postfix -withNames going to be empty too. You could try to regenerate geneIds.txt file using scripts/get_gene_ids.py script and then scripts/mk_counts_file.py to obtain \"clean\" table of counts. Doing so isn't strictly needed however additional information such as human understandable gene name and biotypy often come very handy in understanding differential expression. Having a biotype in counts file also allows you to filter for specific biotype e.g protein_coding or snRNA provided your annotation file has that information. Command line options Read alignment Options Usage -align specify your aligner of choice [star|starWithAnn|hisat|bwa] -fqDir specify path to your raw data directory. `RNAsik` will search that path recursively, so don't worry about nested directores -fastaRef specify path to your reference FASTA file, i.e file that holds your refrence genome -paired specify if data is paired end (RNASik looks for R1 and R2 in the FASTQ filename representing Read 1 and Read 2 Read counting Options Usage -counts flag if you'd like to get read counts -gtfFile specify path to your reference annotation file [GTF|GFF|SAF] Reads metrics Options Usage -all This is an aggregate flag that is a short hand to get everything pipeline has to offer -qc Flag to collect several different QC metrics on your BAM and counts data -exonicRate flag if you'd like to get Int(ra|er)genic rates for your reads, using QualiMap tool -multiqc flag if you'd like to get general report that summarises different log files including `STAR`, `featureCounts`, `FastQC` and `QualiMap` Extra options Options Usage -refFiles path to refFiles/ directory previously generated by RNAsik run -mdups flag to mark duplicates -trim perform FASTQ adapter and quality trimming -cov get coverage plots, bigWig -umi flag to deduplicate using UMI information -samplesSheet specify name of a tab separated text file, two columns,the first with old prefixes to be removed by new prefixes in the second column -genomeIdx specify path to pre-existing alignment index -outDir give a name to your analysis output directory [sikRun] -extn provide your fastq files extntion. [\".fastq.gz\"] -pairIds provide type identification, default is [`_R1,_R2`] -extraOpts provide key=value pairs, one per line, with key being tool name and value is a string of options e.g `star=\"--outWigType bedGraph\"` -configFile specify your own config file with key=value pairs, one per line, for all tools Unusual user case -bamsDir specify path to BAMs directory. Use if bams were generated outside of the pipeline RNAsik config file Below is a list of all options that are supported so by RNAsik so far with the defatul values. User can pass additional config file through -configFile options which takes precedence. User config dosen't have to hold all key=value pairs, just the one user wants to change. For example if I want to use different STAR executable. I would create new file (name of the file isn't relevant), and inside I just put. starExe = new/path/to/STAR RNAsik will inherit the rest of the options from the global config. Two things to note: you can't have comment on the same line as options don't quote values Executable paths starExe = STAR hisat2Exe = hisat2 bwaExe = bwa samtoolsExe = samtools bedtoolsExe = bedtools countsExe = featureCounts fastqcExe = fastqc pythonExe = python picardExe = picard jeExe = je qualimapExe = qualimap multiqcExe = multiqc skewerExe = skewer cpFileExe = cp Memory settings starIdxMem = 40000000000 starAlignMem = 40000000000 bwaIdxMem = -1 bwaAlignMem = -1 hisat2IdxMem = -1 hisat2AlignMem = -1 samtoolsSortMem = 3000000000 samtoolsQcMem = -1 picardMarkDupsMem = 6000000000 picardQcMem = 6000000000 jeMem = picardMarkDupsMem picardQcMem = -1 picardCreateDictMem = 4000000000 countsMem = -1 bedtoolsMem = 4000000000 fastqcMem = -1 multiqcMem = -1 skewerMem = -1 cpFileMem = 4000000000 Threads settings starIdxCpu = 24 starAlignCpu = 10 bwaIdxCpu = 30 bwaAlignCpu = 10 hisat2IdxCpu = 30 hisat2AlignCpu = 10 samtoolsSortCpu = 4 samtoolsQcCpu = 2 picardMarkDupsCpu = 2 jeCpu = picardMarkDupsCpu picardQcCpu = 2 picardCreateDictCpu = 2 bedtoolsCpu = 2 countsCpu = 5 fastqcCpu = 8 multiqcCpu = 2 skewerCpu = 5 cpFileCpu = 2 Python scripts There a few python scripts that are used in the pipeline to do various things, mostly to do with read counts post processing. Hopefully script name are self explanatory or have a good hint to what they do. All script have help menu, simply run the scripts with -h|--help to get more information. All script also output to stdout (print to the screen) in order to save the output you'll need to redirect to a file with symbol. All script set to be executable so you should be able just run them. If for some reason you cannot run them just use python prefix in front of the script name. Here are some examples on how to run python scripts ./get_geneids.py OR /full_path/to/get_geneids.py OR python get_geneids.py get_geneids.py Converts GTF|GFF files into four columns, tab delimited file Gene.Id\\tChrom\\tGene.Name\\tBiotype Note that Gene.Name and Biotype are subject to availability, i.e if that information isn't present in your annotation file then script (obviously) can't parse it out. We need this information to augment our counts file. This isn't essential for DGE but makes our exploratory analysis easier. mk_cnts_file.py Once we have our counts files from featureCounts and we've created geneIds.txt file with previous command We can add that extra meta information to our counts file. Note that this script filter on biotype, default is [protein_coding]. Also note that if biotype information is absent then your -withNames-proteinCoding.txt file will be empty since no such biotype was found. You can use --biotype all to get unfiltered - all genes. This is usually located in -withNames.txt file strand_guessing.py This script takes three different counts files i.e Forward, Reverse and Non stranded counts and attempts to guess which strand the data is. We can get this information from the sequencing facility and most Illumina library preparation kits are reverse stranded these days, but sometimes things happened and this approach gives us correct answers from the data itself. The output of this script is three values, comma separated; StrandType,StrandValue,ExitCode. e.g ReverseStandedCounts,-0.924,0 The first value is obvious, tells you the type of strand it guessed. The second value is calculated like this strnd_val = float(forward - reverse) / float(forward + reverse) which in essence allows us to estimate strand type. It is useful to look at that value as well. Magnitude is the confidence and the sign is directrion, negative is reverse, positive is forward stranded The third value what's called an exit code, zero == all good. It means the script is pretty confident that it guessed it right. The other possible value could be 1, 1 == not good. It means the script couldn't guess what the strand was and simply defaulted to NonStrandedCounts . You should never see exit code 1 with anything else by non stranded counts i.e NonStrandedCounts,1 . If you do, please report this as a bug. mk_igv_links.py This script isn't used in the pipeline actually, but it comes rather handy if you want to visualise your coverage plots, bigWig ( .bw ) files or bam ( .bam ) files Case study Once your RNAsik run had finished, have a look at strandInfo.txt file cat sikRun/countFiles/strandInfo.txt If you are seeing NonStrandedCounts,1 you will need to manually check and figure out what strand your data actually is. You will need to have a look at the .summary files for each of the three counts files. This is standard, summary, output file from featureCounts . For simplicity sake just look at the first sample's raw counts, second column and we are just going to look at \"Assigned\" row, which is second row. So we are focusing on second column, second row cell. We want to compare the number in that cell across three different strands counts. If the data is stranded then that strand going to get dominant number of reads. If reverse stranded counts getting vastly more reads then forward stranded counts then the data is reverse stranded. It is possible that non stranded counts in this case get essentially the same number of reads as reverse stranded. This is okay, but the data still is reverse stranded. Even if your non stranded counts have slightly more counts then your most dominant strand, (in this case) reverse stranded, this is still a reverse stranded data. On the other hand if you are seeing roughly 50/50 split between forward and reverse reads, then this is non stranded data. Now that you know what you are looking for, lets say, your data actually appears forward stranded and you would like to get -withNames.txt and withNames-proteinCoding.txt files. You will need to use mk_cnts_file.py script ./mk_cnt_file.py -h usage: mk_cnts_file.py --counts_dir path/to/coutns_dir --gene_ids path/to/geneIds.txt This script summarises log files information into html table optional arguments: -h, --help show this help message and exit --counts_file COUNTS_FILE path to directory with featureCounts files --gene_ids GENE_IDS path to geneIds.txt file, format EnsmblId Chrm GeneName Biotype --samples_sheet SAMPLES_SHEET path to samplesSheet.txt file, format old_prefix new_prefix --biotype BIOTYPE specify biotype of interest [protein_coding], 'all' is special to include everything --counts_col COUNTS_COL Indicate which column begins read counts. default [7], which is featureCounts default, all columns before 7th are metadata cols To get all feature types ./mk_cnt_file.py --counts_file sikRun/countFiles/ForwardStrandedCounts.txt \\ --gene_ids sikRun/countFiles/geneIds.txt \\ --samples_sheet sikRun/samplesSheet.txt \\ --biotype all ForwardStrandedCounts-withNames.txt To get just protein_coding features ./mk_cnt_file.py --counts_file sikRun/countFiles/ForwardStrandedCounts.txt \\ --gene_ids sikRun/countFiles/geneIds.txt \\ --samples_sheet sikRun/samplesSheet.txt \\ --biotype protein_coding ForwardStrandedCounts-withNames-proteinCoding.txt Metric files explained A lot of the tools output some sort of metrics files, to stdout/stderr or a file. Those metrics are important for analysis and QC checks going forward with the data. All of those metrics files are summarised into multiqc report. This section will attempt to explain in details each one of those metrics STAR Log.final.out This is straight out of the STAR docs Log.final.out: summary mapping statistics after mapping job is complete, very useful for quality control. The statistics are calculated for each read (single- or paired-end) and then summed or averaged over all reads. Note that STAR counts a paired-end read as one read, (unlike the samtools flagstat/idxstats, which count each mate separately). Most of the informa- tion is collected about the UNIQUE mappers (unlike samtools flagstat/idxstats which does not separate unique or multi-mappers). Each splicing is counted in the numbers of splices, which would correspond to summing the counts in SJ.out.tab. The mismatch/indel error rates are calculated on a per base basis, i.e. as total number of mismatches/indels in all unique mappers divided by the total number of mapped bases. Picard CollectAlignmentSummaryMetrics CollectGcBiasMetrics MarkDuplicates These are all picard tools that are used in the pipeline CreateSequenceDictionary SortSam MarkDuplicates BuildBamIndex CollectAlignmentSummaryMetrics CollectInsertSizeMetrics CollectGcBiasMetrics EstimateLibraryComplexity Tweet to @kizza_a Share","title":"Docs"},{"location":"docs/#documentation","text":"","title":"Documentation"},{"location":"docs/#quick-start","text":"","title":"Quick start"},{"location":"docs/#install","text":"Download and run quick_install.bash script export PATH=$(readlink -f miniconda)/bin:$PATH","title":"Install"},{"location":"docs/#align-raw-reads","text":"RNAsik -align star \\ -fastaRef /path/to/reference.fasta \\ -fqDir /path/to/raw-data/directory","title":"Align raw reads"},{"location":"docs/#count-gene-features","text":"RNAsik -counts \\ -gtfFile path/to/annotation.gtf","title":"Count gene features"},{"location":"docs/#the-lot","text":"RNAsik -fqDir /path/to/raw-data/directory \\ -align star \\ -refFiles /path/to/refDir \\ -counts \\ -all","title":"The lot"},{"location":"docs/#data-set-for-testing","text":"N.B RNAsik pipeline is some what resource hungry. This isn't RNAsik fault per say, because it \"simply\" wraps other tools. STAR aligner required fair amount of RAM and cpus. For a large genome like mouse it required around 30 Gb of RAM and the more cpus you have the quicker you'll map. I would advise not run the pipeline with less than 4 cores, which is default. This testing data set is of yeast and requires about 14 Gb of RAM. Also read this comment , in summary you might have RNAsik failing on system that are under minimum system resources, this is work in progess and should be fixed in the future. I figured that for testing you need smallish data set as well as species with a small genome, as indexing of genome takes a while for larger genome e.g mouse I found this study GSE103004 which looks like an open access. If you follow that link you should hit front GEO page for that study. You can find your way to actual data (SRA files) files, but I always find it's a bit convoluted, so hit here is a link to data files . I've already prepared raw-data (fastq) files for you. I also reduced number of samples and sub-sampled reads to speed up your test run. Firstly though let me explain to you how to get full data set. download sratoolkit which is set of tools from NCBI that you'll need to download sra files and then extract/convert those to fastq files. fastq-dump --gzip --split-files SRR3407195 this is a command that you'll want to run to get one particular sra file, not --split-files options, you need to use that if you data is paired end. If you don't use that flag, then you are going to end up with a single fastq file that has reads interleaved or truncated/merged in a funny way (had some issues like that in the past) However you don't want run that command several times, so use a loop while read s; do fastq-dump --gzip --split-files $s $s.log 2 1 done SRR_Acc_List.txt You can download SRR_Acc_List.txt file at this page (mentioned that page before). That list has 9 sra files corresponding to 9 samples, where each samples was paired end and therefore total number of files is double - 18. Also note that default marking when extracting from sra for R1 and R2 is _1 and _2 respectively and so if you are running RNAsik on that full data set you'll need to pass -pairIds \"_1,_2\" flag, default is -pairIds \"_R1,_R2\" If you want nicely labeled bam and then counts you can pass -samplesSheet samplesSheet.txt . I haven't implemented url based samples sheets, so you'll need to download one before hand from here . I'll include handling of url based samples sheets into roadmap, so watch that space ! If you ran RNAsik on a full data set and then used Degust for DGE analysis you should get these results . Note that report was generated using pandoc with custome template and igv_links were created using mk_igv_links script located in scripts/ directory","title":"Data set for testing"},{"location":"docs/#try-it-out","text":"RNAsik -fqDir https://bioinformatics.erc.monash.edu/home/kirill/sikTestData/rawData/fqFiles.txt \\ -align star \\ -fastaRef ftp://ftp.ensembl.org/pub/release-91/fasta/saccharomyces_cerevisiae/dna/Saccharomyces_cerevisiae.R64-1-1.dna_sm.toplevel.fa.gz \\ -gtfFile ftp://ftp.ensembl.org/pub/release-91/gtf/saccharomyces_cerevisiae/Saccharomyces_cerevisiae.R64-1-1.91.gtf.gz \\ -counts \\ -paired \\ -all","title":"Try it out"},{"location":"docs/#introduction","text":"As mentioned previously in about section very first step in RNA-seq analysis is to map your raw reads ( FASTQ ) to the reference genome following by counting of reads that map onto a feature. But there is always more you could do with your data, in fact almost always only by doing more you can get deeper inside into your biological experiment and the system you are studying. And so RNAsik uses these tools to get as much out of your data as possible in an streamline run: STAR aligner for mapping featureCounts from subread package for read counting samtools for coverage calculation and general bam files filtering picard tools also for general bam fiels filtering QualiMap for intragenic and interegenic rates FastQC for QC metrics on yor fastq files MultiQC for wraping everying into nice, single page report As one can imagine every one of those tools has several number of options and by running RNAsik-pipeline you get predefined - subjective run. Obviously it all comes from years of experience and continues development and improvement. Use can always pass his/her own options through -extraOptions flag for more fine turning. Alternatively as, hinted above, user can leverage of RNAsik to run everything separately with fine control over the individual run. RNAsik produces .html report with all commands options specified.","title":"Introduction"},{"location":"docs/#installation","text":"","title":"Installation"},{"location":"docs/#using-conda","text":"download miniconda .sh installer run it and follow the prompts bash Miniconda3-latest-Linux-x86_64.sh add a few conda \"channels\", this is so conda knows where to get things from conda config --add channels defaults conda config --add channels conda-forge conda config --add channels bioconda install RNAsik pipeline conda install -c serine rnasik additionally install qualimap separately (it was a tricky to include qualimap into RNAsik because large number of dependencies that qualimap has) conda install -c bioconda qualimap Right now RNAsik hosted from my \"channel\" (conda terminology). There are plans to push it to official bioconda channel","title":"Using conda"},{"location":"docs/#conda-extras","text":"search \"main\" label (repository) conda search -c serine rnasik search \"dev\" label (repository) conda search -c serine/label/dev rnasik install specific version conda install -c serine/label/dev rnasik=1.5.1+3ecd215 install specific version and specific build number conda install -c serine/label/dev rnasik=1.5.1+3ecd215=4 simply install latest from that \"dev\" label (repository) conda install -c serine/label/dev rnasik NOTE: that these are just some extras commands mainly for testing purposes not for production use !","title":"conda extras"},{"location":"docs/#alternative-installation-methods","text":"HERE","title":"Alternative installation methods"},{"location":"docs/#user-input","text":"","title":"User input"},{"location":"docs/#reference-files","text":"Input File Description FASTA file Most often this is your genomic reference sequence. It is a FASTA file holding raw DNA sequences where different features e.g chromosomes are labeled uniquely with a header line starting with '>'. [FASTA Format Description](https://en.wikipedia.org/wiki/FASTA_format) GTF/GFF/SAF file This is your gene annotation file (i.e coordinates of your genes, exons and other genomic features). This should be linked and associated with your genomic reference file. SAF (simple annotation format) is something that featureCounts use and it supported by the pipeline","title":"Reference files"},{"location":"docs/#raw-data","text":"Input File Description FASTQ file These are your raw files that are provided by the sequencing facility to you, they can be gzipped (.fq, .fastq, .fq.gz, .fastq.gz)","title":"Raw data"},{"location":"docs/#user-input-explained","text":"","title":"User input explained"},{"location":"docs/#annotation-files","text":"Annotation file would central for differential expression (DE) analysis without one you won't be able to do one. You could have very well assembled genome with very good mapping rate, but unless you know where your genes are on that genome i.e start and end coordinates for your features e.g genes you won't be able to deduce any information about those features and therefore compare between conditions. Below is an example of bear minimum information you need for feature counting. GeneID Chr Start End Strand 497097 chr1 3204563 3207049 - 497097 chr1 3411783 3411982 - 497097 chr1 3660633 3661579 - There few entities that provide genome annotation, some cover more species than other. There will be of course individuals that simply provide annotation for one particular species, perhaps for more rare model organisms. There are also different annotation file formats out there, which makes a little hard to provide RNAsik support for all of them. Currently RNAsik can only work with GFF , GTF or SAF file formats. There are many compatibilities issues between formats, but more importantly certain bits of information are only found in some of the files. The example above show SAF file format and as you can see that includes not human redable gene names nor biotype. GFF also often doesn't have biotype information, but on the other hand has product tag, which has short description, for protein coding at least, of resulting protein product, GTF lacks that information. Because of all these little nuances it can be hard to capture all of the desirable information. Most tools in the pipeline prefer GTF , some can only work with GTF . I guess main reason for this is that every line is self contained and the format has been fairly predictable/stable. If for whatever reason you can't get hold of GFF/GTF files and your annotation comes in GenBank (very common for bacterial genomes) or Bed files, don't panic and try to parse those files into SAF format. There are plans to include gb_parse.py script that should help most people with GenBank files. Irrespective of which reference file distributor and which annotation file you are going to use, it is highly recommended that both of those files come from the same distributor. Most common distributors are Ensembl , UCSC and NCBI .","title":"Annotation files"},{"location":"docs/#raw-data-files","text":"Raw data is something that you should take good care of. You can regenerate all other data files, but you can't really regenerate you raw data, not unless you have lots of money and time. So be sure to back your fastq files up and never mess/do (i.e modify) your original fastq files. If you want to try something out, make a copy and do whatever you are doing on a copy. Also there will never be a need to unzip your fastq file. All of you fastq file should be gziped and have file extension .fastq.gz or fq.gz or something similar. RNAsik will search recursively your -fqDir and find all fastq files. RNAsik can handle nested directories as long as your data is homogeneous i.e all data belongs to the same library type single-end or paired-end. If data is paired end, RNAsik uses -pairIds value to figure out read pairs. You can check that all of your fastq files had been found by looking into sikRun/logs/samples/fqFiles . After obtaining a list of all fastq files RNAsik tries to be smart and attempts to group fastq files into samples, that is R1 and R2 reads are grouped, but also any fastq files that had been split across lanes should also be grouped. You should end up, after the run, with the same number of bam files as you have samples. Again you can check grouping in sikRun/logs/samples/fqMap RNAsik fastq grouping works in two modes: smart guessing it is a little involved but essentially it uses regular expression to check if fastq files have common suffix and therefore belong to the same sample. It heavily relies on clear labeling of R1 and R2 reads for paired-end data. a more straight forward mode is simply to use samples sheet file, which is any text file with two columns separated by a tab character, old_prefix\\tnew_prefix . Prefix in this case is your sample name, unique bit of the file. Samples sheet in a bit more details; If you have four samples, two wild-type and two controls, you should have four bam files after the analysis. However you number of fastq files is rather variable, depending on your sequencing. For paired-end sequencing you are going to end up with 2 fastq files per sample and 8 fastq files all up. If your sequencing was also split across lanes, say two lanes, then you are going to have 4 fastq file per each samples and 16 fastq files in total. RNAsik tries to simplify this for you.","title":"Raw data files"},{"location":"docs/#rnasik-output","text":"","title":"RNAsik output"},{"location":"docs/#directories-breakdown","text":"Directories Description refFiles/ Contains the reference files (FASTA and GTF) and indices (aligner index) used in the analysis run alignerFiles/ Containts all other, additional files from alignment run, but the bam files. e.g aligner specific log files, splice junction files bamFiles/ Contains pre-processed BAM files, i.e sorted and duplicates marked as well as indexed, all using samtools and picard tools. These BAMs can be used in [IGV](http://software.broadinstitute.org/software/igv/) to view read alignments countFiles/ Contains read count files, \"raw\" - from `featureCounts`, degust ready counts and filtered for protein_coding features only coverageFiles/ Contains bigWig files for every bam (sample) file - from `bedtools genomecov` and `bedGrapToBigWig` USCS binary. Can load those into IGV fastqReport/ Contains FastQC HTML reports for individual FASTQ files qualiMapResults/ Contains int(ra|er)genic rates from each BAM file. Each BAM has its own directory with metric files. These results generated using `QualiMap rnaseq` command fastqDir/ If you are going to pull your FASTQ file over http in tarball, then tarball will be unarchived here multiqc_data/ Directory created by MultiQC holding a parsed text file, it doesn't serve any purpose for html file logs/ Directory that holds subdirectories, self explanatory, with logs files","title":"Directories breakdown"},{"location":"docs/#files-breakdown","text":"Files Description geneIds.txt Hold four additional columns that get added into read counts file, that has postfix \"-withNames. Gene.id, Chrom, Gene.Name, Biotype. strandInfo.txt Contains guesses, based on `featureCounts` `.summary` files, strand informataion multiqc_report.html This is the report file produced by MultiQC tool. A stand alone html file and can be viewed in any browser","title":"Files breakdown"},{"location":"docs/#rnasik-output-explained","text":"I hope that the directories and files naming is some what self explanatory, but here is a bit more detailed explanation of those.","title":"RNAsik output explained"},{"location":"docs/#bam-files","text":"First thing you most certainly going to get out of the pipeline is your bam files, those will be placed into bamFiles/ directory. I don't really understand why, but featureCounts works best (fastest) with name sorted BAM files a.k.a unsorted. There is really two types of sorting, sorted by coordinates, often preferred as you can index those bam files and then have quick access to random parts of the file, second type is sorted by name, which insures that in paired-end experiment R1 and R2 pairs are interleaved, one after another, but you can't index those). STAR aligner can output either of those files. I'm however outputting \"unsorted\" bam file and then in the second step sorting it with picard SamSort tool. There are a couple of reasons for that: other aligners don't sort e.g bwa and therefore assuming sorted bam file won't work well even though STAR is pretty amazing (honestly), but I still rather prefer one tool for one job, hence why I also don't count reads with STAR The bam files from bamFiles/ are only used with featureCounts and then picard suite converts them into sorted and marked duplicate bam files, which are now placed into mdupsFiles/ directory. The rest of the analysis based on these bam files. I'm still deciding what to do with \"raw\" bam files in bamFiles/ directory. They should be removed after run have finished, but if you have to re-run the pipeline to get additional things (which you can, it will resolve all dependencies and only run new tasks) those bams are now gone and will get regenerated, which will trigger the rest of pipeline to re-run, which is unwanted result. This is why I'm not auto-removing those bam files, rather doing manually after I'm sure.","title":"Bam files"},{"location":"docs/#count-files","text":"Probably the second most important thing in the pipeline is getting read counts. That is given some genome annotation count how many of mapped reads actually ended up mapping into know annotation. For classical differential expression analysis we are interested in protein coding genes only, which pipeline attempts to filter for, but there are other biotypes that we can differentially compare. The pipeline attempts to guess the strand (directionality) of your library. In theory sequencing provider that had made your libraries should be able to tell you that, but sometimes they get it wrong or simply that information never reaches us (bioinformaticians) hence the guessing. Pipelines runs featureCounts three times forcing reads to forward strand only, forcing to reverse strand only and allowing counting on both strand (non stranded library). featureCounts is very nice and it provides summary table that has number of assigned to feature reads. One can simply compare forward and reverse stranded counts and deduce the strand of the library. In essence this formula is used forward-reverse/forward+reverse to obtain the ration, if ration is about 0.9 then library is stranded and sign indicates the strand type, if however ration is about 0.1 then library is non stranded, anything else will indication undetermined and strandInfo.txt file with default to NonStranded,1 note the number one after the comment indicating status code, meaning exit with error. If you see that in your strandInfo.txt file you'll need to manually inspect your *.summary files from featureCounts and make decision about which library type to go with. Actual implementation of strand guessing can be found in this script scripts/strand_guessing.py . featureCounts by default for any given run outputs two files, counts (e.g NonStrandedCounts.txt ) and summary (e.g NonStrandedCounts.txt.summary ). RNAsik attempts to \"clean up\" counts file, which includes removing and addition of certain columns to make counts files more informative. The columns that are added can be found in geneIds.txt . If for what ever reason your geneIds.txt is empty then all the other files with postfix -withNames going to be empty too. You could try to regenerate geneIds.txt file using scripts/get_gene_ids.py script and then scripts/mk_counts_file.py to obtain \"clean\" table of counts. Doing so isn't strictly needed however additional information such as human understandable gene name and biotypy often come very handy in understanding differential expression. Having a biotype in counts file also allows you to filter for specific biotype e.g protein_coding or snRNA provided your annotation file has that information.","title":"Count files"},{"location":"docs/#command-line-options","text":"","title":"Command line options"},{"location":"docs/#read-alignment","text":"Options Usage -align specify your aligner of choice [star|starWithAnn|hisat|bwa] -fqDir specify path to your raw data directory. `RNAsik` will search that path recursively, so don't worry about nested directores -fastaRef specify path to your reference FASTA file, i.e file that holds your refrence genome -paired specify if data is paired end (RNASik looks for R1 and R2 in the FASTQ filename representing Read 1 and Read 2","title":"Read alignment"},{"location":"docs/#read-counting","text":"Options Usage -counts flag if you'd like to get read counts -gtfFile specify path to your reference annotation file [GTF|GFF|SAF]","title":"Read counting"},{"location":"docs/#reads-metrics","text":"Options Usage -all This is an aggregate flag that is a short hand to get everything pipeline has to offer -qc Flag to collect several different QC metrics on your BAM and counts data -exonicRate flag if you'd like to get Int(ra|er)genic rates for your reads, using QualiMap tool -multiqc flag if you'd like to get general report that summarises different log files including `STAR`, `featureCounts`, `FastQC` and `QualiMap`","title":"Reads metrics"},{"location":"docs/#extra-options","text":"Options Usage -refFiles path to refFiles/ directory previously generated by RNAsik run -mdups flag to mark duplicates -trim perform FASTQ adapter and quality trimming -cov get coverage plots, bigWig -umi flag to deduplicate using UMI information -samplesSheet specify name of a tab separated text file, two columns,the first with old prefixes to be removed by new prefixes in the second column -genomeIdx specify path to pre-existing alignment index -outDir give a name to your analysis output directory [sikRun] -extn provide your fastq files extntion. [\".fastq.gz\"] -pairIds provide type identification, default is [`_R1,_R2`] -extraOpts provide key=value pairs, one per line, with key being tool name and value is a string of options e.g `star=\"--outWigType bedGraph\"` -configFile specify your own config file with key=value pairs, one per line, for all tools","title":"Extra options"},{"location":"docs/#unusual-user-case","text":"-bamsDir specify path to BAMs directory. Use if bams were generated outside of the pipeline","title":"Unusual user case"},{"location":"docs/#rnasik-config-file","text":"Below is a list of all options that are supported so by RNAsik so far with the defatul values. User can pass additional config file through -configFile options which takes precedence. User config dosen't have to hold all key=value pairs, just the one user wants to change. For example if I want to use different STAR executable. I would create new file (name of the file isn't relevant), and inside I just put. starExe = new/path/to/STAR RNAsik will inherit the rest of the options from the global config. Two things to note: you can't have comment on the same line as options don't quote values","title":"RNAsik config file"},{"location":"docs/#executable-paths","text":"starExe = STAR hisat2Exe = hisat2 bwaExe = bwa samtoolsExe = samtools bedtoolsExe = bedtools countsExe = featureCounts fastqcExe = fastqc pythonExe = python picardExe = picard jeExe = je qualimapExe = qualimap multiqcExe = multiqc skewerExe = skewer cpFileExe = cp","title":"Executable paths"},{"location":"docs/#memory-settings","text":"starIdxMem = 40000000000 starAlignMem = 40000000000 bwaIdxMem = -1 bwaAlignMem = -1 hisat2IdxMem = -1 hisat2AlignMem = -1 samtoolsSortMem = 3000000000 samtoolsQcMem = -1 picardMarkDupsMem = 6000000000 picardQcMem = 6000000000 jeMem = picardMarkDupsMem picardQcMem = -1 picardCreateDictMem = 4000000000 countsMem = -1 bedtoolsMem = 4000000000 fastqcMem = -1 multiqcMem = -1 skewerMem = -1 cpFileMem = 4000000000","title":"Memory settings"},{"location":"docs/#threads-settings","text":"starIdxCpu = 24 starAlignCpu = 10 bwaIdxCpu = 30 bwaAlignCpu = 10 hisat2IdxCpu = 30 hisat2AlignCpu = 10 samtoolsSortCpu = 4 samtoolsQcCpu = 2 picardMarkDupsCpu = 2 jeCpu = picardMarkDupsCpu picardQcCpu = 2 picardCreateDictCpu = 2 bedtoolsCpu = 2 countsCpu = 5 fastqcCpu = 8 multiqcCpu = 2 skewerCpu = 5 cpFileCpu = 2","title":"Threads settings"},{"location":"docs/#python-scripts","text":"There a few python scripts that are used in the pipeline to do various things, mostly to do with read counts post processing. Hopefully script name are self explanatory or have a good hint to what they do. All script have help menu, simply run the scripts with -h|--help to get more information. All script also output to stdout (print to the screen) in order to save the output you'll need to redirect to a file with symbol. All script set to be executable so you should be able just run them. If for some reason you cannot run them just use python prefix in front of the script name. Here are some examples on how to run python scripts ./get_geneids.py OR /full_path/to/get_geneids.py OR python get_geneids.py get_geneids.py Converts GTF|GFF files into four columns, tab delimited file Gene.Id\\tChrom\\tGene.Name\\tBiotype Note that Gene.Name and Biotype are subject to availability, i.e if that information isn't present in your annotation file then script (obviously) can't parse it out. We need this information to augment our counts file. This isn't essential for DGE but makes our exploratory analysis easier. mk_cnts_file.py Once we have our counts files from featureCounts and we've created geneIds.txt file with previous command We can add that extra meta information to our counts file. Note that this script filter on biotype, default is [protein_coding]. Also note that if biotype information is absent then your -withNames-proteinCoding.txt file will be empty since no such biotype was found. You can use --biotype all to get unfiltered - all genes. This is usually located in -withNames.txt file strand_guessing.py This script takes three different counts files i.e Forward, Reverse and Non stranded counts and attempts to guess which strand the data is. We can get this information from the sequencing facility and most Illumina library preparation kits are reverse stranded these days, but sometimes things happened and this approach gives us correct answers from the data itself. The output of this script is three values, comma separated; StrandType,StrandValue,ExitCode. e.g ReverseStandedCounts,-0.924,0 The first value is obvious, tells you the type of strand it guessed. The second value is calculated like this strnd_val = float(forward - reverse) / float(forward + reverse) which in essence allows us to estimate strand type. It is useful to look at that value as well. Magnitude is the confidence and the sign is directrion, negative is reverse, positive is forward stranded The third value what's called an exit code, zero == all good. It means the script is pretty confident that it guessed it right. The other possible value could be 1, 1 == not good. It means the script couldn't guess what the strand was and simply defaulted to NonStrandedCounts . You should never see exit code 1 with anything else by non stranded counts i.e NonStrandedCounts,1 . If you do, please report this as a bug. mk_igv_links.py This script isn't used in the pipeline actually, but it comes rather handy if you want to visualise your coverage plots, bigWig ( .bw ) files or bam ( .bam ) files","title":"Python scripts"},{"location":"docs/#case-study","text":"Once your RNAsik run had finished, have a look at strandInfo.txt file cat sikRun/countFiles/strandInfo.txt If you are seeing NonStrandedCounts,1 you will need to manually check and figure out what strand your data actually is. You will need to have a look at the .summary files for each of the three counts files. This is standard, summary, output file from featureCounts . For simplicity sake just look at the first sample's raw counts, second column and we are just going to look at \"Assigned\" row, which is second row. So we are focusing on second column, second row cell. We want to compare the number in that cell across three different strands counts. If the data is stranded then that strand going to get dominant number of reads. If reverse stranded counts getting vastly more reads then forward stranded counts then the data is reverse stranded. It is possible that non stranded counts in this case get essentially the same number of reads as reverse stranded. This is okay, but the data still is reverse stranded. Even if your non stranded counts have slightly more counts then your most dominant strand, (in this case) reverse stranded, this is still a reverse stranded data. On the other hand if you are seeing roughly 50/50 split between forward and reverse reads, then this is non stranded data. Now that you know what you are looking for, lets say, your data actually appears forward stranded and you would like to get -withNames.txt and withNames-proteinCoding.txt files. You will need to use mk_cnts_file.py script ./mk_cnt_file.py -h usage: mk_cnts_file.py --counts_dir path/to/coutns_dir --gene_ids path/to/geneIds.txt This script summarises log files information into html table optional arguments: -h, --help show this help message and exit --counts_file COUNTS_FILE path to directory with featureCounts files --gene_ids GENE_IDS path to geneIds.txt file, format EnsmblId Chrm GeneName Biotype --samples_sheet SAMPLES_SHEET path to samplesSheet.txt file, format old_prefix new_prefix --biotype BIOTYPE specify biotype of interest [protein_coding], 'all' is special to include everything --counts_col COUNTS_COL Indicate which column begins read counts. default [7], which is featureCounts default, all columns before 7th are metadata cols To get all feature types ./mk_cnt_file.py --counts_file sikRun/countFiles/ForwardStrandedCounts.txt \\ --gene_ids sikRun/countFiles/geneIds.txt \\ --samples_sheet sikRun/samplesSheet.txt \\ --biotype all ForwardStrandedCounts-withNames.txt To get just protein_coding features ./mk_cnt_file.py --counts_file sikRun/countFiles/ForwardStrandedCounts.txt \\ --gene_ids sikRun/countFiles/geneIds.txt \\ --samples_sheet sikRun/samplesSheet.txt \\ --biotype protein_coding ForwardStrandedCounts-withNames-proteinCoding.txt","title":"Case study"},{"location":"docs/#metric-files-explained","text":"A lot of the tools output some sort of metrics files, to stdout/stderr or a file. Those metrics are important for analysis and QC checks going forward with the data. All of those metrics files are summarised into multiqc report. This section will attempt to explain in details each one of those metrics","title":"Metric files explained"},{"location":"docs/#star","text":"Log.final.out This is straight out of the STAR docs Log.final.out: summary mapping statistics after mapping job is complete, very useful for quality control. The statistics are calculated for each read (single- or paired-end) and then summed or averaged over all reads. Note that STAR counts a paired-end read as one read, (unlike the samtools flagstat/idxstats, which count each mate separately). Most of the informa- tion is collected about the UNIQUE mappers (unlike samtools flagstat/idxstats which does not separate unique or multi-mappers). Each splicing is counted in the numbers of splices, which would correspond to summing the counts in SJ.out.tab. The mismatch/indel error rates are calculated on a per base basis, i.e. as total number of mismatches/indels in all unique mappers divided by the total number of mapped bases.","title":"STAR"},{"location":"docs/#picard","text":"CollectAlignmentSummaryMetrics CollectGcBiasMetrics MarkDuplicates These are all picard tools that are used in the pipeline CreateSequenceDictionary SortSam MarkDuplicates BuildBamIndex CollectAlignmentSummaryMetrics CollectInsertSizeMetrics CollectGcBiasMetrics EstimateLibraryComplexity Tweet to @kizza_a Share","title":"Picard"},{"location":"draft/","text":"Log files data/ addMetrics bams covFiles degust fastqc featureCounts mdupsBams qualiMap strandInfo other/ annotation pairedBool refFiles/ bwa bwaMem chromSizes fai fastaRef fastqc gtfFile picardDictFile qualiMap samples/ fqFiles fqMap samplesSheet toolsOpts/ featureCounts multiqc versions/ bedtools2 bwa fastqc featureCounts MarkDuplicates multiqc python qualimap ReorderSam RNAsik samtools SortSam star Interesting article","title":"Draft"},{"location":"draft/#log-files","text":"data/ addMetrics bams covFiles degust fastqc featureCounts mdupsBams qualiMap strandInfo other/ annotation pairedBool refFiles/ bwa bwaMem chromSizes fai fastaRef fastqc gtfFile picardDictFile qualiMap samples/ fqFiles fqMap samplesSheet toolsOpts/ featureCounts multiqc versions/ bedtools2 bwa fastqc featureCounts MarkDuplicates multiqc python qualimap ReorderSam RNAsik samtools SortSam star Interesting article","title":"Log files"},{"location":"help/","text":"RNAsik? yep! Getting help There is an open RNAsik user's google group any can ask and answer questions there. I will try my best to respond to any questions there, but bear in mind that I could get saturated with work and might not be able to respond straight away. Also couple of house keeping things: be polite (in general) and considerate of others. Include as much information about your problem as you can. The problem needs to be reproducible, otherwise I might not be able to help you. p.s any feedback and suggestions are also welcomed there Bug reports Best place to submit bugs is with GitHub issues Try to include as much information as you can and again problem needs to be reproducible. Sometimes problem could be BigDataScript specific so also try looking at BigDataScrip user's group","title":"Help"},{"location":"help/#rnasik-yep","text":"","title":"RNAsik? yep!"},{"location":"help/#getting-help","text":"There is an open RNAsik user's google group any can ask and answer questions there. I will try my best to respond to any questions there, but bear in mind that I could get saturated with work and might not be able to respond straight away. Also couple of house keeping things: be polite (in general) and considerate of others. Include as much information about your problem as you can. The problem needs to be reproducible, otherwise I might not be able to help you. p.s any feedback and suggestions are also welcomed there","title":"Getting help"},{"location":"help/#bug-reports","text":"Best place to submit bugs is with GitHub issues Try to include as much information as you can and again problem needs to be reproducible. Sometimes problem could be BigDataScript specific so also try looking at BigDataScrip user's group","title":"Bug reports"},{"location":"install/","text":"Using bio-ansible Quick start watch it on youtube sudo apt-get install unzip make gcc git python-virtualenv sudo apt-get install zlib1g-dev libbz2-dev liblzma-dev libncurses5-dev sudo apt-get install openjdk-8-jdk ant golang-go sudo apt-get install git htop tmux vim virtualenv ~/ansible_env source ~/ansible_env/bin/activate pip install --upgrade pip pip install ansible git clone https://github.com/MonashBioinformaticsPlatform/bio-ansible cd bio-ansible/ ansible-playbook -i hosts bio.yml --tags dirs,bds,rnasik,star,bwa,hisat2,subread,samtools,htslib,bedtools,picard,qualimap,fastqc,multiqc export PATH=$HOME/bioansible/software/apps/BigDataScript-0.99999g:$PATH export PATH=$HOME/bioansible/software/apps/RNAsik-pipe-1.4.9/bin:$PATH RNAsik Tools prerequisites I tried to account for every sub-dependency in bio-ansible , definitely checked against vanilla ubuntu 16.04 linux distro, however other systems/linux distros might have slight deviation from this. If you run into trouble please double check dependencies for the tool that is failing. There is quite a spectrum of languages there in the pipeline, C/C++, java and python so far. One can image the difficulty to accommodate every distro and/or system. I'm doing my best ! BigDataScript STAR aligner subread samtools bedtools2 Picard tools QualiMap MultiQC FastQC System prerequisites In order to install system dependencies you'll need admin privilege i.e sudo General , these are you \"stock\" utils, that most running system will/should have unzip make gcc git python-virtualenv sudo apt-get install unzip make gcc git python-virtualenv samtools, htslib and bwa deps , these are some what specific libraries zlib1g-dev libbz2-dev liblzma-dev libncurses5-dev sudo apt-get install zlib1g-dev libbz2-dev liblzma-dev libncurses5-dev Java and BigDataScript , these again rather generic packages, except golang. Note that golang is pretty easy to install, comes as a pre-compiled binary here if you don't want to get it through system package mamanger openjdk-8-jdk ant golang-go sudo apt-get install openjdk-8-jdk ant golang-go Extras , these are optional dependencies, but tmux especially recommended as pipeline run could take some time to complete provided you are doing this on remote machine (server), which is also recommended htop tmux vim sudo apt-get install git htop tmux vim Running bio-ansible Follow ansible installation guid to get ansible then: git clone https://github.com/MonashBioinformaticsPlatform/bio-ansible cd bio-ansible/ ansible-playbook -i hosts bio.yml --tags dirs,bds,rnasik,star,bwa,hisat2,subread,samtools,htslib,bedtools,picard,qualimap,fastqc,multiqc Alternative installation method for RNAsik If you have all of the tools installed and you just need RNAsik you can simply git clone it. It doesn't require any other installations/compilations. BUT you do need to have BigDataScript installed and have it in your PATH for RNAsik to run git clone https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe path/to/RNAsik-pipe/bin/RNAsik Make RNAsik analysis ready bio-ansible is complete bioinformatics stack (with heavily genomics focus at this stage) deployment written in ansible script, which depending on a type of deployment might require admin privilege i.e sudo . Given that system prerequisites are satisfied one don't need sudo to install bioinformatics stack, primarily bio_tools . In this docs there is an assumption that user either has sudo rights and/or able to install system prerequisites OR already has those dependencies installed and therefore can simply use bio-ansible as per installing RNAsik section above to get all required tools dependencies. Also right now bio-ansible is focused on a particular tools/enviroment management type, which is lmod , where one can module load samtools into their environment for use, by default samtools isn't available in the current (shell) environment. This is rather common approach on HPC clusters. Because of that type of installation, if user doesn't have pre-installed lmod they will needs to either export PATH for every tool (sounds a bit annoying), OR export RNAsik into your PATH and them simply let RNAsik know where tools are through -configFile option. export PATH=$HOME/bioansible/software/apps/BigDataScript-0.99999g:$PATH export PATH=$HOME/bioansible/software/apps/RNAsik-pipe-1.4.9/bin:$PATH copy these lines into file e.g sik.config and add -configFile path/to/sik.config to RNAsik starExe = $HOME/bioansible/software/apps/STAR-2.5.2b/STAR hisat2Exe = $HOME/bioansible/software/apps/hisat2-2.1.0/bin/hisat2 bwaExe = $HOME/bioansible/software/apps/bwa-v0.7.15/bwa samtoolsExe = $HOME/bioansible/software/apps/samtools-1.4.1/bin/samtools bedtoolsExe = $HOME/bioansible/software/apps/bedtools2-2.25.0/bin/bedtools countsExe = $HOME/bioansible/software/apps/subread-1.5.2/bin/featureCounts fastqcExe = $HOME/bioansible/software/apps/fastqc-0.11.5/fastqc pythonExe = python picardExe = java -Xmx6g -jar $HOME/bioansible/software/apps/picard-2.17.10/picard.jar qualimapExe = $HOME/bioansible/software/apps/qualimap_v2.2.1/qualimap multiqcExe = $HOME/bioansible/software/apps/multiqc-1.4/bin/multiqc If the user happens to have lmod installed, simply module use $HOME/bioansible/software/modules/bio to let lmod know about new modules and then simply module load RNAsik-pipe , which will automatically \"pull\" other dependencies into your environment. You can check that by module list to see what is in your environment","title":"Install"},{"location":"install/#using-bio-ansible","text":"","title":"Using bio-ansible"},{"location":"install/#quick-start","text":"watch it on youtube sudo apt-get install unzip make gcc git python-virtualenv sudo apt-get install zlib1g-dev libbz2-dev liblzma-dev libncurses5-dev sudo apt-get install openjdk-8-jdk ant golang-go sudo apt-get install git htop tmux vim virtualenv ~/ansible_env source ~/ansible_env/bin/activate pip install --upgrade pip pip install ansible git clone https://github.com/MonashBioinformaticsPlatform/bio-ansible cd bio-ansible/ ansible-playbook -i hosts bio.yml --tags dirs,bds,rnasik,star,bwa,hisat2,subread,samtools,htslib,bedtools,picard,qualimap,fastqc,multiqc export PATH=$HOME/bioansible/software/apps/BigDataScript-0.99999g:$PATH export PATH=$HOME/bioansible/software/apps/RNAsik-pipe-1.4.9/bin:$PATH RNAsik","title":"Quick start"},{"location":"install/#tools-prerequisites","text":"I tried to account for every sub-dependency in bio-ansible , definitely checked against vanilla ubuntu 16.04 linux distro, however other systems/linux distros might have slight deviation from this. If you run into trouble please double check dependencies for the tool that is failing. There is quite a spectrum of languages there in the pipeline, C/C++, java and python so far. One can image the difficulty to accommodate every distro and/or system. I'm doing my best ! BigDataScript STAR aligner subread samtools bedtools2 Picard tools QualiMap MultiQC FastQC","title":"Tools prerequisites"},{"location":"install/#system-prerequisites","text":"In order to install system dependencies you'll need admin privilege i.e sudo General , these are you \"stock\" utils, that most running system will/should have unzip make gcc git python-virtualenv sudo apt-get install unzip make gcc git python-virtualenv samtools, htslib and bwa deps , these are some what specific libraries zlib1g-dev libbz2-dev liblzma-dev libncurses5-dev sudo apt-get install zlib1g-dev libbz2-dev liblzma-dev libncurses5-dev Java and BigDataScript , these again rather generic packages, except golang. Note that golang is pretty easy to install, comes as a pre-compiled binary here if you don't want to get it through system package mamanger openjdk-8-jdk ant golang-go sudo apt-get install openjdk-8-jdk ant golang-go Extras , these are optional dependencies, but tmux especially recommended as pipeline run could take some time to complete provided you are doing this on remote machine (server), which is also recommended htop tmux vim sudo apt-get install git htop tmux vim","title":"System prerequisites"},{"location":"install/#running-bio-ansible","text":"Follow ansible installation guid to get ansible then: git clone https://github.com/MonashBioinformaticsPlatform/bio-ansible cd bio-ansible/ ansible-playbook -i hosts bio.yml --tags dirs,bds,rnasik,star,bwa,hisat2,subread,samtools,htslib,bedtools,picard,qualimap,fastqc,multiqc","title":"Running bio-ansible"},{"location":"install/#alternative-installation-method-for-rnasik","text":"If you have all of the tools installed and you just need RNAsik you can simply git clone it. It doesn't require any other installations/compilations. BUT you do need to have BigDataScript installed and have it in your PATH for RNAsik to run git clone https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe path/to/RNAsik-pipe/bin/RNAsik","title":"Alternative installation method for RNAsik"},{"location":"install/#make-rnasik-analysis-ready","text":"bio-ansible is complete bioinformatics stack (with heavily genomics focus at this stage) deployment written in ansible script, which depending on a type of deployment might require admin privilege i.e sudo . Given that system prerequisites are satisfied one don't need sudo to install bioinformatics stack, primarily bio_tools . In this docs there is an assumption that user either has sudo rights and/or able to install system prerequisites OR already has those dependencies installed and therefore can simply use bio-ansible as per installing RNAsik section above to get all required tools dependencies. Also right now bio-ansible is focused on a particular tools/enviroment management type, which is lmod , where one can module load samtools into their environment for use, by default samtools isn't available in the current (shell) environment. This is rather common approach on HPC clusters. Because of that type of installation, if user doesn't have pre-installed lmod they will needs to either export PATH for every tool (sounds a bit annoying), OR export RNAsik into your PATH and them simply let RNAsik know where tools are through -configFile option. export PATH=$HOME/bioansible/software/apps/BigDataScript-0.99999g:$PATH export PATH=$HOME/bioansible/software/apps/RNAsik-pipe-1.4.9/bin:$PATH copy these lines into file e.g sik.config and add -configFile path/to/sik.config to RNAsik starExe = $HOME/bioansible/software/apps/STAR-2.5.2b/STAR hisat2Exe = $HOME/bioansible/software/apps/hisat2-2.1.0/bin/hisat2 bwaExe = $HOME/bioansible/software/apps/bwa-v0.7.15/bwa samtoolsExe = $HOME/bioansible/software/apps/samtools-1.4.1/bin/samtools bedtoolsExe = $HOME/bioansible/software/apps/bedtools2-2.25.0/bin/bedtools countsExe = $HOME/bioansible/software/apps/subread-1.5.2/bin/featureCounts fastqcExe = $HOME/bioansible/software/apps/fastqc-0.11.5/fastqc pythonExe = python picardExe = java -Xmx6g -jar $HOME/bioansible/software/apps/picard-2.17.10/picard.jar qualimapExe = $HOME/bioansible/software/apps/qualimap_v2.2.1/qualimap multiqcExe = $HOME/bioansible/software/apps/multiqc-1.4/bin/multiqc If the user happens to have lmod installed, simply module use $HOME/bioansible/software/modules/bio to let lmod know about new modules and then simply module load RNAsik-pipe , which will automatically \"pull\" other dependencies into your environment. You can check that by module list to see what is in your environment","title":"Make RNAsik analysis ready"},{"location":"methods/","text":"Raw fastq files have been analysed with RNAsik pipeline [@Tsyganov2018-si] to produce raw genes count matrix and various quality control metrics. For this analysis RNAsik pipeline [@Tsyganov2018-si] ran with STAR aligner option [@Dobin2013-yw] and reads were quantified with featureCounts [@Liao2014-qo]. The reference GTF and FASTA files were downloaded from Ensembl database . Raw counts were then analysed with Degust [@Powell2015] web tool to do differential expression analysis to produce list of differentially expressed genes and several quality plots including classical multidimensional scaling (MDS) and MA plots. In this analysis limma voom [@Law2014-ev] was used for differential expression analysis. Degust [@Powell2015] largely follows limma voom workflow with typical conts per million (CPM) library size normalisation and trimmed mean of M values (TMM) normalisation [@Robinson2010-yu] for RNA composition normalisation. References","title":"Methods"},{"location":"methods/#references","text":"","title":"References"},{"location":"roadmap/","text":"Roadmap Going forward 1.x.x need to have better way to check for index directory, want to know if starIdx includes or doesn't indexing with annotation. recheck Stuart's PR , polish off refFiles detection recheck this whole PR noticed that qualimap could have high RAM consumption, need to fix cpu and mem parameters passing through sik.config file. Reckon to set mem at 4 or 6 Gb add support for another aligner - minimap2 1.5.5 (end of the year) 2019 include handling of url based samples sheets, i.e -samplesSheet flag should handle local based or remote files, just like -fastaRef option better tools version logging, don't like when RNAsik checks bwa version when STAR aligner is used include logging of split lanes and R1 and R2. Want to be able to see from the log whether two reads were classified as split lanes or paired end. This is to do with recent bug that got fixed in b924027 add alignment free support for RNAseq analysis salmon/kalisto include igv_links.html as part of the RNAsik output, default to file:/// with a bit of javascript in the html to figure out the correct path 1.6.0 (February/March) 2019 Plans to add variants calling to RNAsik . It'll be opt in flag, -varsCall . Suggestions are welcomed about different name for a flag. I already have a prototype in bds, just need to plug it in. Not sure which caller to use GATK or freebayes will need to do more reading on that. Also need to document common pitfalls for using RNAseq for variant calling e.g can only can variances in coding regions that are expressed. Not a good idea to use pulled samples as you won't be able to get allele frequency will also need to find out where to get known SNP's (snpDB? for known germ line mutations) and a list of blacklisted regions an example of someone else variant calling pipeline Ideas for future releases Need better support for exonic/intronic rates estimation. Is read_distribution.py from RSeQC good idea? Right now qualiMap is ok flag to opt in. is there need for circular RNA support? add demultiplexign tools into pipeline; -demult , more info here Changelog 1.5.4 maitenance: fixed #42 important fix #41 bug changed scaling factor down fixed #39 removed qualimap rnaseq test from travis. It's a bad test which doesn't really test anything. Merged 'feature/permissive-geneids' @pansapiens PR #38 Merge pull request #31 from methylnick/patch-1 worked on python scripts improvements strand_guessing script , thanks to @stu2 docs 1.5.3 features: updated je-suite defualt values, previous ones were buggy maitenance: bug fixes in sikCounts and sikExtrOpts capturing stdout/stderr from samtools sort, picard mdups and counts also minor consmetic code re-arrangements fixed small bug in getExtrOpts function and added a test for it rewrote and simplified parsing user passed extra tools option. docs 1.5.2 features: -fqDir can now take file with links to fastq files, links can have local or remote paths coverage plots are now stranded, i.e for every bam file you'll get forward, reverse and all (non) stranded coverages trimming has now support for both single and paired-end data started to include logging of individual tools, started with sikQC.bds file. Basically redirecting individual tools stderr/stdout into logs files. maintenance: include continue integration testing - TraviCI and started writing more test that cover bds source as well as additional scripts source bug fixes and improvements of python scripts. added testing for get_geneids.py script, this isn't python unit test rather simple \"does the tool run\" type test. introduced short args notation for python scripts as an option to long args naming pulled @pansapiens PR, now we have RNASIK_BDS_CONFIG variable for passing bds.config fixed samtools sort bug that led to out-of-memory kill all (most?) picard tools now have mem and cpu parameters fixed bwa mem dependencies issue, for more info here fixed qualimap issue with DISPLAY variable, explicitly unsetting it now fixed pairIds overide, only set pairIds to default value _R1,_R2 if no -pairIds given on cmd removed paired-end checking from inside bwa, all checks happens outside of alinger scope now improved multiqc report visual, by tweaking config file, the report shouldn't look as cluttered conda: started packaging bds and RNAsik with conda, packages are available at my anaconda channel updated docs with how to conda build, install and upload wrote quick_install.bash script that does install and used in traviCI 1.5.1 several bug fixes including #18 , hisat2 related bugs, and samtools sort memory bug in relation to bug #18 added extra sanity check general code improvement and maintenance updated docs and included new installation method improved python scripts, made them user executable and updated docs with how to use them updated UCSC binaries due to libpng12 issue 1.5.0 fixed bugs and improved python scripts, also migrated them to python3 fixed issues: #16, #15, #20, #21 fixed bug in handling remote reference files added mk_igv_links.py script as general utility script added FASTQ trimmer - skewer internal code improvements, made code more readable and clean Re-wrote bam files processing, i.e sorting and marking duplicates. Changed sorting from picard SortSam to samtools sort . Kept picard MarkDuplicates for conventional marking duplicates, but add Je-suite for UMI based de-duplication. Made improvements in handling of featureCounts output for multiqc purposes. completely removed threads and memory parameters, now each task's gets it's own cpu and mem setting all through sik.config. This makes it more cluster friendly as well Added more metrics gathering; samtools qc metrics: flagstat idxstats stats Improved many different task's dependencies flow. changed few command lines options; new options: -all -counts -mdups -qc -umi -trim removed command line options: -metrics -fastqc -prePro -threads -memory all flags changes have some backward compatibility, i.e will set the closet new option. 1.4.9 Fixed BWA indexing problem. Problem around STAR and Hisat2 aligners pass index as directory whereas bwa as a file, had to fight to make all different options i.e -refFiles and -genomeIdx to work Included proper support for SAF file format handled through -gtfFile flag i.e user can pass GTF, GFF or SAF through that flag and will still get counts Imporved handling of urls for refrence files -fastaRef , -gtfFile now works with all bds supported url types. Also fixed tarball url handling through -fqDir Improved code readability in several places and included canFail flag for making degust reads counts files. Fixed a bug in exonicRates function was passing \"wrong\" gtf file path Updated docs, added more explanation on how RNAsik ticks. Included a roadmap to allow better time and features management fixed -pairIds bug, courtesy @stu2 (PR #6) and samples sheet file making Improved python script, including several small bug fixing 1.4.8 added new feature: coverage plots generation added new feature: ability to pass previously generated references directory, saves spaces and time fixed strand guessing script, should be better at guessing now moved to mkdocs for documents compilation and deployment to gh_pages added new python script to make degust file, this simplifies and strengthens the code improved readability of the code improved and fixed bugs in handling fastq files and assignment of fastq to sample names 1.4.7 fixed STAR memory allocation issue, now user can run with fewer cpus without a worry for STAR spawning multiple tasks causing out of memory issue. made BASH wrapper (not ideal) for RNAsik this is capture bds logs including report.html which is rather valuable piece of information about the run introduced another new aligner - bwa mem to do bacterial RNAseq. introduced multiqc config file in configs directory now completely removed -fqRegex and added sanity check for paired end data. If R2 is found and -paired isn't set or vice verse then error message sent several general bug fixes simplified help menu 1.4.6 generalised aligner's call, this will make it easier to add new aligners into RNAsik included support for hista2 aligner added samplesSheep logging fixed few minor bugs and improved code quality added canFail option to several non crucial tasks, allowing pipeline to continue if some task failed of fastqc and qualimap to allow them to fail as those are non essential tasks. 1.3 Content General STAR featureCounts General Improved documentations and help menu Introduced new -extraOptions command. Now user can pass in any additional commands that particular tools can have. This will make pipeline rather flexible. Included more checks along the way, such as: checking if directories and files given on the cli are valid and accessible check if FASTQ files where found in the given location if no -align option was specified check that bamFiles directory exists and has BAM files if no -prePro options specified checks for preqcBamFiles directory and not present through an error. Can now use -proBams for processed bams to specify RNAseQC ready bams Made RNAsik-pipe more sequential, i.e step one run STAR, then run featureCounts then run processing steps. Previously featureCounts and picard tools were running in paralell and I/O was suffering. It is faster to have featureCounts end its run before doing picard processing. Removed -makeIndicies and -fqDirs options and simplified input Combined -fqDir and fqDirs into single flag -fqDir under which you can specify either directory with FASTQ's or a project directory with directories with FASTQ's. In another way, now pipeline looks two level deep for FASTQ files in a given directory under -fqDir -makeIndex now only makes STAR index. In future it might accept aligner name for which to make an index other indicies for picard and RNAseQC are now made on the fly when those tools are called Don't have to specify -makeIndex if running an alignment. If -align given and no -genomeIndex is specified, then pipeline will ask for -fastaRef and make index before aligning Improved scoping. RNAsik-pipe is a mine file that runs everything, all other files define functions and don't look outside of the file. Everything is passed in from within main file - RANsik-pipe. Included an option to specify gzipped files, but not in the -extraOptions if additoinal file is need to be given through extraOptions and file is gzipped it won't be handled. The gzipped option is specific for fastaRef and gtfFile only. Those can be gzipped and pipieline will handle it. also now copy fastaRef and gtfFile into refFiles directory. This is to avoid permission issues. Because original destination might not have all the required files, such as .dict and .fai files and if not permitted pipeline won't be able to execute certain steps. Introduced -sampleNames options now user can \"fix\" BAM file names and all the downstream file and data naming to something more minegful. STAR Changed bool -star option for -align that now accepts a string. At the moment the only string it can accept is star (lower case). This is again step towards making pipeline more flexible for users demands. In future I'm planing to introduce other aligners to my pipeline so that user perhaps can choose an aligner. Auto detect is FASTQ are paired-end or not. Wrote a function that loops through -fqDir directory and counting all the R1 and R2 reads. Based on the counts it ditermines whether data is paired end or not. featureCounts included a couple of python script that uses gffutils package to make a datatbase of GTF entries and then parse that database file to get public gene names, Ensmebl Ids and gene's biotypes. It is easy to include more information about the gene with this python module. Included more post processing on count files, now they are ready for degust upload 1.2 Changed the way RNAsik-pipe gets read counts files. Now it creates only two files one for reverse stranded data and another for non stranded data. featureNo and featureReverse directories with corresponding read counts files have been removed and replaced with featureNo.txt and featureRevere.txt that already will have all of your reads in columns as expected by Degust . Minor cosmetic changes are made to both featureNo.txt and featureReverse.txt to convert then into featureNoCounts.txt and featureReverseCounts.txt respectively. Use counts file for your Degust session. Added threads option, default at [1], so that user can specify number of threads they wish to use. Added makeIndex option, which allows user to either make all indices with makeIndices , that is STAR genomeGenerate , picard CreateSequnceDictionary and samtools faidx , but given that STAR index takes a long time, can be some hours if running on minimal number of threads and user already has BAM files and just wishes to use other modules of the RNAsik-pipe , user can now just make other required indices. Tweet to @kizza_a Share","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"roadmap/#going-forward","text":"","title":"Going forward"},{"location":"roadmap/#1xx","text":"need to have better way to check for index directory, want to know if starIdx includes or doesn't indexing with annotation. recheck Stuart's PR , polish off refFiles detection recheck this whole PR noticed that qualimap could have high RAM consumption, need to fix cpu and mem parameters passing through sik.config file. Reckon to set mem at 4 or 6 Gb add support for another aligner - minimap2","title":"1.x.x"},{"location":"roadmap/#155-end-of-the-year-2019","text":"include handling of url based samples sheets, i.e -samplesSheet flag should handle local based or remote files, just like -fastaRef option better tools version logging, don't like when RNAsik checks bwa version when STAR aligner is used include logging of split lanes and R1 and R2. Want to be able to see from the log whether two reads were classified as split lanes or paired end. This is to do with recent bug that got fixed in b924027 add alignment free support for RNAseq analysis salmon/kalisto include igv_links.html as part of the RNAsik output, default to file:/// with a bit of javascript in the html to figure out the correct path","title":"1.5.5 (end of the year) 2019"},{"location":"roadmap/#160-februarymarch-2019","text":"Plans to add variants calling to RNAsik . It'll be opt in flag, -varsCall . Suggestions are welcomed about different name for a flag. I already have a prototype in bds, just need to plug it in. Not sure which caller to use GATK or freebayes will need to do more reading on that. Also need to document common pitfalls for using RNAseq for variant calling e.g can only can variances in coding regions that are expressed. Not a good idea to use pulled samples as you won't be able to get allele frequency will also need to find out where to get known SNP's (snpDB? for known germ line mutations) and a list of blacklisted regions an example of someone else variant calling pipeline","title":"1.6.0 (February/March) 2019"},{"location":"roadmap/#ideas-for-future-releases","text":"Need better support for exonic/intronic rates estimation. Is read_distribution.py from RSeQC good idea? Right now qualiMap is ok flag to opt in. is there need for circular RNA support? add demultiplexign tools into pipeline; -demult , more info here","title":"Ideas for future releases"},{"location":"roadmap/#changelog","text":"","title":"Changelog"},{"location":"roadmap/#154","text":"maitenance: fixed #42 important fix #41 bug changed scaling factor down fixed #39 removed qualimap rnaseq test from travis. It's a bad test which doesn't really test anything. Merged 'feature/permissive-geneids' @pansapiens PR #38 Merge pull request #31 from methylnick/patch-1 worked on python scripts improvements strand_guessing script , thanks to @stu2 docs","title":"1.5.4"},{"location":"roadmap/#153","text":"features: updated je-suite defualt values, previous ones were buggy maitenance: bug fixes in sikCounts and sikExtrOpts capturing stdout/stderr from samtools sort, picard mdups and counts also minor consmetic code re-arrangements fixed small bug in getExtrOpts function and added a test for it rewrote and simplified parsing user passed extra tools option. docs","title":"1.5.3"},{"location":"roadmap/#152","text":"features: -fqDir can now take file with links to fastq files, links can have local or remote paths coverage plots are now stranded, i.e for every bam file you'll get forward, reverse and all (non) stranded coverages trimming has now support for both single and paired-end data started to include logging of individual tools, started with sikQC.bds file. Basically redirecting individual tools stderr/stdout into logs files. maintenance: include continue integration testing - TraviCI and started writing more test that cover bds source as well as additional scripts source bug fixes and improvements of python scripts. added testing for get_geneids.py script, this isn't python unit test rather simple \"does the tool run\" type test. introduced short args notation for python scripts as an option to long args naming pulled @pansapiens PR, now we have RNASIK_BDS_CONFIG variable for passing bds.config fixed samtools sort bug that led to out-of-memory kill all (most?) picard tools now have mem and cpu parameters fixed bwa mem dependencies issue, for more info here fixed qualimap issue with DISPLAY variable, explicitly unsetting it now fixed pairIds overide, only set pairIds to default value _R1,_R2 if no -pairIds given on cmd removed paired-end checking from inside bwa, all checks happens outside of alinger scope now improved multiqc report visual, by tweaking config file, the report shouldn't look as cluttered conda: started packaging bds and RNAsik with conda, packages are available at my anaconda channel updated docs with how to conda build, install and upload wrote quick_install.bash script that does install and used in traviCI","title":"1.5.2"},{"location":"roadmap/#151","text":"several bug fixes including #18 , hisat2 related bugs, and samtools sort memory bug in relation to bug #18 added extra sanity check general code improvement and maintenance updated docs and included new installation method improved python scripts, made them user executable and updated docs with how to use them updated UCSC binaries due to libpng12 issue","title":"1.5.1"},{"location":"roadmap/#150","text":"fixed bugs and improved python scripts, also migrated them to python3 fixed issues: #16, #15, #20, #21 fixed bug in handling remote reference files added mk_igv_links.py script as general utility script added FASTQ trimmer - skewer internal code improvements, made code more readable and clean Re-wrote bam files processing, i.e sorting and marking duplicates. Changed sorting from picard SortSam to samtools sort . Kept picard MarkDuplicates for conventional marking duplicates, but add Je-suite for UMI based de-duplication. Made improvements in handling of featureCounts output for multiqc purposes. completely removed threads and memory parameters, now each task's gets it's own cpu and mem setting all through sik.config. This makes it more cluster friendly as well Added more metrics gathering; samtools qc metrics: flagstat idxstats stats Improved many different task's dependencies flow. changed few command lines options; new options: -all -counts -mdups -qc -umi -trim removed command line options: -metrics -fastqc -prePro -threads -memory all flags changes have some backward compatibility, i.e will set the closet new option.","title":"1.5.0"},{"location":"roadmap/#149","text":"Fixed BWA indexing problem. Problem around STAR and Hisat2 aligners pass index as directory whereas bwa as a file, had to fight to make all different options i.e -refFiles and -genomeIdx to work Included proper support for SAF file format handled through -gtfFile flag i.e user can pass GTF, GFF or SAF through that flag and will still get counts Imporved handling of urls for refrence files -fastaRef , -gtfFile now works with all bds supported url types. Also fixed tarball url handling through -fqDir Improved code readability in several places and included canFail flag for making degust reads counts files. Fixed a bug in exonicRates function was passing \"wrong\" gtf file path Updated docs, added more explanation on how RNAsik ticks. Included a roadmap to allow better time and features management fixed -pairIds bug, courtesy @stu2 (PR #6) and samples sheet file making Improved python script, including several small bug fixing","title":"1.4.9"},{"location":"roadmap/#148","text":"added new feature: coverage plots generation added new feature: ability to pass previously generated references directory, saves spaces and time fixed strand guessing script, should be better at guessing now moved to mkdocs for documents compilation and deployment to gh_pages added new python script to make degust file, this simplifies and strengthens the code improved readability of the code improved and fixed bugs in handling fastq files and assignment of fastq to sample names","title":"1.4.8"},{"location":"roadmap/#147","text":"fixed STAR memory allocation issue, now user can run with fewer cpus without a worry for STAR spawning multiple tasks causing out of memory issue. made BASH wrapper (not ideal) for RNAsik this is capture bds logs including report.html which is rather valuable piece of information about the run introduced another new aligner - bwa mem to do bacterial RNAseq. introduced multiqc config file in configs directory now completely removed -fqRegex and added sanity check for paired end data. If R2 is found and -paired isn't set or vice verse then error message sent several general bug fixes simplified help menu","title":"1.4.7"},{"location":"roadmap/#146","text":"generalised aligner's call, this will make it easier to add new aligners into RNAsik included support for hista2 aligner added samplesSheep logging fixed few minor bugs and improved code quality added canFail option to several non crucial tasks, allowing pipeline to continue if some task failed of fastqc and qualimap to allow them to fail as those are non essential tasks.","title":"1.4.6"},{"location":"roadmap/#13","text":"","title":"1.3"},{"location":"roadmap/#content","text":"General STAR featureCounts","title":"Content"},{"location":"roadmap/#general","text":"Improved documentations and help menu Introduced new -extraOptions command. Now user can pass in any additional commands that particular tools can have. This will make pipeline rather flexible. Included more checks along the way, such as: checking if directories and files given on the cli are valid and accessible check if FASTQ files where found in the given location if no -align option was specified check that bamFiles directory exists and has BAM files if no -prePro options specified checks for preqcBamFiles directory and not present through an error. Can now use -proBams for processed bams to specify RNAseQC ready bams Made RNAsik-pipe more sequential, i.e step one run STAR, then run featureCounts then run processing steps. Previously featureCounts and picard tools were running in paralell and I/O was suffering. It is faster to have featureCounts end its run before doing picard processing. Removed -makeIndicies and -fqDirs options and simplified input Combined -fqDir and fqDirs into single flag -fqDir under which you can specify either directory with FASTQ's or a project directory with directories with FASTQ's. In another way, now pipeline looks two level deep for FASTQ files in a given directory under -fqDir -makeIndex now only makes STAR index. In future it might accept aligner name for which to make an index other indicies for picard and RNAseQC are now made on the fly when those tools are called Don't have to specify -makeIndex if running an alignment. If -align given and no -genomeIndex is specified, then pipeline will ask for -fastaRef and make index before aligning Improved scoping. RNAsik-pipe is a mine file that runs everything, all other files define functions and don't look outside of the file. Everything is passed in from within main file - RANsik-pipe. Included an option to specify gzipped files, but not in the -extraOptions if additoinal file is need to be given through extraOptions and file is gzipped it won't be handled. The gzipped option is specific for fastaRef and gtfFile only. Those can be gzipped and pipieline will handle it. also now copy fastaRef and gtfFile into refFiles directory. This is to avoid permission issues. Because original destination might not have all the required files, such as .dict and .fai files and if not permitted pipeline won't be able to execute certain steps. Introduced -sampleNames options now user can \"fix\" BAM file names and all the downstream file and data naming to something more minegful.","title":"General"},{"location":"roadmap/#star","text":"Changed bool -star option for -align that now accepts a string. At the moment the only string it can accept is star (lower case). This is again step towards making pipeline more flexible for users demands. In future I'm planing to introduce other aligners to my pipeline so that user perhaps can choose an aligner. Auto detect is FASTQ are paired-end or not. Wrote a function that loops through -fqDir directory and counting all the R1 and R2 reads. Based on the counts it ditermines whether data is paired end or not.","title":"STAR"},{"location":"roadmap/#featurecounts","text":"included a couple of python script that uses gffutils package to make a datatbase of GTF entries and then parse that database file to get public gene names, Ensmebl Ids and gene's biotypes. It is easy to include more information about the gene with this python module. Included more post processing on count files, now they are ready for degust upload","title":"featureCounts"},{"location":"roadmap/#12","text":"Changed the way RNAsik-pipe gets read counts files. Now it creates only two files one for reverse stranded data and another for non stranded data. featureNo and featureReverse directories with corresponding read counts files have been removed and replaced with featureNo.txt and featureRevere.txt that already will have all of your reads in columns as expected by Degust . Minor cosmetic changes are made to both featureNo.txt and featureReverse.txt to convert then into featureNoCounts.txt and featureReverseCounts.txt respectively. Use counts file for your Degust session. Added threads option, default at [1], so that user can specify number of threads they wish to use. Added makeIndex option, which allows user to either make all indices with makeIndices , that is STAR genomeGenerate , picard CreateSequnceDictionary and samtools faidx , but given that STAR index takes a long time, can be some hours if running on minimal number of threads and user already has BAM files and just wishes to use other modules of the RNAsik-pipe , user can now just make other required indices. Tweet to @kizza_a Share","title":"1.2"},{"location":"tutorials/","text":"Tutorials So far I don't have any tutorials that I've wrote specific to this (RNAseq) topic, but here is few very useful links to learning resource. Hands-on Training in RNA-Seq Data Analysis Applied Computational Genomics Course Bioconductor RNAseq tutorial RNA-seqlopedia","title":"Tutes"},{"location":"tutorials/#tutorials","text":"So far I don't have any tutorials that I've wrote specific to this (RNAseq) topic, but here is few very useful links to learning resource. Hands-on Training in RNA-Seq Data Analysis Applied Computational Genomics Course Bioconductor RNAseq tutorial RNA-seqlopedia","title":"Tutorials"}]}