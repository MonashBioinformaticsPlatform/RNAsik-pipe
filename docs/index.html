<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="serine">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Docs - RNAsik pipeline</title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../css/highlight.css">
        <link href="../css/style.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script src="../js/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/highlight.pack.js"></script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="..">RNAsik pipeline</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="..">About</a>
                    </li>
                    <li class="active">
                        <a href="./">Docs</a>
                    </li>
                    <li >
                        <a href="../help/">Help</a>
                    </li>
                    <li >
                        <a href="../contrib/">Contributing</a>
                    </li>
                    <li >
                        <a href="../roadmap/">Roadmap</a>
                    </li>
                    <li >
                        <a href="../install/">Advance</a>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="..">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../help/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe"><i class="fa fa-github"></i> GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#documentation">Documentation</a></li>
            <li><a href="#quick-start">Quick start</a></li>
            <li><a href="#data-set-for-testing">Data set for testing</a></li>
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#installation">Installation</a></li>
            <li><a href="#user-input">User input</a></li>
            <li><a href="#user-input-explained">User input explained</a></li>
            <li><a href="#rnasik-output">RNAsik output</a></li>
            <li><a href="#rnasik-output-explained">RNAsik output explained</a></li>
            <li><a href="#command-line-options">Command line options</a></li>
            <li><a href="#rnasik-config-file">RNAsik config file</a></li>
            <li><a href="#python-scripts">Python scripts</a></li>
            <li><a href="#metric-files-explained">Metric files explained</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<p><img alt="mbp-banner" src="../images/mbp_banner.png" /></p>
<h1 id="documentation">Documentation</h1>
<h2 id="quick-start">Quick start</h2>
<h3 id="install">Install</h3>
<ul>
<li><a href="https://raw.githubusercontent.com/MonashBioinformaticsPlatform/RNAsik-pipe/master/scripts/quick_install.bash">Download and run <code>quick_install.bash</code> script</a></li>
<li><code>export PATH=$(readlink -f miniconda)/bin:$PATH</code> </li>
</ul>
<h3 id="align-raw-reads">Align raw reads</h3>
<pre><code class="BASH">RNAsik -align star \
       -fastaRef /path/to/reference.fasta \
       -fqDir /path/to/raw-data/directory
</code></pre>

<h3 id="count-gene-features">Count gene features</h3>
<pre><code class="BASH">RNAsik -counts \
       -gtfFile path/to/annotation.gtf
</code></pre>

<h3 id="the-lot">The lot</h3>
<pre><code class="BASH">RNAsik -fqDir /path/to/raw-data/directory \
       -align star \
       -refFiles /path/to/refDir \
       -counts \
       -all
</code></pre>

<h2 id="data-set-for-testing">Data set for testing</h2>
<blockquote>
<p>N.B <code>RNAsik</code> pipeline is some what resource hungry. This isn't <code>RNAsik</code> fault per say, because it "simply" wraps other tools. STAR aligner required fair amount of RAM and cpus. For a large genome like mouse it required around 30 Gb of RAM and the more cpus you have the quicker you'll map. I would advise not run the pipeline with less than 4 cores, which is default. This testing data set is of yeast and requires about 14 Gb of RAM. Also read <a href="https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe/issues/7#issuecomment-367172511">this comment</a>, in summary you might have <code>RNAsik</code> failing on system that are under minimum system resources, this is work in progess and should be fixed in the future.</p>
</blockquote>
<p>I figured that for testing you need smallish data set as well as species with a small genome, as indexing of genome takes a while for larger genome e.g mouse
I found this study <a href="https://www.ncbi.nlm.nih.gov//geo/query/acc.cgi?acc=GSE103004">GSE103004</a> which looks like an open access. If you follow <a href="https://www.ncbi.nlm.nih.gov//geo/query/acc.cgi?acc=GSE103004">that link</a> you should hit front GEO page for that study. You can find your way to actual data (SRA files) files, but I always find it's a bit convoluted, so hit <a href="https://www.ncbi.nlm.nih.gov/Traces/study/?acc=SRP116034">here is a link to data files</a>. </p>
<p>I've already prepared raw-data (fastq) files for you. I also reduced number of samples and sub-sampled reads to speed up your test run. Firstly though let me explain to you how to get full data set.</p>
<ul>
<li>
<p><a href="https://www.ncbi.nlm.nih.gov/sra/docs/toolkitsoft/">download sratoolkit</a> which is set of tools from <a href="https://www.ncbi.nlm.nih.gov/">NCBI</a> that you'll need to download <a href="https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/">sra files</a> and then extract/convert those to fastq files.</p>
</li>
<li>
<p><code>fastq-dump --gzip --split-files SRR3407195</code> this is a command that you'll want to run to get one particular sra file, not <code>--split-files</code> options, you need to use that if you data is paired end. If you don't use that flag, then you are going to end up with a single fastq file that has reads interleaved or truncated/merged in a funny way (had some issues like that in the past)</p>
</li>
</ul>
<p>However you don't want run that command several times, so use a loop</p>
<pre><code>while read s; do fastq-dump --gzip --split-files $s &gt; $s.log 2&gt;&amp;1 &amp;done &lt; SRR_Acc_List.txt
</code></pre>

<p>You can download <a href="https://www.ncbi.nlm.nih.gov/Traces/study/?acc=SRP116034">SRR_Acc_List.txt file at this page</a> (mentioned that page before). That list has 9 sra files corresponding to 9 samples, where each samples was paired end and therefore total number of files is double - 18. </p>
<p>Also note that default marking when extracting from sra for R1 and R2 is <code>_1</code> and <code>_2</code> respectively and so if you are running <code>RNAsik</code> on that full data set you'll need to pass <code>-pairIds "_1,_2"</code> flag, default is <code>-pairIds "_R1,_R2"</code> </p>
<p>If you want nicely labeled bam and then counts you can pass <code>-samplesSheet samplesSheet.txt</code>. I haven't implemented url based samples sheets, so you'll need to download one before hand from <a href="http://bioinformatics.erc.monash.edu/home/kirill/sikTestData/samplesSheet.txt">here</a>. I'll include handling of url based samples sheets into roadmap, so watch that space !</p>
<p>If you ran <code>RNAsik</code> on a full data set and then used <a href="http://degust.erc.monash.edu">Degust</a> for DGE analysis you should get <a href="http://bioinformatics.erc.monash.edu/home/kirill/sikTestData/">these results</a>.</p>
<p><em>Note that report was generated using <code>pandoc</code> with custome template and <code>igv_links</code> were created using <code>mk_igv_links</code> script located in <a href="https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe/tree/master/scripts"><code>scripts/</code></a> directory</em></p>
<h3 id="try-it-out">Try it out</h3>
<pre><code class="BASH">RNAsik -align star \
       -fastaRef ftp://ftp.ensembl.org/pub/release-91/fasta/saccharomyces_cerevisiae/dna/Saccharomyces_cerevisiae.R64-1-1.dna_sm.toplevel.fa.gz \
       -fqDir http://bioinformatics.erc.monash.edu/home/kirill/sikTestData/rawData/IndustrialAntifoamAgentsYeastRNAseqData.tar \
       -counts \
       -gtfFile ftp://ftp.ensembl.org/pub/release-91/gtf/saccharomyces_cerevisiae/Saccharomyces_cerevisiae.R64-1-1.91.gtf.gz \
       -all \
       -paired
</code></pre>

<h2 id="introduction">Introduction</h2>
<p>As mentioned previously in <a href="..#about">about section</a> very first step in <a href="https://rnaseq.uoregon.edu/">RNA-seq analysis</a> is to map your raw reads (<a href="https://en.wikipedia.org/wiki/FASTQ_format">FASTQ</a>) to the reference genome following by counting of reads that map onto a feature. But there is always more you could do with your data, in fact almost always only by doing more you can get deeper inside into your biological experiment and the system you are studying. And so <a href="https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe">RNAsik</a> uses these tools to get as much out of your data as possible in an streamline run:</p>
<ul>
<li><a href="https://github.com/alexdobin/STAR/releases">STAR aligner for mapping</a></li>
<li><a href="http://subread.sourceforge.net/">featureCounts from subread package for read counting</a></li>
<li><a href="http://www.htslib.org/download/">samtools for coverage calculation and general bam files filtering</a></li>
<li><a href="http://broadinstitute.github.io/picard/">picard tools also for general bam fiels filtering</a></li>
<li><a href="http://qualimap.bioinfo.cipf.es/">QualiMap for intragenic and interegenic rates</a></li>
<li><a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/">FastQC for QC metrics on yor fastq files</a></li>
<li><a href="http://multiqc.info/">MultiQC for wraping everying into nice, single page report</a> </li>
</ul>
<p>As one can imagine every one of those tools has several number of options and by running <a href="https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe">RNAsik-pipeline</a> you get predefined - subjective run. Obviously it all comes from years of experience and continues development and improvement. Use can always pass his/her own options through <code>-extraOptions</code> flag for more fine turning. 
Alternatively as, hinted above, user can leverage of <a href="https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe">RNAsik</a> to run everything separately with fine control over the individual run. <a href="https://github.com/MonashBioinformaticsPlatform/RNAsik-pipe">RNAsik</a> produces <a href="https://en.wikipedia.org/wiki/HTML">.html report</a> with all commands options specified.</p>
<h2 id="installation">Installation</h2>
<h3 id="using-conda">Using conda</h3>
<ul>
<li>download <a href="https://conda.io/miniconda.html">miniconda</a> <code>.sh</code> installer </li>
<li>run it and follow the prompts</li>
</ul>
<pre><code>bash Miniconda3-latest-Linux-x86_64.sh
</code></pre>

<ul>
<li>add a few <code>conda</code> "channels", this is so <code>conda</code> knows where to get things from</li>
</ul>
<pre><code>conda config --add channels defaults
conda config --add channels conda-forge
conda config --add channels bioconda
</code></pre>

<ul>
<li>install <code>RNAsik</code> pipeline</li>
</ul>
<pre><code>conda install -c serine rnasik 
</code></pre>

<ul>
<li>additionally install <code>qualimap</code> separately (it was a tricky to include qualimap into RNAsik because large number of dependencies that qualimap has)</li>
</ul>
<pre><code>conda install -c bioconda qualimap 

</code></pre>

<p>Right now <code>RNAsik</code> hosted from my "channel" (conda terminology). There are plans to push it to official <a href="https://bioconda.github.io/">bioconda channel</a></p>
<h4 id="conda-extras">conda extras</h4>
<ul>
<li>search "main" label (repository)</li>
</ul>
<pre><code>conda search -c serine rnasik
</code></pre>

<ul>
<li>search "dev" label (repository)</li>
</ul>
<pre><code>conda search -c serine/label/dev rnasik
</code></pre>

<ul>
<li>install specific version</li>
</ul>
<pre><code>conda install -c serine/label/dev &quot;rnasik=1.5.1+3ecd215&quot;
</code></pre>

<ul>
<li>install specific version and specific build number</li>
</ul>
<pre><code>conda install -c serine/label/dev &quot;rnasik=1.5.1+3ecd215=4
</code></pre>

<ul>
<li>simply install latest from that "dev" label (repository)</li>
</ul>
<pre><code>conda install -c serine/label/dev rnasik
</code></pre>

<p><strong>NOTE:</strong> that these are just some extras commands mainly for testing purposes not for production use !</p>
<h3 id="alternative-installation-methods">Alternative installation methods</h3>
<ul>
<li><a href="../install/">HERE</a></li>
</ul>
<h2 id="user-input">User input</h2>
<h3 id="reference-files">Reference files</h3>
<table>
<tr><th class="left_col">Input File</th><th>Description</th></tr>
<tr><td class="left_col">FASTA file</td><td>Most often this is your genomic reference sequence. It is a FASTA file holding raw DNA sequences where different features e.g chromosomes are labeled uniquely with a header line starting with '>'. [FASTA Format Description](https://en.wikipedia.org/wiki/FASTA_format) </td></tr>
<tr><td class="left_col">GTF/GFF/SAF file</td><td> This is your gene annotation file (i.e coordinates of your genes, exons and other genomic features). This should be linked and associated with your genomic reference file. SAF (simple annotation format) is something that featureCounts use and it supported by the pipeline</td></tr>
</table>

<h3 id="raw-data">Raw data</h3>
<table>
<tr><th>Input File</th><th>Description</th></tr>
<tr><td class="left_col">FASTQ file</td><td>These are your raw files that are provided by the sequencing facility to you, they can be gzipped (.fq, .fastq, .fq.gz, .fastq.gz) </td></tr>
</table>

<h2 id="user-input-explained">User input explained</h2>
<h3 id="annotation-files">Annotation files</h3>
<p>Annotation file would central for differential expression (DE) analysis without one you won't be able to do one. You could have very well assembled genome with very good mapping rate, but unless you know where your genes are on that genome i.e start and end coordinates for your features e.g genes you won't be able to deduce any information about those features and therefore compare between conditions. Below is an example of bear minimum information you need for feature counting. </p>
<pre><code>GeneID  Chr Start   End Strand
497097  chr1    3204563 3207049 -
497097  chr1    3411783 3411982 -
497097  chr1    3660633 3661579 -
</code></pre>

<p>There few entities that provide genome annotation, some cover more species than other. There will be of course individuals that simply provide annotation for one particular species, perhaps for more rare model organisms.</p>
<p>There are also different annotation file formats out there, which makes a little hard to provide <code>RNAsik</code> support for all of them. Currently <code>RNAsik</code> can only work with <code>GFF</code>, <code>GTF</code> or <code>SAF</code> file formats. There are many compatibilities issues between formats, but more importantly certain bits of information are only found in some of the files. The example above show <code>SAF</code> file format and as you can see that includes not human redable gene names nor biotype. <code>GFF</code> also often doesn't have biotype information, but on the other hand has product tag, which has short description, for protein coding at least, of resulting protein product, <code>GTF</code> lacks that information. Because of all these little nuances it can be hard to capture all of the desirable information.</p>
<p>Most tools in the pipeline prefer <code>GTF</code>, some can only work with <code>GTF</code>. I guess main reason for this is that every line is self contained and the format has been fairly predictable/stable.</p>
<p>If for whatever reason you can't get hold of <code>GFF/GTF</code> files and your annotation comes in <code>GenBank</code> (very common for bacterial genomes) or <code>Bed</code> files, don't panic and try to parse those files into <code>SAF</code> format. There are plans to include <code>gb_parse.py</code> script that should help most people with <code>GenBank</code> files.</p>
<p>Irrespective of which reference file distributor and which annotation file you are going to use, it is highly recommended that both of those files come from the same distributor. Most common distributors are <a href="http://www.ensembl.org/index.html">Ensembl</a>, <a href="http://genome.ucsc.edu/">UCSC</a> and <a href="ftp://ftp.ncbi.nih.gov/genomes/">NCBI</a>.</p>
<h3 id="raw-data-files">Raw data files</h3>
<p>Raw data is something that you should take good care of. You can regenerate all other data files, but you can't really regenerate you raw data, not unless you have lots of money and time. So be sure to back your <code>fastq</code> files up and never mess/do (i.e modify) your original fastq files. If you want to try something out, make a copy and do whatever you are doing on a copy. Also there will never be a need to unzip your fastq file. All of you fastq file should be gziped and have file extension <code>.fastq.gz</code> or <code>fq.gz</code> or something similar. </p>
<p><code>RNAsik</code> will search recursively your <code>-fqDir</code> and find all fastq files. <code>RNAsik</code> can handle nested directories as long as your data is homogeneous i.e all data belongs to the same library type single-end or paired-end. If data is paired end, <code>RNAsik</code> uses <code>-pairIds</code> value to figure out read pairs. You can check that all of your fastq files had been found by looking into <code>sikRun/logs/samples/fqFiles</code>. </p>
<p>After obtaining a list of all fastq files <code>RNAsik</code> tries to be smart and attempts to group fastq files into samples, that is R1 and R2 reads are grouped, but also any fastq files that had been split across lanes should also be grouped. You should end up, after the run, with the same number of bam files as you have samples. Again you can check grouping in <code>sikRun/logs/samples/fqMap</code></p>
<p><code>RNAsik</code> fastq grouping works in two modes:</p>
<ul>
<li>smart guessing it is a little involved but essentially it uses regular expression to check if fastq files have common suffix and therefore belong to the same sample. It heavily relies on clear labeling of R1 and R2 reads for paired-end data. </li>
<li>a more straight forward mode is simply to use samples sheet file, which is any text file with two columns separated by a tab character, <code>old_prefix\tnew_prefix</code>. Prefix in this case is your sample name, unique bit of the file. </li>
</ul>
<p>Samples sheet in a bit more details; If you have four samples, two wild-type and two controls, you should have four bam files after the analysis. However you number of fastq files is rather variable, depending on your sequencing. For paired-end sequencing you are going to end up with 2 fastq files per sample and 8 fastq files all up. If your sequencing was also split across lanes, say two lanes, then you are going to have 4 fastq file per each samples and 16 fastq files in total. <code>RNAsik</code> tries to simplify this for you.</p>
<h2 id="rnasik-output">RNAsik output</h2>
<h3 id="directories-breakdown">Directories breakdown</h3>
<table>
<tr><th>Directories</th><th>Description</th></tr>
<tr><td class="left_col">refFiles/</td><td> Contains the reference files (FASTA and GTF) and indices (aligner index) used in the analysis run </td></tr>
<tr><td class="left_col">alignerFiles/</td><td> Containts all other, additional files from alignment run, but the bam files. e.g aligner specific log files, splice junction files </td></tr>
<tr><td class="left_col">bamFiles/</td><td> Contains pre-processed BAM files, i.e sorted and duplicates marked as well as indexed, all using samtools and picard tools. These BAMs can be used in [IGV](http://software.broadinstitute.org/software/igv/) to view read alignments </td></tr>
<tr><td class="left_col">countFiles/</td><td> Contains read count files, "raw" - from `featureCounts`, degust ready counts and filtered for protein_coding features only</td></tr>
<tr><td class="left_col">coverageFiles/</td><td> Contains bigWig files for every bam (sample) file - from `bedtools genomecov` and `bedGrapToBigWig` USCS binary. Can load those into IGV</td></tr>
<tr><td class="left_col">fastqReport/</td><td> Contains FastQC HTML reports for individual FASTQ files</td></tr>
<tr><td class="left_col">qualiMapResults/</td><td> Contains int(ra|er)genic rates from each BAM file. Each BAM has its own directory with metric files. These results generated using `QualiMap rnaseq` command</td></tr>
<tr><td class="left_col">fastqDir/</td><td> If you are going to pull your FASTQ file over http in tarball, then tarball will be unarchived here</td></tr>
<tr><td class="left_col">multiqc_data/</td><td>Directory created by MultiQC holding a parsed text file, it doesn't serve any purpose for html file</td></tr>
<tr><td class="left_col">logs/</td><td>Directory that holds subdirectories, self explanatory, with logs files</td></tr>
</table>

<h3 id="files-breakdown">Files breakdown</h3>
<table>
<tr><th>Files</th><th>Description</th></tr>
<tr><td class="left_col">geneIds.txt</td><td> Hold four additional columns that get added into read counts file, that has postfix "-withNames. Gene.id, Chrom, Gene.Name, Biotype.</td></tr>
<tr><td class="left_col">strandInfo.txt</td><td> Contains guesses, based on `featureCounts` `.summary` files, strand informataion</td></tr>
<tr><td class="left_col">multiqc_report.html</td><td>This is the report file produced by MultiQC tool. A stand alone html file and can be viewed in any browser</td></tr>
</table>

<h2 id="rnasik-output-explained">RNAsik output explained</h2>
<blockquote>
<p>I hope that the directories and files naming is some what self explanatory, but here is a bit more detailed explanation of those.</p>
</blockquote>
<h3 id="bam-files">Bam files</h3>
<p>First thing you most certainly going to get out of the pipeline is your bam files, those will be placed into <code>bamFiles/</code> directory. I don't really understand why, but <code>featureCounts</code> works best (fastest) with name sorted BAM files a.k.a unsorted. There is really two types of sorting, sorted by coordinates, often preferred as you can index those bam files and then have quick access to random parts of the file, second type is sorted by name, which insures that in paired-end experiment R1 and R2 pairs are interleaved, one after another, but you can't index those). <code>STAR</code> aligner can output either of those files. I'm however outputting "unsorted" bam file and then in the second step sorting it with <code>picard SamSort</code> tool. There are a couple of reasons for that:</p>
<ul>
<li>other aligners don't sort e.g bwa and therefore assuming sorted bam file won't work well</li>
<li>even though <code>STAR</code> is pretty amazing (honestly), but I still rather prefer one tool for one job,
hence why I also don't count reads with <code>STAR</code></li>
</ul>
<p>The bam files from <code>bamFiles/</code> are only used with <code>featureCounts</code> and then <code>picard</code> suite converts them into sorted and marked duplicate bam files, which are now placed into <code>mdupsFiles/</code> directory. The rest of the analysis based on these bam files. I'm still deciding what to do with "raw" bam files in <code>bamFiles/</code> directory. They should be removed after run have finished, but if you have to re-run the pipeline to get additional things (which you can, it will resolve all dependencies and only run new tasks) those bams are now gone and will get regenerated, which will trigger the rest of pipeline to re-run, which is unwanted result. This is why I'm not auto-removing those bam files, rather doing manually after I'm sure.  </p>
<h3 id="count-files">Count files</h3>
<p>Probably the second most important thing in the pipeline is getting read counts. That is given some genome annotation count how many of mapped reads actually ended up mapping into know annotation. For classical differential expression analysis we are interested in protein coding genes only, which pipeline attempts to filter for, but there are other biotypes that we can differentially compare.</p>
<p>The pipeline attempts to guess the strand (directionality) of your library. In theory sequencing provider that had made your libraries should be able to tell you that, but sometimes they get it wrong or simply that information never reaches us (bioinformaticians) hence the guessing.</p>
<p>Pipelines runs <code>featureCounts</code> three times forcing reads to forward strand only, forcing to reverse strand only and allowing counting on both strand (non stranded library). <code>featureCounts</code> is very nice and it provides summary table that has number of assigned to feature reads. One can simply compare forward and reverse stranded counts and deduce the strand of the library. In essence this formula is used <code>forward-reverse/forward+reverse</code> to obtain the ration, if ration is about 0.9 then library is stranded and sign indicates the strand type, if however ration is about 0.1 then library is non stranded, anything else will indication undetermined and <code>strandInfo.txt</code> file with default to <code>NonStranded,1</code> note the number one after the comment indicating status code, meaning exit with error. If you see that in your <code>strandInfo.txt</code> file you'll need to manually inspect your <code>*.summary</code> files from <code>featureCounts</code> and make decision about which library type to go with. Actual implementation of strand guessing can be found in this script <code>scripts/strand_guessing.py</code>.</p>
<p><code>featureCounts</code> by default for any given run outputs two files, counts (e.g <code>NonStrandedCounts.txt</code>) and summary (e.g <code>NonStrandedCounts.txt.summary</code>). <code>RNAsik</code> attempts to "clean up" counts file, which includes removing and addition of certain columns to make counts files more informative. The columns that are added can be found in <code>geneIds.txt</code>. If for what ever reason your <code>geneIds.txt</code> is empty then all the other files with postfix <code>-withNames</code> going to be empty too. You could try to regenerate <code>geneIds.txt</code> file using <code>scripts/get_gene_ids.py</code> script and then <code>scripts/mk_counts_file.py</code> to obtain "clean" table of counts. Doing so isn't strictly needed however additional information such as human understandable gene name and biotypy often come very handy in understanding differential expression. Having a biotype in counts file also allows you to filter for specific biotype e.g <code>protein_coding</code> or <code>snRNA</code> provided your annotation file has that information.</p>
<h2 id="command-line-options">Command line options</h2>
<h3 id="read-alignment">Read alignment</h3>
<table>
<tr><th>Options</th><th>Usage</th></tr>
<tr><td class="left_col">-align</td><td>specify your aligner of choice [star|starWithAnn|hisat|bwa]</td></tr>
<tr><td class="left_col">-fqDir</td><td>specify path to your raw data directory. `RNAsik` will search that path recursively, so don't worry about nested directores</td></tr>
<tr><td class="left_col">-fastaRef</td><td>specify path to your reference FASTA file, i.e file that holds your refrence genome</td></tr>
<tr><td class="left_col">-paired</td><td>specify if data is paired end (RNASik looks for R1 and R2 in the FASTQ filename representing Read 1 and Read 2 </td></tr>
</table>

<h3 id="read-counting">Read counting</h3>
<table>
<tr><th>Options</th><th> Usage </th></tr>
<tr><td class="left_col">-counts</td> <td> flag if you'd like to get read counts</td></tr>
<tr><td class="left_col">-gtfFile</td> <td> specify path to your reference annotation file [GTF|GFF|SAF]</td></tr>
</table>

<h3 id="reads-metrics">Reads metrics</h3>
<table>
<tr><th>Options</th><th> Usage </th></tr>
<tr><td class="left_col">-all</td> <td> This is an aggregate flag that is a short hand to get everything pipeline has to offer</td></tr>
<tr><td class="left_col">-qc</td> <td>Flag to collect several different QC metrics on your BAM and counts data</td></tr>
<tr><td class="left_col">-exonicRate</td> <td> flag if you'd like to get Int(ra|er)genic rates for your reads, using QualiMap tool</td></tr>
<tr><td class="left_col">-multiqc</td> <td> flag if you'd like to get general report that summarises different log files including `STAR`, `featureCounts`, `FastQC` and `QualiMap`</td></tr>
</table>

<h3 id="extra-options">Extra options</h3>
<table>
<tr><th>Options</th><th> Usage </th></tr>
<tr><td class="left_col">-refFiles</td> <td> path to refFiles/ directory previously generated by RNAsik run</td></tr>
<tr><td class="left_col">-mdups</td> <td> flag to mark duplicates</td></tr>
<tr><td class="left_col">-trim</td> <td> perform FASTQ adapter and quality trimming</td></tr>
<tr><td class="left_col">-cov</td> <td> get coverage plots, bigWig </td></tr>
<tr><td class="left_col">-umi</td> <td> flag to deduplicate using UMI information</td></tr>
<tr><td class="left_col">-samplesSheet</td> <td> specify name of a tab separated text file, two columns,the first with old prefixes to be removed by new prefixes in the second column</td></tr>
<tr><td class="left_col">-genomeIdx</td> <td> specify path to pre-existing alignment index </td></tr>
<tr><td class="left_col">-outDir</td><td>give a name to your analysis output directory [sikRun] </td></tr>
<tr><td class="left_col">-extn</td> <td> provide your fastq files extntion. [".fastq.gz"]  </td></tr>
<tr><td class="left_col">-pairIds</td> <td> provide type identification, default is [`_R1,_R2`]</td></tr>
<tr><td class="left_col">-extraOpts</td> <td> provide key=value pairs, one per line, with key being tool name and value is a string of options e.g `star="--outWigType bedGraph"` </td></tr>
<tr><td class="left_col">-configFile</td><td>specify your own config file with key=value pairs, one per line, for all tools</td></tr>
</table>

<h3 id="unusual-user-case">Unusual user case</h3>
<table>
<tr><td class="left_col">-bamsDir</td> <td> specify path to BAMs directory. Use if bams were generated outside of the pipeline </td></tr>
</table>

<h2 id="rnasik-config-file">RNAsik config file</h2>
<p>Below is a list of all options that are supported so by <code>RNAsik</code> so far with the defatul values.
User can pass additional config file through <code>-configFile</code> options which takes precedence.
User config dosen't have to hold all key=value pairs, just the one user wants to change. </p>
<p>For example if I want to use different <code>STAR</code> executable. I would create new file (name of the file isn't relevant),
and inside I just put. </p>
<p><code>starExe = new/path/to/STAR</code></p>
<p><code>RNAsik</code> will inherit the rest of the options from the global config.</p>
<p>Two things to note:</p>
<ul>
<li>you can't have comment on the same line as options</li>
<li>don't quote values</li>
</ul>
<h4 id="executable-paths">Executable paths</h4>
<ul>
<li><code>starExe = STAR</code></li>
<li><code>hisat2Exe = hisat2</code></li>
<li><code>bwaExe = bwa</code></li>
<li><code>samtoolsExe = samtools</code></li>
<li><code>bedtoolsExe = bedtools</code></li>
<li><code>countsExe = featureCounts</code></li>
<li><code>fastqcExe = fastqc</code></li>
<li><code>pythonExe = python</code></li>
<li><code>picardExe = picard</code></li>
<li><code>jeExe = je</code></li>
<li><code>qualimapExe = qualimap</code></li>
<li><code>multiqcExe = multiqc</code></li>
<li><code>skewerExe = skewer</code></li>
<li><code>cpFileExe = cp</code></li>
</ul>
<h4 id="memory-settings">Memory settings</h4>
<ul>
<li><code>starIdxMem = 40000000000</code></li>
<li><code>starAlignMem = 40000000000</code></li>
<li><code>bwaIdxMem = -1</code></li>
<li><code>bwaAlignMem = -1</code></li>
<li><code>hisat2IdxMem = -1</code></li>
<li><code>hisat2AlignMem = -1</code></li>
<li><code>samtoolsSortMem = 3000000000</code></li>
<li><code>samtoolsQcMem = -1</code></li>
<li><code>picardMarkDupsMem = 6000000000</code></li>
<li><code>picardQcMem = 6000000000</code></li>
<li><code>jeMem = picardMarkDupsMem</code></li>
<li><code>picardQcMem = -1</code></li>
<li><code>picardCreateDictMem = 4000000000</code></li>
<li><code>countsMem = -1</code></li>
<li><code>bedtoolsMem = 4000000000</code></li>
<li><code>fastqcMem = -1</code></li>
<li><code>multiqcMem = -1</code></li>
<li><code>skewerMem = -1</code></li>
<li><code>cpFileMem = 4000000000</code></li>
</ul>
<h4 id="threads-settings">Threads settings</h4>
<ul>
<li><code>starIdxCpu = 24</code></li>
<li><code>starAlignCpu = 10</code></li>
<li><code>bwaIdxCpu = 30</code></li>
<li><code>bwaAlignCpu = 10</code></li>
<li><code>hisat2IdxCpu = 30</code></li>
<li><code>hisat2AlignCpu = 10</code></li>
<li><code>samtoolsSortCpu = 4</code></li>
<li><code>samtoolsQcCpu = 2</code></li>
<li><code>picardMarkDupsCpu = 2</code></li>
<li><code>jeCpu = picardMarkDupsCpu</code></li>
<li><code>picardQcCpu = 2</code></li>
<li><code>picardCreateDictCpu = 2</code></li>
<li><code>bedtoolsCpu = 2</code></li>
<li><code>countsCpu = 5</code></li>
<li><code>fastqcCpu = 8</code></li>
<li><code>multiqcCpu = 2</code></li>
<li><code>skewerCpu = 5</code></li>
<li><code>cpFileCpu = 2</code></li>
</ul>
<h2 id="python-scripts">Python scripts</h2>
<p>There a few python scripts that are used in the pipeline to do various things, mostly to do with read counts post processing.
Hopefully script name are self explanatory or have a good hint to what they do. All script have help menu, simply run the scripts
with <code>-h|--help</code> to get more information. All script also output to stdout (print to the screen) in order to save the output you'll
need to redirect to a file with <code>&gt;</code> symbol.
All script set to be executable so you should be able just run them. If for some reason you cannot run them just use <code>python</code> prefix
in front of the script name. Here are some examples on how to run python scripts</p>
<pre><code class="BASH">./get_geneids.py
</code></pre>

<p>OR</p>
<pre><code class="BASH">/full_path/to/get_geneids.py
</code></pre>

<p>OR</p>
<pre><code class="BASH">python get_geneids.py
</code></pre>

<ul>
<li><code>get_geneids.py</code></li>
</ul>
<p>Converts GTF|GFF files into four columns, tab delimited file <code>Gene.Id\tChrom\tGene.Name\tBiotype</code>
Note that <code>Gene.Name</code> and <code>Biotype</code> are subject to availability, i.e if that information isn't present
in your annotation file then script (obviously) can't parse it out.
We need this information to augment our counts file. This isn't essential for DGE but makes
our exploratory analysis easier.</p>
<ul>
<li><code>mk_cnts_file.py</code></li>
</ul>
<p>Once we have our counts files from <code>featureCounts</code> and we've created <code>geneIds.txt</code> file with previous command
We can add that extra meta information to our counts file.
Note that this script filter on biotype, default is [protein_coding]. Also note that if biotype information is
absent then your <code>-withNames-proteinCoding.txt</code> file will be empty since no such biotype was found.
You can use <code>--biotype all</code> to get unfiltered - all genes. This is usually located in <code>-withNames.txt</code> file</p>
<ul>
<li><code>strand_guessing.py</code></li>
</ul>
<p>This script takes three different counts files i.e Forward, Reverse and Non stranded counts and attempts to
guess which strand the data is. We can get this information from the sequencing facility and most Illumina
library preparation kits are reverse stranded these days, but sometimes things happened and this approach
gives us correct answers from the data itself.
The output of this script is three values, comma separated; StrandType,StrandValue,ExitCode. e.g <code>ReverseStandedCounts,-0.924,0</code>
The first value is obvious, tells you the type of strand it guessed. The second value is calculated like this</p>
<pre><code>strnd_val = float(forward - reverse) / float(forward + reverse)
</code></pre>

<p>which in essence allows us to estimate strand type. It is useful to look at that value as well.
Magnitude is the confidence and the sign is directrion, negative is reverse, positive is forward stranded
The third value what's called an exit code, zero == all good. It means the script is pretty confident that it guessed it right. The other
possible value could be 1, 1 == not good. It means the script couldn't guess what the strand was and simply
defaulted to <code>NonStrandedCounts</code>. You should never see exit code 1 with anything else by non stranded counts
i.e <code>NonStrandedCounts,1</code>. If you do, please report this as a bug.</p>
<ul>
<li><code>mk_igv_links.py</code></li>
</ul>
<p>This script isn't used in the pipeline actually, but it comes rather handy if you want to visualise your
coverage plots, bigWig (<code>.bw</code>) files or bam (<code>.bam</code>) files</p>
<h4 id="case-study">Case study</h4>
<p>Once your <code>RNAsik</code> run had finished, have a look at <code>strandInfo.txt</code> file</p>
<pre><code class="BASH">cat sikRun/countFiles/strandInfo.txt
</code></pre>

<p>If you are seeing <code>NonStrandedCounts,1</code> you will need to manually check and figure out what strand your
data actually is. You will need to have a look at the <code>.summary</code> files for each of the three counts files.
This is standard, summary, output file from <code>featureCounts</code>. For simplicity sake just look at the first sample's
raw counts, second column and we are just going to look at "Assigned" row, which is second row. So we are focusing
on second column, second row cell. We want to compare the number in that cell across three different strands counts.</p>
<p>If the data is stranded then that strand going to get dominant number of reads. If reverse stranded counts getting
vastly more reads then forward stranded counts then the data is reverse stranded. It is possible that non stranded
counts in this case get essentially the same number of reads as reverse stranded. This is okay, but the data still is
reverse stranded. Even if your non stranded counts have slightly more counts then your most dominant strand, (in this case)
reverse stranded, this is still a reverse stranded data.</p>
<p>On the other hand if you are seeing roughly 50/50 split between forward and reverse reads, then this is non stranded
data.</p>
<p>Now that you know what you are looking for, lets say, your data actually appears forward stranded and you would like to get
<code>-withNames.txt</code> and <code>withNames-proteinCoding.txt</code> files. You will need to use <code>mk_cnts_file.py</code> script</p>
<pre><code class="BASH">./mk_cnt_file.py -h

usage: mk_cnts_file.py --counts_dir &lt;path/to/coutns_dir&gt; --gene_ids &lt;path/to/geneIds.txt

This script summarises log files information into html table

optional arguments:
  -h, --help            show this help message and exit
  --counts_file COUNTS_FILE
                        path to directory with featureCounts files
  --gene_ids GENE_IDS   path to geneIds.txt file, format EnsmblId Chrm
                        GeneName Biotype
  --samples_sheet SAMPLES_SHEET
                        path to samplesSheet.txt file, format old_prefix
                        new_prefix
  --biotype BIOTYPE     specify biotype of interest [protein_coding], 'all' is
                        special to include everything
  --counts_col COUNTS_COL
                        Indicate which column begins read counts. default [7],
                        which is featureCounts default, all columns before 7th
                        are metadata cols
</code></pre>

<p>To get all feature types</p>
<pre><code class="BASH">./mk_cnt_file.py --counts_file sikRun/countFiles/ForwardStrandedCounts.txt \
                 --gene_ids sikRun/countFiles/geneIds.txt \
                 --samples_sheet sikRun/samplesSheet.txt \
                 --biotype all &gt; ForwardStrandedCounts-withNames.txt
</code></pre>

<p>To get just protein_coding features</p>
<pre><code class="BASH">./mk_cnt_file.py --counts_file sikRun/countFiles/ForwardStrandedCounts.txt \
                 --gene_ids sikRun/countFiles/geneIds.txt \
                 --samples_sheet sikRun/samplesSheet.txt \
                 --biotype protein_coding &gt; ForwardStrandedCounts-withNames-proteinCoding.txt
</code></pre>

<h2 id="metric-files-explained">Metric files explained</h2>
<blockquote>
<p>A lot of the tools output some sort of metrics files, to stdout/stderr or a file.
Those metrics are important for analysis and QC checks going forward with the data.
All of those metrics files are summarised into <a href="https://multiqc.info">multiqc</a> report.
This section will attempt to explain in details each one of those metrics</p>
</blockquote>
<h4 id="star">STAR</h4>
<ul>
<li><code>Log.final.out</code></li>
</ul>
<p>This is straight out of the STAR docs</p>
<p>Log.final.out: summary mapping statistics after mapping job is complete, very useful for
quality control. The statistics are calculated for each read (single- or paired-end) and then
summed or averaged over all reads. Note that STAR counts a paired-end read as one read,
(unlike the samtools flagstat/idxstats, which count each mate separately). Most of the informa-
tion is collected about the UNIQUE mappers (unlike samtools flagstat/idxstats which does not
separate unique or multi-mappers). Each splicing is counted in the numbers of splices, which
would correspond to summing the counts in SJ.out.tab. The mismatch/indel error rates are
calculated on a per base basis, i.e. as total number of mismatches/indels in all unique mappers
divided by the total number of mapped bases.</p>
<h4 id="picard">Picard</h4>
<ul>
<li><a href="https://broadinstitute.github.io/picard/picard-metric-definitions.html#AlignmentSummaryMetrics">CollectAlignmentSummaryMetrics</a></li>
<li><a href="https://software.broadinstitute.org/gatk/documentation/tooldocs/current/picard_analysis_CollectGcBiasMetrics.php">CollectGcBiasMetrics</a></li>
<li><a href="https://broadinstitute.github.io/picard/picard-metric-definitions.html#DuplicationMetrics">MarkDuplicates</a></li>
</ul>
<p>These are all picard tools that are used in the pipeline</p>
<ul>
<li><code>CreateSequenceDictionary</code></li>
<li><code>SortSam</code></li>
<li><code>MarkDuplicates</code></li>
<li><code>BuildBamIndex</code></li>
<li><code>CollectAlignmentSummaryMetrics</code></li>
<li><code>CollectInsertSizeMetrics</code></li>
<li><code>CollectGcBiasMetrics</code></li>
<li><code>EstimateLibraryComplexity</code></li>
</ul>
<p><a href="https://twitter.com/intent/tweet?screen_name=kizza_a" class="twitter-mention-button" data-size="large" data-show-count="false">Tweet to @kizza_a</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script> </p>

<p class="twitter-btn">
<a class="twitter-share-button"
  href="https://twitter.com/intent/tweet?text=Hey%20I%27m%20using%20this%20fully%20sick%20RNAseq%20pipeline%20It%27s%20sik%20easy%20http%3A%2F%2Fgithub%2Ecom%2Fmonashbioinformaticsplatform%2FRNAsik%2Dpipe%20by%20%40kizza%5Fa%20from%20%40MonashBioinfo" data-size="large">
Share</a>
</p></div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Created by <a href="https://twitter.com/kizza_a">Kirill Tsyganov</a> with help from the <a href="http://bioinformatics.erc.monash.edu">Monash Bioinformatics Platform</a> team. <br /><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '..';</script>
        <script src="../js/base.js"></script>
        <script src="../search/require.js"></script>
        <script src="../search/search.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td><kbd>&larr;</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td><kbd>&rarr;</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>


    </body>
</html>
